WEBVTT

00:00:00.000 --> 00:00:09.600
[Amit Varma]: If a tree falls in a forest and no one is around to hear it, does it make a sound?

00:00:09.600 --> 00:00:13.880
[Amit Varma]: The philosopher George Berkeley first asked this question in the early 18th century and

00:00:13.880 --> 00:00:18.960
[Amit Varma]: a modern equivalent of it might well be, if you don't possess an ID card given by the

00:00:18.960 --> 00:00:21.680
[Amit Varma]: state, do you even exist?

00:00:21.680 --> 00:00:26.200
[Amit Varma]: This is a poignant question for many people, which is best illustrated by the story of

00:00:26.200 --> 00:00:27.200
[Amit Varma]: Lal Bihari.

00:00:27.200 --> 00:00:31.240
[Amit Varma]: Lal Bihari was a farmer from Azamgarh in Uttar Pradesh.

00:00:31.240 --> 00:00:38.800
[Amit Varma]: He was born in 1951 and when he was 25 years old, in 1976, he was informed by a government

00:00:38.800 --> 00:00:40.760
[Amit Varma]: official that he was dead.

00:00:40.760 --> 00:00:45.280
[Amit Varma]: Apparently, his cousins had bribed a government officer to get him declared dead so that they

00:00:45.280 --> 00:00:47.080
[Amit Varma]: could usurp his land.

00:00:47.080 --> 00:00:51.880
[Amit Varma]: So now Lal Bihari told the officer, but I am here before you, you know me, I have met

00:00:51.880 --> 00:00:53.280
[Amit Varma]: you before.

00:00:53.280 --> 00:00:54.280
[Amit Varma]: The officer wouldn't listen.

00:00:54.280 --> 00:00:56.880
[Amit Varma]: There weren't any documents to prove that he existed.

00:00:56.880 --> 00:01:01.820
[Amit Varma]: So Lal Bihari now realized that to prove that he existed, he would have to get his name

00:01:01.820 --> 00:01:03.840
[Amit Varma]: in the official records.

00:01:03.840 --> 00:01:08.000
[Amit Varma]: He threw stones at a police station so that he would be arrested and his name would be

00:01:08.000 --> 00:01:09.240
[Amit Varma]: on the records.

00:01:09.240 --> 00:01:10.240
[Amit Varma]: No luck.

00:01:10.240 --> 00:01:12.040
[Amit Varma]: He kidnapped his cousin.

00:01:12.040 --> 00:01:15.080
[Amit Varma]: No one seemed to care, so he sent the boy home with an ice cream.

00:01:15.080 --> 00:01:18.040
[Amit Varma]: He applied for compensation for his alleged widow.

00:01:18.040 --> 00:01:20.520
[Amit Varma]: He organized his own funeral.

00:01:20.520 --> 00:01:25.960
[Amit Varma]: And finally, he stood for elections against VP Singh from Allahabad in 1988 and Rajiv

00:01:25.960 --> 00:01:28.400
[Amit Varma]: Gandhi in Amethi in 1989.

00:01:28.400 --> 00:01:29.760
[Amit Varma]: He lost both elections.

00:01:29.760 --> 00:01:31.180
[Amit Varma]: He was still dead.

00:01:31.180 --> 00:01:36.760
[Amit Varma]: By this time, he had formed the Uttar Pradesh Mitak Sangh or the Dead Man's Association

00:01:36.760 --> 00:01:38.520
[Amit Varma]: of Uttar Pradesh.

00:01:38.520 --> 00:01:44.040
[Amit Varma]: They had 20,000 members, people who had been declared dead and did not have an ID with

00:01:44.040 --> 00:01:46.600
[Amit Varma]: which they could prove their existence.

00:01:46.600 --> 00:01:51.860
[Amit Varma]: Lal Bihari himself won a court case and was declared alive in 1994, two decades after

00:01:51.860 --> 00:01:53.500
[Amit Varma]: being declared dead.

00:01:53.500 --> 00:01:57.320
[Amit Varma]: But this land is still full of the walking dead.

00:01:57.320 --> 00:02:02.520
[Amit Varma]: And my point in telling you this story is not that ID cards are a good thing.

00:02:02.520 --> 00:02:03.560
[Amit Varma]: It's the opposite.

00:02:03.560 --> 00:02:09.920
[Amit Varma]: My point is that no government should ever have such power over its citizens.

00:02:09.920 --> 00:02:17.520
[Unknown]: Welcome to the scene and the unseen, our weekly podcast on economics, politics and behavioral

00:02:17.520 --> 00:02:18.520
[Unknown]: science.

00:02:18.520 --> 00:02:19.520
[Unknown]: Please welcome your host, Amit Badma.

00:02:19.520 --> 00:02:23.800
[Amit Varma]: Welcome to the scene and the unseen.

00:02:23.800 --> 00:02:29.680
[Amit Varma]: My topic for today is Aadhaar and my guest is my old friend Nikhil Pawar of Media Nama.

00:02:29.680 --> 00:02:34.360
[Amit Varma]: When I started blogging a decade and a half ago, Nikhil was one of the early friends I

00:02:34.360 --> 00:02:35.360
[Amit Varma]: made.

00:02:35.360 --> 00:02:41.320
[Amit Varma]: In those days, he was a young roly poly cherubic N2 cutlet with a permanent smile on his face.

00:02:41.320 --> 00:02:46.520
[Amit Varma]: And he's still a young roly poly cherubic N2 cutlet all these years later, except that

00:02:46.520 --> 00:02:51.320
[Amit Varma]: now he is also one of the most formidable warriors of freedom in the online space.

00:02:51.320 --> 00:02:55.960
[Amit Varma]: Nikhil runs Media Nama, a highly respected media company and has been a prominent digital

00:02:55.960 --> 00:03:01.120
[Amit Varma]: activist, most well known for his Save the Internet campaign and for spearheading the

00:03:01.120 --> 00:03:02.520
[Amit Varma]: fight against Aadhaar.

00:03:02.520 --> 00:03:05.240
[Guest]: Nikhil, welcome to the scene and the unseen.

00:03:05.240 --> 00:03:08.120
[Guest]: Thanks Amit and thanks for the great intro.

00:03:08.120 --> 00:03:11.560
[Guest]: It's great to be talking to a friend about these issues because you know, that's when

00:03:11.560 --> 00:03:15.200
[Guest]: you're most comfortable and we can have a great conversation, I hope.

00:03:15.200 --> 00:03:20.640
[Amit Varma]: I want to make this episode a sort of a beginner's guide to Aadhaar to people who hear that term

00:03:20.640 --> 00:03:24.920
[Amit Varma]: bandied about but aren't really sure what it is apart from just an ID card, which, you

00:03:24.920 --> 00:03:28.360
[Amit Varma]: know, as you go on to enlighten us, it's not an ID card at all.

00:03:28.360 --> 00:03:34.200
[Amit Varma]: But can we start by talking about all the various objections that you have to Aadhaar?

00:03:34.200 --> 00:03:35.800
[Guest]: So there's a long list of them.

00:03:35.800 --> 00:03:41.880
[Guest]: But the first part is that the idea that this is a national ID is a misnomer.

00:03:41.880 --> 00:03:43.600
[Guest]: Because it's not national.

00:03:43.600 --> 00:03:44.640
[Guest]: It's a resident ID.

00:03:44.640 --> 00:03:49.640
[Guest]: If you are in India for 182 days or above, you can go and get an Aadhaar.

00:03:49.640 --> 00:03:57.560
[Guest]: Which is why an Uzbek citizen in, I think, Vishakhapatnam had committed a crime and she

00:03:57.560 --> 00:04:03.440
[Guest]: was caught with an Aadhaar card not in her name, in a fake name, in a sense, right?

00:04:03.440 --> 00:04:08.800
[Guest]: There was a Pakistani national in Pathankot who was caught with an Aadhaar card as well.

00:04:08.800 --> 00:04:15.520
[Guest]: So any foreigner who stayed in India over 182 days will need an Aadhaar card effectively

00:04:15.520 --> 00:04:20.360
[Guest]: if they want a bank account, if they want a working mobile connection.

00:04:20.360 --> 00:04:24.440
[Guest]: So it's not a national ID because anyone can get it.

00:04:24.440 --> 00:04:28.520
[Amit Varma]: In fact, that means it's a very weak form of ID because even like a passport or a driving

00:04:28.520 --> 00:04:32.520
[Amit Varma]: license is a far better form of ID having gone through verifications.

00:04:32.520 --> 00:04:36.120
[Amit Varma]: And you know, if someone has an Indian passport, you know, they're an Indian citizen, right?

00:04:36.120 --> 00:04:41.880
[Guest]: So the other part of it is that it's also not an ID because there is no verification.

00:04:41.880 --> 00:04:45.640
[Guest]: So what happens is that when you get an Aadhaar and I haven't gotten one and you haven't

00:04:45.640 --> 00:04:46.960
[Amit Varma]: neither have I.

00:04:46.960 --> 00:04:53.600
[Guest]: So essentially what happens is that you go, you take an existing ID and they take your

00:04:53.600 --> 00:04:57.520
[Guest]: fingerprints, they take your iris scan and they give you an Aadhaar card after a particular

00:04:57.520 --> 00:05:00.640
[Guest]: period of time.

00:05:00.640 --> 00:05:05.720
[Guest]: There is a journalist called Devayan Roy who works with CNN and IBN and he went through

00:05:05.720 --> 00:05:09.480
[Guest]: this process, realized that there was no verification that's taking place.

00:05:09.480 --> 00:05:13.720
[Guest]: So he got an Aadhaar card made in a different name.

00:05:13.720 --> 00:05:19.600
[Guest]: He went to the verification center and he got, they made a fake driver's license for

00:05:19.600 --> 00:05:21.320
[Guest]: him I think.

00:05:21.320 --> 00:05:26.880
[Guest]: And so both got submitted at the same time, his actual submission as well as his fake

00:05:26.880 --> 00:05:27.880
[Guest]: one.

00:05:27.880 --> 00:05:28.880
[Guest]: Wow.

00:05:28.880 --> 00:05:31.680
[Guest]: So he reported it and the UIDF filed a case against him.

00:05:31.680 --> 00:05:37.600
[Guest]: What happened eventually was that they granted him an Aadhaar in the false name.

00:05:37.600 --> 00:05:44.760
[Guest]: So Devayan, now it's sad because Devayan is in court trying to get his Aadhaar in his

00:05:44.760 --> 00:05:45.760
[Guest]: own name.

00:05:45.760 --> 00:05:52.780
[Guest]: And you know, I asked the UIDF CEO that question at GCCS, which was a global conference taking

00:05:52.780 --> 00:05:54.800
[Guest]: place in Delhi.

00:05:54.800 --> 00:05:59.400
[Guest]: And he laughed and he said that, you know, I'm saying that he will be stuck with his

00:05:59.400 --> 00:06:01.800
[Guest]: name for the rest of his life.

00:06:01.800 --> 00:06:05.200
[Guest]: And this is the beauty of Aadhaar that if you get it in the wrong name, you're stuck

00:06:05.200 --> 00:06:07.800
[Guest]: with that name for the rest of your life.

00:06:07.800 --> 00:06:13.400
[Guest]: He said his words were that, you know, his child will go to school and say that my papa's

00:06:13.400 --> 00:06:14.400
[Guest]: name has changed.

00:06:14.400 --> 00:06:18.540
[Guest]: I mean, that's disgusting.

00:06:18.540 --> 00:06:19.540
[Guest]: But it is what it is.

00:06:19.540 --> 00:06:24.400
[Guest]: And it shows the mentality of the UIDF when it comes to these issues.

00:06:24.400 --> 00:06:29.720
[Guest]: But the point is that anyone can take any ID and get an Aadhaar made in that name.

00:06:29.720 --> 00:06:35.120
[Guest]: Now there are criminals who may have potentially changed their name now and now have a clean

00:06:35.120 --> 00:06:37.960
[Guest]: record and there's no way of knowing that.

00:06:37.960 --> 00:06:45.360
[Guest]: So you know, really when you look at Aadhaar from this perspective about being an ID, it's

00:06:45.360 --> 00:06:48.880
[Guest]: not really an ID, it's more of a proof of authentication.

00:06:48.880 --> 00:06:53.760
[Guest]: It's a proof that your fingerprint is connected to this Aadhaar number or not.

00:06:53.760 --> 00:06:54.760
[Guest]: But there is no verification.

00:06:54.760 --> 00:06:58.240
[Guest]: A passport is a better means of verification.

00:06:58.240 --> 00:07:02.200
[Guest]: You have cops who come to your home, they talk to your neighbours, there's some amount

00:07:02.200 --> 00:07:07.600
[Guest]: of physical check that takes place before you get a passport.

00:07:07.600 --> 00:07:11.120
[Guest]: The scale at which Aadhaar has been implemented, it was impossible to do that.

00:07:11.120 --> 00:07:15.640
[Guest]: The pace at which it was being implemented, there's a large number of fakes that would

00:07:15.640 --> 00:07:17.100
[Guest]: have been created.

00:07:17.100 --> 00:07:24.360
[Guest]: So that's another problem with Aadhaar that there were about 49,000 enrolment agencies

00:07:24.360 --> 00:07:31.040
[Guest]: whose license was cancelled for violation of processes when it came to the creation

00:07:31.040 --> 00:07:38.000
[Guest]: of Aadhaar, including one that was storing biometrics and effectively using replay biometrics

00:07:38.000 --> 00:07:44.420
[Guest]: which generate new Aadhaar numbers because they were being paid per ID generated.

00:07:44.420 --> 00:07:49.900
[Guest]: And so the incentive structure was created in a manner that they would create more enrolments

00:07:49.900 --> 00:07:53.620
[Guest]: and there was no way of checking this.

00:07:53.620 --> 00:07:58.940
[Guest]: I think the whole system is flawed in the way it has been developed and there's a Silicon

00:07:58.940 --> 00:08:03.060
[Guest]: Valley philosophy that goes move fast and break things.

00:08:03.060 --> 00:08:09.100
[Guest]: There is an agile development sort of approach which says that start and then keep iterating

00:08:09.100 --> 00:08:10.680
[Guest]: and keep improving.

00:08:10.680 --> 00:08:15.860
[Guest]: But when you're looking at something of a national scale that impacts the lives of people,

00:08:15.860 --> 00:08:20.300
[Guest]: I think the philosophy we ought to have is move slow and fix things.

00:08:20.300 --> 00:08:24.540
[Guest]: You know, you have to be deliberate, you have to be conscious, you have to monitor and you

00:08:24.540 --> 00:08:28.720
[Guest]: have to fix these problems before it impacts a large number of people.

00:08:28.720 --> 00:08:32.900
[Guest]: In this case, the rush to just get more and more people on board and this is something

00:08:32.900 --> 00:08:39.180
[Guest]: which Nandan Nilekani has talked about, which is that if you move so very, very quickly

00:08:39.180 --> 00:08:44.060
[Guest]: in these things, the opposition does not have time to consolidate.

00:08:44.060 --> 00:08:47.340
[Guest]: So by the time they realized what was going on, these guys had moved much further ahead.

00:08:47.340 --> 00:08:49.260
[Amit Varma]: Did he say this approvingly?

00:08:49.260 --> 00:08:56.020
[Guest]: I think he said this as a strategy that they deployed because there was opposition to Aadhaar

00:08:56.020 --> 00:08:57.620
[Guest]: from the very beginning as well.

00:08:57.620 --> 00:09:02.780
[Guest]: So I'm saying that this is the negative outcome of the problems that we're facing now is an

00:09:02.780 --> 00:09:03.900
[Guest]: outcome of the rush.

00:09:03.900 --> 00:09:09.580
[Guest]: So that was another point that I wanted to make about how not to create a national ID

00:09:09.580 --> 00:09:12.740
[Guest]: is, haste is bad.

00:09:12.740 --> 00:09:15.580
[Guest]: You are going to mess up people's life if you do that.

00:09:15.580 --> 00:09:19.580
[Amit Varma]: And the thing to remember is that there is so much at stake, like, it makes me really

00:09:19.580 --> 00:09:24.300
[Amit Varma]: angry when you just told me, you know, what the UAE IDI chairman said about, you know,

00:09:24.300 --> 00:09:27.980
[Amit Varma]: Deba and Roy being stuck with a fake name forever and almost a sense of Schadenfreude

00:09:27.980 --> 00:09:31.900
[Amit Varma]: that he kind of expressed is that they control the lives of the people.

00:09:31.900 --> 00:09:35.780
[Amit Varma]: This whole approach that the people belong to the state and we can do what we want with

00:09:35.780 --> 00:09:36.780
[Amit Varma]: you.

00:09:36.780 --> 00:09:39.660
[Amit Varma]: Like, you know, I started my show with an intro about Lal Bihari Mirtak who you must

00:09:39.660 --> 00:09:40.660
[Guest]: have heard of.

00:09:40.660 --> 00:09:41.660
[Amit Varma]: Yeah.

00:09:41.660 --> 00:09:44.180
[Guest]: And, and that attitude just infuriates me.

00:09:44.180 --> 00:09:45.180
[Guest]: No.

00:09:45.180 --> 00:09:50.460
[Guest]: And therefore, this is also about, so, is us as citizens and as people being deprived

00:09:50.460 --> 00:09:51.460
[Guest]: of agency.

00:09:51.460 --> 00:09:52.460
[Guest]: Right.

00:09:52.460 --> 00:09:57.420
[Guest]: We are not given a choice about whether we want an Aadhaar or not.

00:09:57.420 --> 00:10:01.940
[Guest]: And so, you know, I think there's, this is one of the challenges that we face and this

00:10:01.940 --> 00:10:07.260
[Guest]: is why there's a great deal of anger amongst people right now, because you're constantly

00:10:07.260 --> 00:10:11.780
[Guest]: bombarded with messages about having been forced to link it.

00:10:11.780 --> 00:10:16.700
[Guest]: The question that I would like to ask is how many people who've gotten an Aadhaar actually

00:10:16.700 --> 00:10:18.180
[Unknown]: wanted to get one?

00:10:18.180 --> 00:10:20.660
[Guest]: And how many have been forced to get one?

00:10:20.660 --> 00:10:27.380
[Guest]: And by making it mandatory for so many things, you've effectively forced, like, I know,

00:10:27.380 --> 00:10:31.380
[Guest]: students who didn't want one but had to get one because they wouldn't be allowed to sit

00:10:31.380 --> 00:10:33.580
[Guest]: in exams if they didn't have one.

00:10:33.580 --> 00:10:39.580
[Guest]: And how do they feel about this is something that we have to take into account.

00:10:39.580 --> 00:10:44.860
[Guest]: And this is an argument that's also being made in court, that it's, we have the right

00:10:44.860 --> 00:10:49.660
[Guest]: to informational self-determination, which is that we have the right to choose what we

00:10:49.660 --> 00:10:52.740
[Guest]: want to do with our information, who we give it to.

00:10:52.740 --> 00:10:57.500
[Guest]: And by being forced to get an Aadhaar and being forced to give this information to the

00:10:57.500 --> 00:11:01.460
[Guest]: government, we are being dropped off our agency.

00:11:01.460 --> 00:11:07.700
[Guest]: What's happening with Aadhaar in this case is that it is, it's taking your and my personal

00:11:07.700 --> 00:11:15.900
[Guest]: information, converting it into a public asset, and then privatizing it without us having

00:11:15.900 --> 00:11:16.900
[Guest]: a choice.

00:11:16.900 --> 00:11:22.100
[Guest]: So, for example, the National Health Information Network is probably going to get rolled out

00:11:22.100 --> 00:11:26.820
[Guest]: next year with Aadhaar linked electronic health records.

00:11:26.820 --> 00:11:31.660
[Guest]: Last year, Viral Acharya, the deputy governor of the RBI spoke about the creation of a public

00:11:31.660 --> 00:11:37.740
[Guest]: credit registry, which then startups can build businesses on top of, saying that the baseline

00:11:37.740 --> 00:11:43.520
[Guest]: of personal credit information, the financial transactions that we do, will be provided

00:11:43.520 --> 00:11:44.860
[Guest]: by the government.

00:11:44.860 --> 00:11:49.740
[Guest]: And then they can add their own data sets on top of it to provide you more granular

00:11:49.740 --> 00:11:50.740
[Guest]: services.

00:11:50.740 --> 00:11:54.900
[Guest]: Now, this is good, but the question is, where is the agency here in the sense, do we have

00:11:54.900 --> 00:11:55.900
[Guest]: choice?

00:11:55.900 --> 00:11:58.580
[Guest]: Are we giving consent?

00:11:58.580 --> 00:12:01.260
[Guest]: So we're being forced to part with our data.

00:12:01.260 --> 00:12:03.940
[Guest]: And the idea is to build businesses on top of that data.

00:12:03.940 --> 00:12:08.780
[Amit Varma]: And then what I keep telling people is, you know, whatever you say about Aadhaar, my fundamental

00:12:08.780 --> 00:12:13.180
[Amit Varma]: objection to it, as you correctly nailed right now, is a question of consent.

00:12:13.180 --> 00:12:15.540
[Amit Varma]: It's a coercion that we are forced to take Aadhaar.

00:12:15.540 --> 00:12:18.780
[Amit Varma]: You know, you might say it's insecure or it's not insecure or whatever.

00:12:18.780 --> 00:12:22.700
[Amit Varma]: But if you have the agency to be able to decide, that's fine.

00:12:22.700 --> 00:12:28.100
[Amit Varma]: And the whole Aadhaar imbroglio, in a sense, illustrates the perversity of what the state

00:12:28.100 --> 00:12:29.100
[Amit Varma]: has become.

00:12:29.100 --> 00:12:32.580
[Amit Varma]: The state is ideally there to protect our rights and to protect our property.

00:12:32.580 --> 00:12:36.460
[Amit Varma]: But now what is happening is, I am told that if by 31st March, I don't link my Aadhaar

00:12:36.460 --> 00:12:39.420
[Amit Varma]: to my bank account, they could freeze my bank account.

00:12:39.420 --> 00:12:45.380
[Amit Varma]: The government is there to protect my money, not to, you know, I mean, is basically theft

00:12:45.380 --> 00:12:46.380
[Amit Varma]: if not destruction.

00:12:46.380 --> 00:12:50.260
[Guest]: No, and what this does essentially is that it's changing the relationship between the

00:12:50.260 --> 00:12:55.100
[Guest]: citizen and the state, because of all the information that they're now able to collect

00:12:55.100 --> 00:12:56.100
[Guest]: on you.

00:12:56.100 --> 00:12:57.100
[Guest]: Right.

00:12:57.100 --> 00:13:00.100
[Guest]: So if you go back to the idea of Aadhaar, I think you need to look at it from a mass

00:13:00.100 --> 00:13:01.940
[Guest]: surveillance perspective.

00:13:01.940 --> 00:13:06.620
[Guest]: So about, I think, five, six years ago, we heard about this project being rolled out

00:13:06.620 --> 00:13:10.940
[Guest]: called NatGrid, which was a national intelligence grid, effectively.

00:13:10.940 --> 00:13:14.860
[Guest]: And the idea was that it would connect 21 databases together.

00:13:14.860 --> 00:13:18.060
[Guest]: So your bank, your mobile, etc, all of these things.

00:13:18.060 --> 00:13:24.580
[Guest]: Now, you know, if you think about it, an Amit Sharma in one database is not going to be

00:13:24.580 --> 00:13:27.180
[Guest]: an Amit Sharma in another database, right?

00:13:27.180 --> 00:13:32.820
[Guest]: The de-duplication is very difficult, because the names are going to be, are the same across.

00:13:32.820 --> 00:13:35.920
[Guest]: John Smith, you know, from that perspective.

00:13:35.920 --> 00:13:40.700
[Guest]: What the Aadhaar number does is it de-duplicates these databases.

00:13:40.700 --> 00:13:47.820
[Guest]: This two of NatGrid, at least from what I've read, is going to have 955 public and private

00:13:47.820 --> 00:13:48.980
[Guest]: databases.

00:13:48.980 --> 00:13:54.620
[Guest]: So every aspect of your life, every interaction is going to effectively become an Aadhaar

00:13:54.620 --> 00:14:00.220
[Guest]: linked database, which will then be available to the state when they want to glean information

00:14:00.220 --> 00:14:01.220
[Guest]: about you.

00:14:01.220 --> 00:14:06.020
[Guest]: Now, zoom out and look at the impact that can have on a democracy, and that impact that

00:14:06.020 --> 00:14:11.980
[Guest]: can have on an individual's agency, if the state has that much informational power over

00:14:11.980 --> 00:14:12.980
[Guest]: them.

00:14:12.980 --> 00:14:18.580
[Guest]: And so these are very dangerous times for us as citizens and for our rights.

00:14:18.580 --> 00:14:23.380
[Guest]: Also for the opposition parties, because you know, this government may not be that bad,

00:14:23.380 --> 00:14:28.980
[Guest]: but who knows five governments down the line, you will have a totalitarian entity that uses

00:14:28.980 --> 00:14:32.740
[Guest]: this information to effectively change the course of history forever.

00:14:32.740 --> 00:14:36.660
[Amit Varma]: I mean, every individual should just think of the government in power as being the absolute

00:14:36.660 --> 00:14:39.380
[Amit Varma]: worst that he can think of, whatever that might be.

00:14:39.380 --> 00:14:41.180
[Amit Varma]: And you give them this much power.

00:14:41.180 --> 00:14:45.500
[Amit Varma]: And you said earlier that this reverses the relationship between the citizen and the state.

00:14:45.500 --> 00:14:48.020
[Amit Varma]: I would actually say it illustrates it.

00:14:48.020 --> 00:14:52.940
[Amit Varma]: And in the sense that it's pretty much been this way that the state has treated its citizens

00:14:52.940 --> 00:14:54.700
[Amit Varma]: as its subjects.

00:14:54.700 --> 00:14:59.180
[Amit Varma]: And the difference of Aadhaar and the control that they have over our lives, because our

00:14:59.180 --> 00:15:03.580
[Amit Varma]: data now belongs to them, is that the state is empowered, like typically, you'd imagine

00:15:03.580 --> 00:15:07.380
[Amit Varma]: that in these modern times, technology empowers individuals.

00:15:07.380 --> 00:15:12.300
[Amit Varma]: But here you actually have Aadhaar empowering the state against its individuals instead

00:15:12.300 --> 00:15:13.780
[Guest]: of, you know, protecting the individuals.

00:15:13.780 --> 00:15:17.780
[Guest]: So one of the arguments that's being made is that Google has your data, Facebook has

00:15:17.780 --> 00:15:18.780
[Guest]: your data.

00:15:18.780 --> 00:15:19.780
[Guest]: That's voluntary.

00:15:19.780 --> 00:15:24.740
[Guest]: So one part is yes, that is voluntary, but also they have a lot of data about you.

00:15:24.740 --> 00:15:29.860
[Guest]: So you know, we're in an era where all of these entities have a large amount of information

00:15:29.860 --> 00:15:30.860
[Guest]: about us.

00:15:30.860 --> 00:15:35.380
[Guest]: But we really have little control over information that is us.

00:15:35.380 --> 00:15:40.020
[Guest]: In the sense, in today's day and age, we are data, you know, we, every single activity

00:15:40.020 --> 00:15:41.580
[Guest]: that we do generates data.

00:15:41.580 --> 00:15:47.060
[Guest]: You have, people are talking about the quantified self with, I mean, I have a friend who stuck

00:15:47.060 --> 00:15:52.880
[Guest]: some device in his arm, and he uses it to monitor his blood sugar levels, that's going

00:15:52.880 --> 00:15:53.960
[Guest]: to an app.

00:15:53.960 --> 00:15:58.740
[Guest]: So we're generating truckloads of information about ourselves and we'll continue to do that.

00:15:58.740 --> 00:16:02.780
[Guest]: The power equation with the platforms is also something to consider.

00:16:02.780 --> 00:16:08.020
[Guest]: So the state's solution for dealing with that changing power equation, and these platforms

00:16:08.020 --> 00:16:14.780
[Guest]: like, you know, whether it's Google or Facebook or it's Amazon, it's Microsoft, Tencent, Baidu,

00:16:14.780 --> 00:16:20.960
[Guest]: the state's solution there is to, hey, give us your data as well, so we'll also use that.

00:16:20.960 --> 00:16:26.880
[Guest]: So we're effectively in a situation where there is a global market failure in data protection

00:16:26.880 --> 00:16:28.540
[Guest]: and privacy.

00:16:28.540 --> 00:16:31.860
[Guest]: And the solution to that problem shouldn't be more data.

00:16:31.860 --> 00:16:34.020
[Amit Varma]: It should be giving us more control over our data.

00:16:34.020 --> 00:16:38.260
[Amit Varma]: In fact, the fundamental role of the government should be to protect the rights of its citizens,

00:16:38.260 --> 00:16:42.940
[Amit Varma]: and therefore the government should be putting that data, those data protection laws in place

00:16:42.940 --> 00:16:45.460
[Amit Varma]: rather than trying to exploit its absence.

00:16:45.460 --> 00:16:51.020
[Guest]: So this is one of the problems with Aadhaar, that Aadhaar was brought in through an ordinance

00:16:51.020 --> 00:16:56.260
[Guest]: initially, without a privacy law in place, there still isn't a privacy law.

00:16:56.260 --> 00:17:00.020
[Guest]: The current committee that's looking at the privacy law is essentially, it has people

00:17:00.020 --> 00:17:03.860
[Guest]: who've argued against a fundamental right to privacy in the Supreme Court, right?

00:17:03.860 --> 00:17:08.780
[Guest]: It has a CEO of the UIDA and the UIDA is really not one that's going to uphold privacy the

00:17:08.780 --> 00:17:10.460
[Guest]: way it's operating right now.

00:17:10.460 --> 00:17:16.620
[Guest]: So we have a problem here that we don't have a data protection law, Aadhaar, even when

00:17:16.620 --> 00:17:22.500
[Guest]: it was taken through Parliament, it was taken as a money bill, with the Rajya Sabha having

00:17:22.500 --> 00:17:27.620
[Guest]: no role except making recommendations which the Lok Sabha rejected, because the current

00:17:27.620 --> 00:17:30.340
[Guest]: government has a majority in the Lok Sabha.

00:17:30.340 --> 00:17:35.740
[Guest]: And those protection requirements were actually fairly good in the sense you had, one was

00:17:35.740 --> 00:17:41.940
[Guest]: for the definition of national security, because in India, there is no definition.

00:17:41.940 --> 00:17:47.860
[Guest]: So the state has complete freedom in terms of who, under what causes it goes and snoops

00:17:47.860 --> 00:17:48.860
[Guest]: on someone.

00:17:48.860 --> 00:17:54.580
[Guest]: You know, there was purpose limitation, which was another solution where you can only limit

00:17:54.580 --> 00:17:59.860
[Guest]: it to a few select services, and not build a whole private ecosystem or enable a whole

00:17:59.860 --> 00:18:03.020
[Guest]: private ecosystem on the basis of our data.

00:18:03.020 --> 00:18:07.460
[Guest]: So checks and balances were essentially rejected in Parliament.

00:18:07.460 --> 00:18:14.480
[Guest]: And therefore, even from like, it's almost been a journey of the state constantly trying

00:18:14.480 --> 00:18:17.420
[Guest]: to hoodwink its citizens over the last few years.

00:18:17.420 --> 00:18:20.460
[Guest]: And this is not just the BJP, by the way, it happened with the Congress as well.

00:18:20.460 --> 00:18:22.060
[Guest]: It's a DNA of the state.

00:18:22.060 --> 00:18:23.060
[Guest]: It's a state.

00:18:23.060 --> 00:18:28.280
[Guest]: And so I'm very worried about where we're going with this and how the future is going

00:18:28.280 --> 00:18:34.660
[Guest]: to be, if this is allowed, because, you know, I don't, I don't, I'm not sure whether the

00:18:34.660 --> 00:18:39.740
[Guest]: Supreme Court judges really realize the ramifications of what they're dealing with over here.

00:18:39.740 --> 00:18:44.220
[Guest]: We got a great judgment in terms of the fundamental right to privacy.

00:18:44.220 --> 00:18:50.180
[Guest]: But the way it looks at, there were exceptions that were brought in, especially for welfare.

00:18:50.180 --> 00:18:54.380
[Guest]: And that's what the lawyers, some lawyers that I've spoken with seem to think that,

00:18:54.380 --> 00:18:57.540
[Guest]: that is a means of justifying Aadhaar.

00:18:57.540 --> 00:19:01.860
[Guest]: So we don't know where this case is going to go, but I think it's pretty worrying.

00:19:01.860 --> 00:19:05.700
[Amit Varma]: Let's move on with your laundry list of objections to Aadhaar, which I know is a long one.

00:19:05.700 --> 00:19:06.700
[Guest]: It's a long one.

00:19:06.700 --> 00:19:14.260
[Guest]: So the other is that, actually, this is about the permanence of the Aadhaar number, which

00:19:14.260 --> 00:19:22.500
[Guest]: is a single permanent number that is you effectively, and the permanence of biometrics as a password.

00:19:22.500 --> 00:19:29.620
[Guest]: Now that's just stupid, because if, imagine having an email address with a permanent password

00:19:29.620 --> 00:19:30.940
[Guest]: that you can't change.

00:19:30.940 --> 00:19:32.060
[Guest]: Mind boggling.

00:19:32.060 --> 00:19:38.100
[Guest]: So this is, and, and what's happened over the past few years is that government departments

00:19:38.100 --> 00:19:44.140
[Guest]: have been leaking Aadhaar numbers and a lot of personal information by the millions.

00:19:44.140 --> 00:19:50.860
[Guest]: I mean, a CIS report pointed out that only about four schemes had, have had details of

00:19:50.860 --> 00:19:54.780
[Guest]: over 135 million people.

00:19:54.780 --> 00:19:56.740
[Guest]: And all of this is available on Google search.

00:19:56.740 --> 00:20:01.820
[Amit Varma]: So sketch out a scenario for me, what happens if some, what can, what can go wrong if someone's

00:20:01.820 --> 00:20:02.820
[Guest]: Aadhaar number gets leaked?

00:20:02.820 --> 00:20:04.540
[Guest]: First, let me tell you what information it had.

00:20:04.540 --> 00:20:08.740
[Guest]: Because I've seen some of these Excel sheets, because government departments uploaded Excel

00:20:08.740 --> 00:20:12.340
[Guest]: sheets with personal information on their websites.

00:20:12.340 --> 00:20:20.580
[Guest]: And you had to do a Google search for a file type xlsx in quotes Aadhaar number, and you

00:20:20.580 --> 00:20:24.980
[Guest]: would get some of these sheets, which you can download and get people's personal details.

00:20:24.980 --> 00:20:33.620
[Guest]: So they had Aadhaar number, bank account, address, date of birth, father slash spouse's

00:20:33.620 --> 00:20:41.540
[Guest]: name, you know, gender in some cases, caste and religion in some cases in Excel sheets.

00:20:41.540 --> 00:20:45.980
[Amit Varma]: So spell out for me, what can go wrong when this kind of data gets released or falls into

00:20:45.980 --> 00:20:46.980
[Guest]: the wrong hands?

00:20:46.980 --> 00:20:52.780
[Guest]: So, one is of course targeting, you know, if as Aadhaar gets linked to more and more

00:20:52.780 --> 00:20:56.700
[Guest]: things, individuals can be targeted in a manner which is predatory.

00:20:56.700 --> 00:21:01.260
[Guest]: And we've seen some of this happen, because the information that's being leaked where

00:21:01.260 --> 00:21:05.820
[Guest]: you had a situation where people were getting phone calls saying, I'm calling from so and

00:21:05.820 --> 00:21:07.940
[Guest]: so bank, is this your Aadhaar number?

00:21:07.940 --> 00:21:11.300
[Guest]: Is this, is this your bank account number?

00:21:11.300 --> 00:21:16.860
[Guest]: I'm sending you a verification code because you have to link your Aadhaar to your bank.

00:21:16.860 --> 00:21:19.660
[Guest]: And then people would give that detail and they would find that money's been transferred

00:21:19.660 --> 00:21:20.660
[Amit Varma]: out.

00:21:20.660 --> 00:21:24.940
[Guest]: In fact, this happened to a member of parliament in Punjab, as well.

00:21:24.940 --> 00:21:30.420
[Guest]: I received a call in fact, and I have the audio of that because I recorded it, where,

00:21:30.420 --> 00:21:34.060
[Guest]: and it wasn't Aadhaar related, but because I don't have an Aadhaar, but it was related

00:21:34.060 --> 00:21:38.700
[Guest]: to PhonePe, which is a UPI payments app, which I use.

00:21:38.700 --> 00:21:44.460
[Guest]: And so the person didn't realize that I know about the payments ecosystem.

00:21:44.460 --> 00:21:47.320
[Guest]: He said, I'm sending you a verification code.

00:21:47.320 --> 00:21:51.940
[Guest]: When I looked at my phone, it was a password reset code.

00:21:51.940 --> 00:21:56.940
[Guest]: And so for most people who can't understand English, and because this, they're going to

00:21:56.940 --> 00:22:01.500
[Guest]: give this information away, because they think that the person who's calling them is legitimately

00:22:01.500 --> 00:22:03.140
[Guest]: calling from these places.

00:22:03.140 --> 00:22:05.660
[Amit Varma]: And how did you realize it was a password reset code?

00:22:05.660 --> 00:22:07.500
[Amit Varma]: It would have just been a number, right?

00:22:07.500 --> 00:22:12.340
[Guest]: No, it said your password reset code, so credit to PhonePe over here.

00:22:12.340 --> 00:22:16.000
[Guest]: It said your password reset code is so and so.

00:22:16.000 --> 00:22:19.980
[Guest]: So I think, but again, it was entirely in English, right?

00:22:19.980 --> 00:22:25.960
[Guest]: So you know, and so we are going to face problems because there are issues of information asymmetry

00:22:25.960 --> 00:22:27.880
[Guest]: and bounded rationality.

00:22:27.880 --> 00:22:30.960
[Guest]: And people may not understand the implications of what they're doing, and they might find

00:22:30.960 --> 00:22:33.300
[Guest]: that money's been funneled and they've been wiped out.

00:22:33.300 --> 00:22:34.300
[Amit Varma]: Exactly.

00:22:34.300 --> 00:22:39.320
[Guest]: But they still have their Aadhaar number, they still have their Aadhaar number.

00:22:39.320 --> 00:22:47.220
[Guest]: So again, so going back to the issues, one major problem is a centralization of all this

00:22:47.220 --> 00:22:49.460
[Guest]: data in a single database.

00:22:49.460 --> 00:22:56.260
[Guest]: And so what we found a month or so ago, there was a story broken by Rasna Khera of the Tribune,

00:22:56.260 --> 00:23:01.820
[Guest]: where she was added to a WhatsApp group of people who were allowing, who were selling

00:23:01.820 --> 00:23:04.720
[Guest]: access to the Aadhaar database.

00:23:04.720 --> 00:23:09.020
[Guest]: So what the government had done was they had made some village level entrepreneurs at some

00:23:09.020 --> 00:23:14.340
[Guest]: common service centers, customer support people for you know, people who walk up to them saying

00:23:14.340 --> 00:23:20.500
[Guest]: we have these issues, etc, and that allowed access to the Aadhaar database.

00:23:20.500 --> 00:23:24.820
[Guest]: They were selling access to the database at 500 rupees a pop.

00:23:24.820 --> 00:23:29.500
[Guest]: And they were doing that because there were no checks and balances in place in terms of

00:23:29.500 --> 00:23:31.260
[Guest]: permissions.

00:23:31.260 --> 00:23:40.620
[Guest]: So you know, if you use WordPress, you have administrator, editor, contributor, etc, etc.

00:23:40.620 --> 00:23:46.580
[Guest]: So here's the thing, WordPress was started what in 2004-2005, WordPress then had a better

00:23:46.580 --> 00:23:50.000
[Guest]: permission architecture than Aadhaar does today.

00:23:50.000 --> 00:23:53.580
[Guest]: And so people who've got access get access to the entire database.

00:23:53.580 --> 00:23:57.340
[Guest]: From a centralization database, the other issue is that if it gets compromised, if access

00:23:57.340 --> 00:24:02.060
[Guest]: gets compromised, the access to the entire database gets compromised.

00:24:02.060 --> 00:24:07.380
[Guest]: It's not in silos, it's not like as per district and you have limited amount of access.

00:24:07.380 --> 00:24:11.700
[Guest]: So it's a bad idea because it creates a single point of failure.

00:24:11.700 --> 00:24:16.920
[Guest]: The other single point of failure is the Aadhaar number itself, because it's a unification

00:24:16.920 --> 00:24:19.340
[Guest]: of an identity into a single number.

00:24:19.340 --> 00:24:24.700
[Guest]: So you know, today you can give your driver's license somewhere as an ID proof, you can

00:24:24.700 --> 00:24:28.540
[Guest]: give your PAN, you can give your Aadhaar number.

00:24:28.540 --> 00:24:34.280
[Guest]: If you have federated IDs or separate IDs, then there is a certain amount of security

00:24:34.280 --> 00:24:38.020
[Guest]: that comes in because only one part will get compromised.

00:24:38.020 --> 00:24:42.500
[Guest]: Sometimes if people take a driver's license, they don't know what that is ID proof for.

00:24:42.500 --> 00:24:43.500
[Guest]: Correct.

00:24:43.500 --> 00:24:44.500
[Guest]: Right?

00:24:44.500 --> 00:24:46.660
[Guest]: No one knows what you've given as an ID proof for your bank.

00:24:46.660 --> 00:24:48.700
[Guest]: It could be one of multiple things.

00:24:48.700 --> 00:24:53.940
[Guest]: But if there's a single number that is the ID proof for everything, and remember, it's

00:24:53.940 --> 00:24:57.140
[Guest]: not an ID proof, right?

00:24:57.140 --> 00:25:01.780
[Guest]: It's effectively it can compromise you across the board.

00:25:01.780 --> 00:25:06.940
[Guest]: Once someone has your Aadhaar number, all they need is your biometrics, or they need

00:25:06.940 --> 00:25:07.940
[Guest]: an OTP.

00:25:07.940 --> 00:25:09.980
[Guest]: OTP is easily hackable.

00:25:09.980 --> 00:25:12.900
[Guest]: And biometrics have been cloned from fingerprints.

00:25:12.900 --> 00:25:17.740
[Guest]: There were school students, I think the college students in Bombay, who found faking attendance

00:25:17.740 --> 00:25:23.420
[Guest]: because they had cloned fingerprints and you had attendance based on fingerprint authentication.

00:25:23.420 --> 00:25:30.900
[Guest]: In Surat, biometrics were being sold, biometric databases were being sold.

00:25:30.900 --> 00:25:35.620
[Guest]: And I saw this photograph of a pink thumb impression, which someone could just take

00:25:35.620 --> 00:25:38.940
[Guest]: and put on a authentication machine.

00:25:38.940 --> 00:25:45.060
[Guest]: So again, because you're using biometrics and biometrics have been cloned, the iris

00:25:45.060 --> 00:25:51.100
[Guest]: has been cloned, the fingerprint has been cloned, a face ID is even easier to clone

00:25:51.100 --> 00:25:53.120
[Guest]: from from photographs.

00:25:53.120 --> 00:25:54.900
[Guest]: You are going to have problems going forward.

00:25:54.900 --> 00:25:59.580
[Amit Varma]: No, and also, you know, if any system can be gamed, it will be gamed.

00:25:59.580 --> 00:26:02.940
[Amit Varma]: And here you have a government which is building a system and the government is always going

00:26:02.940 --> 00:26:05.540
[Amit Varma]: to be staggeringly incompetent at this.

00:26:05.540 --> 00:26:09.180
[Amit Varma]: And the ingenuity we have in our country, we can game anything.

00:26:09.180 --> 00:26:12.180
[Amit Varma]: You put the two together, and it's a recipe for disaster.

00:26:12.180 --> 00:26:13.980
[Guest]: And we've seen multiple instances of that.

00:26:13.980 --> 00:26:19.780
[Guest]: So again, from a security access perspective, in UP, there was a case where people had cloned

00:26:19.780 --> 00:26:24.660
[Guest]: fingerprints and they were generating Aadhaar numbers and they were selling that software

00:26:24.660 --> 00:26:35.380
[Guest]: bypassing the iris authentication for an enrolment officer by essentially patching the Aadhaar

00:26:35.380 --> 00:26:36.380
[Guest]: enrolment software.

00:26:36.380 --> 00:26:40.780
[Amit Varma]: Because of bad incentives, they were paid by the number of Aadhaars generated.

00:26:40.780 --> 00:26:41.780
[Guest]: Exactly.

00:26:41.780 --> 00:26:43.940
[Guest]: Again, right now it is enrolment.

00:26:43.940 --> 00:26:48.700
[Guest]: Once enrolment is finished, if, let's say 100% or given that they're probably fakes

00:26:48.700 --> 00:26:57.980
[Guest]: in the system, 106% of this country is enrolled, then you will find other scams emerging bit

00:26:57.980 --> 00:26:58.980
[Guest]: by bit.

00:26:58.980 --> 00:27:00.260
[Guest]: We don't know the scale of this problem.

00:27:00.260 --> 00:27:06.620
[Guest]: And there are, like I said, 49,000 enrolment agencies whose license was cancelled.

00:27:06.620 --> 00:27:10.460
[Guest]: And we don't know how many fakes there are in the system right now.

00:27:10.460 --> 00:27:15.020
[Guest]: For all those people who were enrolled by those agencies, have they been re-enrolled

00:27:15.020 --> 00:27:16.180
[Guest]: or not?

00:27:16.180 --> 00:27:19.100
[Guest]: Is there any information to that effect so far?

00:27:19.100 --> 00:27:21.020
[Guest]: We don't know.

00:27:21.020 --> 00:27:24.740
[Guest]: And that's again because of a lack of transparency from the UIDAI.

00:27:24.740 --> 00:27:30.020
[Guest]: They are repeatedly rejecting requests of right to information.

00:27:30.020 --> 00:27:32.860
[Guest]: So they have something to hide it seems.

00:27:32.860 --> 00:27:37.860
[Guest]: But again, going back to the earlier point about this relationship between the state

00:27:37.860 --> 00:27:44.700
[Guest]: and the citizen, we're in a situation where transparency is expected of citizens but not

00:27:44.700 --> 00:27:45.700
[Amit Varma]: of the state.

00:27:45.700 --> 00:27:46.700
[Amit Varma]: Yeah.

00:27:46.700 --> 00:27:50.540
[Amit Varma]: And there are millions of common citizens who are victims of this.

00:27:50.540 --> 00:27:55.780
[Amit Varma]: And you know, you spoke about Debayan Roy and obviously he's privileged enough that

00:27:55.780 --> 00:27:58.180
[Unknown]: you were speaking about him and asking questions about him.

00:27:58.180 --> 00:28:00.100
[Amit Varma]: But most common people have no recourse at all.

00:28:00.100 --> 00:28:01.100
[Amit Varma]: They may not even know English.

00:28:01.100 --> 00:28:04.260
[Amit Varma]: They may not know how to negotiate the system in any way whatsoever.

00:28:04.260 --> 00:28:10.980
[Guest]: And I don't think, I mean, there's a separate debate to be had on the state of media and

00:28:10.980 --> 00:28:14.180
[Guest]: the economic health of media in this country right now.

00:28:14.180 --> 00:28:19.340
[Guest]: But really, most publications don't have people who can go out into the villages and see the

00:28:19.340 --> 00:28:20.860
[Guest]: kind of problems that they're facing.

00:28:20.860 --> 00:28:23.460
[Guest]: Scroll has done some great work on this.

00:28:23.460 --> 00:28:27.740
[Guest]: And one of the one of the main issues that's coming up is exclusion.

00:28:27.740 --> 00:28:31.940
[Guest]: So you know, I'm a ghost right now and I'm assuming so are you because neither of us

00:28:31.940 --> 00:28:32.940
[Amit Varma]: have either.

00:28:32.940 --> 00:28:33.940
[Amit Varma]: Exist.

00:28:33.940 --> 00:28:34.940
[Amit Varma]: Exactly.

00:28:34.940 --> 00:28:40.420
[Guest]: And the problem right now is that for a lot of people, especially in Rajasthan and Jharkhand

00:28:40.420 --> 00:28:49.580
[Guest]: where it's been made mandatory to the greatest extent for getting welfare, old people, daily

00:28:49.580 --> 00:28:57.100
[Guest]: wage laborers whose fingerprints either change or don't work or there isn't sufficient connectivity,

00:28:57.100 --> 00:28:59.180
[Guest]: they're not getting their welfare.

00:28:59.180 --> 00:29:04.220
[Guest]: So and there are people, instances of people who have died because they haven't gotten

00:29:04.220 --> 00:29:05.220
[Guest]: it.

00:29:05.220 --> 00:29:11.860
[Guest]: Think of an 80 year old woman who had to now has to go 20 kilometers to authenticate with

00:29:11.860 --> 00:29:15.820
[Guest]: her fingerprints that may or may not work and then therefore has to go repeatedly.

00:29:15.820 --> 00:29:21.060
[Guest]: Whereas earlier she could have given her ration card to a neighbor to go and get that.

00:29:21.060 --> 00:29:24.900
[Guest]: Now and there was pilferage that was taking place earlier.

00:29:24.900 --> 00:29:29.260
[Guest]: But there are also instances emerging in news reports of people, you know, for whom the

00:29:29.260 --> 00:29:35.940
[Guest]: fingerprint authentication has failed based on what the person who's giving rations is

00:29:35.940 --> 00:29:36.940
[Guest]: saying.

00:29:36.940 --> 00:29:41.540
[Guest]: And what they found is that that authentication actually worked and the rations were essentially

00:29:41.540 --> 00:29:42.740
[Guest]: pilfered out.

00:29:42.740 --> 00:29:48.900
[Guest]: So it's not really affecting pilferage or stealing of rations as much because you may

00:29:48.900 --> 00:29:55.440
[Guest]: have authentication that's taking place but you're not able to address quantity theft.

00:29:55.440 --> 00:30:00.260
[Guest]: So as an effective mechanism, it's not really working and even the numbers that they're

00:30:00.260 --> 00:30:02.380
[Guest]: talking about have been overstated.

00:30:02.380 --> 00:30:08.300
[Guest]: We've done detailed analysis, Anand Venkatanayanan is a person who's done detailed analysis on

00:30:08.300 --> 00:30:13.620
[Guest]: how the numbers are overstated by thousands of multiples, I mean, where it might be about

00:30:13.620 --> 00:30:20.180
[Guest]: 150 crore in savings is being posited as 49,000 crores of savings or something like that.

00:30:20.180 --> 00:30:25.460
[Guest]: So again, because there is lack of transparency from the government and because there's also

00:30:25.460 --> 00:30:31.100
[Guest]: attribution to Aadhaar where it shouldn't exist, for example, in case of West Bengal,

00:30:31.100 --> 00:30:35.660
[Guest]: ghosts and fakes were effectively removed through door-to-door surveys.

00:30:35.660 --> 00:30:39.300
[Guest]: But the savings from what we understand are being attributed to Aadhaar.

00:30:39.300 --> 00:30:44.620
[Guest]: So it's essentially, right now the system is geared up towards doing anything possible

00:30:44.620 --> 00:30:45.620
[Guest]: to save Aadhaar.

00:30:45.620 --> 00:30:50.340
[Amit Varma]: And again, within the welfare delivery system, it's had the effect of empowering the rent-seekers,

00:30:50.340 --> 00:30:52.620
[Amit Varma]: which is the opposite effect that you'd want.

00:30:52.620 --> 00:30:57.280
[Amit Varma]: But you know, just more than that, you know, people have died because they haven't got

00:30:57.280 --> 00:31:00.220
[Amit Varma]: admission to hospitals because the people demanded an Aadhaar card.

00:31:00.220 --> 00:31:02.020
[Amit Varma]: We've heard horror stories like that.

00:31:02.020 --> 00:31:03.580
[Amit Varma]: And there is a moral cost to that.

00:31:03.580 --> 00:31:08.700
[Amit Varma]: And it infuriates me that people sitting in air-conditioned cabins in Delhi treat this

00:31:08.700 --> 00:31:12.740
[Amit Varma]: as collateral damage, you know, much as it did during demonetization.

00:31:12.740 --> 00:31:16.660
[Amit Varma]: Talking about vague long-term benefits while there is actual suffering happening on the

00:31:16.660 --> 00:31:17.660
[Guest]: ground.

00:31:17.660 --> 00:31:26.700
[Guest]: But I think that's kind of the state of political discourse today, that growth at any cost and

00:31:26.700 --> 00:31:31.100
[Guest]: people are being seen as collateral damage and you're trying to digitize the economy

00:31:31.100 --> 00:31:32.940
[Guest]: by forcing people into it.

00:31:32.940 --> 00:31:39.740
[Guest]: See, I'm, I'm someone who loves tech, I've covered the space for 12 years, love the internet.

00:31:39.740 --> 00:31:43.820
[Guest]: I've always been idealistic about the role that technology can play in the sense, even

00:31:43.820 --> 00:31:52.220
[Guest]: Medianama is built on this idea that our role is to help enable an open, fair and competitive

00:31:52.220 --> 00:31:53.740
[Guest]: digital ecosystem in the country.

00:31:53.740 --> 00:31:55.580
[Guest]: So I love the space.

00:31:55.580 --> 00:32:02.380
[Guest]: But really what turned my thinking around Aadhaar was this, this was around demonetization

00:32:02.380 --> 00:32:07.340
[Guest]: and digital payments and when people were primarily talking about forcing change upon

00:32:07.340 --> 00:32:14.320
[Guest]: the country, almost like it being, so, you know, I likened it to white man's burden as

00:32:14.320 --> 00:32:19.820
[Guest]: digital man's burden, that it is the role of the digitally enabled to force everyone

00:32:19.820 --> 00:32:21.820
[Guest]: to become digitally enabled.

00:32:21.820 --> 00:32:25.140
[Guest]: And that's not the, that's not how I became digitally enabled.

00:32:25.140 --> 00:32:27.880
[Guest]: It was by choice, it was his agency.

00:32:27.880 --> 00:32:33.080
[Guest]: And so there's a philosophical shift that has taken place where those who've benefited

00:32:33.080 --> 00:32:37.740
[Guest]: from it feel that it's their job to force others to conform to it.

00:32:37.740 --> 00:32:42.620
[Guest]: And because it brings in efficiency and savings and power for them, but I think this is largely

00:32:42.620 --> 00:32:43.620
[Guest]: about power.

00:32:43.620 --> 00:32:49.380
[Amit Varma]: And it's very interesting, you'll hear supporters of Prime Minister Modi talking about how they

00:32:49.380 --> 00:32:51.020
[Amit Varma]: hate communism and so on.

00:32:51.020 --> 00:32:53.900
[Amit Varma]: But all of this is right out of Chairman Mao's playbook.

00:32:53.900 --> 00:32:57.840
[Amit Varma]: You know, the mass coercion during the time of demonetization, the kind of social engineering

00:32:57.840 --> 00:33:03.540
[Amit Varma]: that is being attempted in various ways of which Aadhaar is a phenomenally powerful tool.

00:33:03.540 --> 00:33:08.380
[Guest]: Well, if you if you look at the removal of agency, the one aspect that really stands

00:33:08.380 --> 00:33:15.720
[Guest]: out is in the Aadhaar Act, where if your data gets stolen, you can't go to court.

00:33:15.720 --> 00:33:16.720
[Guest]: My God.

00:33:16.720 --> 00:33:21.300
[Guest]: So the law disables you from going to court, only the UIDAI can go to court.

00:33:21.300 --> 00:33:26.340
[Guest]: Now, why would the UIDAI go to court against another government department?

00:33:26.340 --> 00:33:30.060
[Guest]: So far, they've only gone to court against journalists and researchers who've pointed

00:33:30.060 --> 00:33:37.940
[Guest]: out issues with Aadhaar, which is again a wrong thing to do, because it shoots the messenger.

00:33:37.940 --> 00:33:43.380
[Guest]: But they've not gone to court against at least 216 websites that were publishing Aadhaar

00:33:43.380 --> 00:33:48.180
[Guest]: information, even though the Aadhaar Act doesn't allow it.

00:33:48.180 --> 00:33:51.340
[Amit Varma]: And the thing is, you should have, if your rights are infringed, you should be able to

00:33:51.340 --> 00:33:53.180
[Guest]: go to court on your own behalf.

00:33:53.180 --> 00:33:58.660
[Guest]: It's not just that, what, what that system, if you're able to go to court, it helps correct

00:33:58.660 --> 00:33:59.660
[Guest]: the system.

00:33:59.660 --> 00:34:00.660
[Guest]: Right.

00:34:00.660 --> 00:34:06.000
[Guest]: So effectively, Aadhaar is not going to get fixed unless someone goes to court.

00:34:06.000 --> 00:34:10.540
[Guest]: If your data gets stolen, and you go to court, it forces people to make the systems more

00:34:10.540 --> 00:34:13.300
[Guest]: secure because they might get fined or someone might get jailed.

00:34:13.300 --> 00:34:15.340
[Guest]: But now those incentives don't exist.

00:34:15.340 --> 00:34:16.340
[Guest]: Exactly.

00:34:16.340 --> 00:34:21.780
[Guest]: So, so, so that's, and I think from what I remember, when, when Ravi Shankar Prasad,

00:34:21.780 --> 00:34:26.620
[Guest]: the IT minister was asked about this in Parliament, I think he said that, you know, if we do that,

00:34:26.620 --> 00:34:31.380
[Guest]: then there would be too many cases, which is almost an admission of a problem.

00:34:31.380 --> 00:34:37.100
[Amit Varma]: Yeah, which also indicates his government's unceasing focus on optics.

00:34:37.100 --> 00:34:38.460
[Amit Varma]: They don't care what really happens.

00:34:38.460 --> 00:34:41.220
[Amit Varma]: They just care how it's reported.

00:34:41.220 --> 00:34:44.900
[Guest]: Well, I don't know about that aspect of it.

00:34:44.900 --> 00:34:48.500
[Guest]: But from one of the things that I've noticed is that there's also a great deal of lying

00:34:48.500 --> 00:34:54.020
[Guest]: that's going on, like this constant refrain that there has been no breach.

00:34:54.020 --> 00:34:55.620
[Guest]: And that's optics effectively, right?

00:34:55.620 --> 00:34:59.980
[Guest]: But the fact is that a breach is unauthorized access.

00:34:59.980 --> 00:35:05.300
[Guest]: So if Rasna Khera of the Tribune was able to get unauthorized access to the Aadhaar

00:35:05.300 --> 00:35:11.460
[Guest]: database by paying 500 bucks to someone, that is a breach.

00:35:11.460 --> 00:35:18.940
[Guest]: You know, if let's say Abhinav Srivastava, a developer in Bangalore, was able to access

00:35:18.940 --> 00:35:25.180
[Guest]: the Aadhaar database, because NIC, a government body was running access to it on HTTP instead

00:35:25.180 --> 00:35:26.180
[Guest]: of HTTPS.

00:35:26.180 --> 00:35:31.700
[Guest]: And it's a non secure connection, which can effectively data can be taken from that.

00:35:31.700 --> 00:35:33.220
[Guest]: That is a breach.

00:35:33.220 --> 00:35:38.220
[Guest]: If biometrics have been cloned or being sold, that is a breach.

00:35:38.220 --> 00:35:43.060
[Guest]: So you know, I think by denying that there's a problem, we're not going to solve it.

00:35:43.060 --> 00:35:48.340
[Guest]: Because, you know, if you think about it from a governance standpoint, the first part of

00:35:48.340 --> 00:35:55.180
[Guest]: the solution is to accept that there's a problem, then it is to involve the right minded stakeholders

00:35:55.180 --> 00:36:00.940
[Guest]: in trying to figure out the source of the problem, trying to find out the solution.

00:36:00.940 --> 00:36:08.260
[Guest]: And it and then solving it, and also informing about solving it and bringing in processes

00:36:08.260 --> 00:36:12.900
[Guest]: of transparency, so that there is accountability in the future.

00:36:12.900 --> 00:36:14.700
[Guest]: None of this is happening right now.

00:36:14.700 --> 00:36:19.220
[Guest]: And so we're just digging ourselves a deeper hole by denying that the problem exists.

00:36:19.220 --> 00:36:23.460
[Guest]: So you know, another part of the problem with the way Aadhaar is being run is that there

00:36:23.460 --> 00:36:25.940
[Guest]: is no monitoring mechanism.

00:36:25.940 --> 00:36:32.380
[Guest]: There is only there's only an audit mechanism, which means that someone has to do an audit

00:36:32.380 --> 00:36:33.620
[Guest]: to find a problem.

00:36:33.620 --> 00:36:38.940
[Guest]: Now, nobody seems to be doing that audit because journalists and researchers are finding problems,

00:36:38.940 --> 00:36:41.740
[Guest]: and the UIDA goes and sues them for it.

00:36:41.740 --> 00:36:47.980
[Guest]: If that problem hadn't been reported by a news agency, the UIDA probably would never

00:36:47.980 --> 00:36:50.140
[Guest]: have known about it and the leaks would have kept happening.

00:36:50.140 --> 00:36:54.180
[Amit Varma]: And you're actually disincentivizing people from finding the problems in the system you're

00:36:54.180 --> 00:36:55.180
[Amit Varma]: supposed to run.

00:36:55.180 --> 00:36:56.180
[Guest]: Absolutely.

00:36:56.180 --> 00:37:01.660
[Guest]: But more, I mean, it's just as important to remember, if there is a problem, and nobody

00:37:01.660 --> 00:37:08.060
[Guest]: reports it, going back to your tree falls in a forest example, who knows, there is probably

00:37:08.060 --> 00:37:11.380
[Guest]: data leaking everywhere that we don't even know about.

00:37:11.380 --> 00:37:15.860
[Guest]: So that's why you have researchers, there's some anonymous Twitter handle called F society

00:37:15.860 --> 00:37:24.180
[Guest]: right now that is, that's effectively, constantly, almost on a daily basis pointing out issues

00:37:24.180 --> 00:37:25.980
[Guest]: with Aadhaar.

00:37:25.980 --> 00:37:28.860
[Guest]: Because an anonymous handle probably has a better chance of doing that.

00:37:28.860 --> 00:37:32.860
[Guest]: Because if an Indian handled it, they'd probably get sued or they get put in jail.

00:37:32.860 --> 00:37:33.860
[Amit Varma]: Yeah.

00:37:33.860 --> 00:37:38.020
[Amit Varma]: So I have a sneaky feeling that anonymous handle is also a ghost like us.

00:37:38.020 --> 00:37:47.660
[Guest]: No, but, you know, so going back to the agency issue, the UIDA under the Aadhaar Act can

00:37:47.660 --> 00:37:52.540
[Guest]: also cancel your Aadhaar number for any reason they may deem necessary.

00:37:52.540 --> 00:37:54.500
[Guest]: And do you have recourse, can you go to court?

00:37:54.500 --> 00:37:57.660
[Guest]: I'm not sure about the recourse part.

00:37:57.660 --> 00:38:00.860
[Guest]: Because if you think about it, only the UIDA can go to court.

00:38:00.860 --> 00:38:01.860
[Amit Varma]: Yeah.

00:38:01.860 --> 00:38:05.580
[Amit Varma]: And also only even if everyone could go to court, only the incredibly privileged people

00:38:05.580 --> 00:38:08.940
[Amit Varma]: like us would actually be able to do so at a practical level.

00:38:08.940 --> 00:38:11.220
[Amit Varma]: Most people in this country, they don't really have that option.

00:38:11.220 --> 00:38:15.460
[Guest]: I mean, but you know, they also don't have it easy even getting an Aadhaar number.

00:38:15.460 --> 00:38:22.420
[Guest]: So you know, you've seen instances of enrollment agencies because of the atmosphere of desperation

00:38:22.420 --> 00:38:29.300
[Guest]: that has been created by the government, having to pay bribes to get an Aadhaar number.

00:38:29.300 --> 00:38:33.780
[Guest]: It's supposed to be very cheap, but the people who've had to pay 300, 500, 1000 bucks to

00:38:33.780 --> 00:38:35.540
[Guest]: get an Aadhaar number.

00:38:35.540 --> 00:38:40.620
[Guest]: And this is essentially rent seeking that's happening at an enrollment level right now.

00:38:40.620 --> 00:38:46.220
[Guest]: There will probably be rent seeking that will happen if you need to get some data changed.

00:38:46.220 --> 00:38:49.820
[Guest]: So we don't know where this is going, but really that's where the corruption has come

00:38:49.820 --> 00:38:50.820
[Guest]: in.

00:38:50.820 --> 00:38:54.900
[Guest]: If you look at it, Aadhaar has effectively enabled corruption at that level, even though

00:38:54.900 --> 00:38:58.220
[Guest]: the state may not see it as that.

00:38:58.220 --> 00:39:00.580
[Amit Varma]: I mean, as the old saying goes, power corrupts.

00:39:00.580 --> 00:39:03.580
[Amit Varma]: So the more power you give, the more corruption you will have.

00:39:03.580 --> 00:39:05.660
[Amit Varma]: That's a truism.

00:39:05.660 --> 00:39:07.740
[Guest]: What else is in your laundry list?

00:39:07.740 --> 00:39:14.220
[Guest]: So one of the things is that the people who've already been compromised forever.

00:39:14.220 --> 00:39:18.380
[Guest]: And so that's one of the problems I have with Aadhaar, that the leaks have happened at such

00:39:18.380 --> 00:39:23.340
[Guest]: a large scale that we really don't know what to do about it.

00:39:23.340 --> 00:39:31.500
[Guest]: So if someone's actual information about their bank account number, Aadhaar number, religion,

00:39:31.500 --> 00:39:38.780
[Guest]: address, date of birth, father's name slash husband's name, if all of that identifiable

00:39:38.780 --> 00:39:44.060
[Guest]: information that can be used to compromise them has been put in the public domain or

00:39:44.060 --> 00:39:48.260
[Guest]: has been leaked, how do you protect them?

00:39:48.260 --> 00:39:49.260
[Guest]: What do you do for them?

00:39:49.260 --> 00:39:52.180
[Guest]: They're compromised for the rest of their lives.

00:39:52.180 --> 00:39:53.180
[Amit Varma]: That ship has sailed.

00:39:53.180 --> 00:39:54.180
[Guest]: They're just unlucky.

00:39:54.180 --> 00:39:55.180
[Guest]: They can't do anything.

00:39:55.180 --> 00:39:57.900
[Guest]: I'd love suggestions on how we can fix that now.

00:39:57.900 --> 00:39:59.780
[Guest]: I don't know.

00:39:59.780 --> 00:40:04.500
[Guest]: So the way I look at it is that this is an increasing problem.

00:40:04.500 --> 00:40:10.660
[Guest]: And we need to suspend Aadhaar right now to mitigate the problem.

00:40:10.660 --> 00:40:12.620
[Guest]: I don't know if we can solve it.

00:40:12.620 --> 00:40:16.260
[Guest]: But at least for the time being, we need to recheck our processes.

00:40:16.260 --> 00:40:19.220
[Guest]: We need to figure out where all the leaks are happening.

00:40:19.220 --> 00:40:23.100
[Guest]: And you can't do that with an ongoing system because, you know, it's like you plug one

00:40:23.100 --> 00:40:25.700
[Guest]: hole and then you suddenly realize there's another one, there's another one, there's

00:40:25.700 --> 00:40:27.140
[Guest]: another one.

00:40:27.140 --> 00:40:28.580
[Amit Varma]: This is not something that can be done live.

00:40:28.580 --> 00:40:31.540
[Amit Varma]: First you plug all the holes, then you think about repairing the wall at a fundamental

00:40:31.540 --> 00:40:32.540
[Guest]: level.

00:40:32.540 --> 00:40:33.540
[Guest]: Right.

00:40:33.540 --> 00:40:37.380
[Guest]: And that's what, so we first need to suspend the project and figure out where all the problems

00:40:37.380 --> 00:40:38.380
[Guest]: lie.

00:40:38.380 --> 00:40:44.540
[Guest]: You know, so I also mentioned about not being able to count the fakes in the Aadhaar system

00:40:44.540 --> 00:40:51.700
[Guest]: because there is no way of knowing if you've created a fake Aadhaar number or an ID.

00:40:51.700 --> 00:40:52.700
[Guest]: You will never know.

00:40:52.700 --> 00:41:00.740
[Guest]: In fact, you can essentially take a photo of an Aadhaar card, put in any random number,

00:41:00.740 --> 00:41:04.940
[Guest]: put in your photograph, put in any random name and it's an Aadhaar card.

00:41:04.940 --> 00:41:09.660
[Guest]: And most people will accept it as a proof of identification because of the environment

00:41:09.660 --> 00:41:13.660
[Guest]: that we've created where it's acceptable.

00:41:13.660 --> 00:41:21.180
[Guest]: So you know, in most countries they have chips and that chip is a means of authentication.

00:41:21.180 --> 00:41:26.180
[Guest]: You can't really put in a fingerprint scanner everywhere and I don't think people should

00:41:26.180 --> 00:41:30.460
[Guest]: be going and scanning their fingerprints everywhere because it's so easy to clone fingerprints.

00:41:30.460 --> 00:41:34.620
[Guest]: Like you know, someone can just place a machine before you, you put your fingerprint, you

00:41:34.620 --> 00:41:38.340
[Guest]: put your thumb on it and they say, oh, this one didn't work and they put another one and

00:41:38.340 --> 00:41:39.340
[Amit Varma]: that works.

00:41:39.340 --> 00:41:40.340
[Amit Varma]: Yeah.

00:41:40.340 --> 00:41:41.340
[Amit Varma]: And they could have just cloned it for the first one.

00:41:41.340 --> 00:41:43.420
[Guest]: It's the same thing with credit cards, the way you clone it, yeah.

00:41:43.420 --> 00:41:49.500
[Guest]: So the other problem is that 15 states have already taken copies of the Aadhaar database

00:41:49.500 --> 00:41:55.180
[Guest]: under something called the SRDH or the State Resident Data Hubs.

00:41:55.180 --> 00:42:00.140
[Guest]: Now in Andhra, what we've seen is that all sorts of information is being linked to it.

00:42:00.140 --> 00:42:04.820
[Guest]: So you know, the UIDA and Ravi Shankar Prasad have gone out and said that we're only collecting

00:42:04.820 --> 00:42:08.900
[Guest]: demographic data, which you would give to your bank or your mobile operator and stuff

00:42:08.900 --> 00:42:09.900
[Guest]: like that.

00:42:09.900 --> 00:42:15.140
[Guest]: But at the state level, they're linking stuff like traffic violations to it.

00:42:15.140 --> 00:42:20.220
[Guest]: They're linking property records, petty crimes information, and this is happening in case

00:42:20.220 --> 00:42:22.140
[Guest]: of Andhra Pradesh.

00:42:22.140 --> 00:42:28.500
[Guest]: Now what you develop effectively over a period of time when you start collecting and linking

00:42:28.500 --> 00:42:34.580
[Guest]: all of this information is you get a 360 degree profile of each single individual.

00:42:34.580 --> 00:42:39.860
[Guest]: And that kind of data in the hands of a state is very dangerous, you know, because historically

00:42:39.860 --> 00:42:46.020
[Guest]: even income tax records have been out of bounds for other government departments.

00:42:46.020 --> 00:42:51.260
[Guest]: So the silos that existed, which protected us, are now being broken through the creation

00:42:51.260 --> 00:42:54.080
[Guest]: of the centralized database.

00:42:54.080 --> 00:42:59.420
[Guest]: And so the scale of the problems that this is going to cause is something we don't even

00:42:59.420 --> 00:43:00.420
[Guest]: realize right now.

00:43:00.420 --> 00:43:04.500
[Guest]: It's difficult to comprehend because there are also no checks and balances in place.

00:43:04.500 --> 00:43:10.460
[Guest]: So many of these states don't have a state level Aadhaar Act to regulate the collection

00:43:10.460 --> 00:43:12.500
[Guest]: and sharing of this information.

00:43:12.500 --> 00:43:19.340
[Guest]: Now one argument that UIDA is making is that the Aadhaar Act also applies to the states,

00:43:19.340 --> 00:43:23.180
[Guest]: where the states already have collected way more information than the Aadhaar Act allows

00:43:23.180 --> 00:43:26.660
[Guest]: the central government to take.

00:43:26.660 --> 00:43:31.900
[Guest]: So the ambiguity is actually there right now to be misused.

00:43:31.900 --> 00:43:36.700
[Amit Varma]: And just thinking aloud, the political repercussions of this on our democracy can be staggering.

00:43:36.700 --> 00:43:41.700
[Amit Varma]: I mean, just to take two examples, in 1984, we now know that a lot of the rioters had

00:43:41.700 --> 00:43:47.340
[Amit Varma]: electoral rolls, by which they identified which house the people they wanted to victimize

00:43:47.340 --> 00:43:51.900
[Amit Varma]: lived in and they just went door to door to those houses and, you know, and that is just

00:43:51.900 --> 00:43:55.140
[Amit Varma]: a very limited set of data and the damage it caused.

00:43:55.140 --> 00:44:02.580
[Amit Varma]: And equally, you saw recently how T-Star Settle Wards credit card details were leaked out

00:44:02.580 --> 00:44:06.500
[Amit Varma]: at a government press conference where they said that, listen, this woman spent her, used

00:44:06.500 --> 00:44:10.940
[Amit Varma]: her credit card to buy alcohol, as if buying alcohol is a crime.

00:44:10.940 --> 00:44:14.700
[Amit Varma]: And the fact is that data should not have been out there.

00:44:14.700 --> 00:44:17.620
[Guest]: Exactly in what right does a government have to release that data in the first place?

00:44:17.620 --> 00:44:18.620
[Amit Varma]: Exactly.

00:44:18.620 --> 00:44:21.700
[Guest]: I mean, they should have the data and if they have it, you know.

00:44:21.700 --> 00:44:26.980
[Guest]: So that affects the opposition in a democracy.

00:44:26.980 --> 00:44:28.860
[Amit Varma]: And it has a chilling effect on the opposition as well.

00:44:28.860 --> 00:44:32.660
[Amit Varma]: If you know your bank account can be freezed, if your entire life can be shut down.

00:44:32.660 --> 00:44:35.300
[Guest]: Well, look at it from another perspective, right?

00:44:35.300 --> 00:44:39.100
[Guest]: The beauty of digital is that the data is digital.

00:44:39.100 --> 00:44:41.180
[Guest]: And so therefore, the data can be manipulated.

00:44:41.180 --> 00:44:42.180
[Guest]: Exactly.

00:44:42.180 --> 00:44:47.460
[Guest]: So if, let's say, there's a murder that's taken place three, four kilometers from here,

00:44:47.460 --> 00:44:49.460
[Guest]: how do I know that Amit wasn't there?

00:44:49.460 --> 00:44:55.500
[Guest]: If his location data puts him there, if he's done a credit card transaction in the same

00:44:55.500 --> 00:44:59.280
[Guest]: building at some stop on the ground floor, right?

00:44:59.280 --> 00:45:00.280
[Amit Varma]: So these are things...

00:45:00.280 --> 00:45:03.220
[Amit Varma]: You think you're giving ideas that will get me into trouble, buddy, you've got more enemies

00:45:03.220 --> 00:45:05.220
[Amit Varma]: than I do right now.

00:45:05.220 --> 00:45:12.220
[Guest]: Well, so just going back to that last example, the other thing you have to keep in mind in

00:45:12.220 --> 00:45:18.740
[Guest]: terms of the databases that get created is that there is no control that the UIDAI has

00:45:18.740 --> 00:45:21.260
[Guest]: on private databases.

00:45:21.260 --> 00:45:26.460
[Guest]: So through this AKYC mechanism, which is why I started off by saying that this is the conversion

00:45:26.460 --> 00:45:32.160
[Guest]: of personal data into a public asset, and then privatized, is that private agencies

00:45:32.160 --> 00:45:38.340
[Guest]: are now and private entities are now creating their own databases built on this information.

00:45:38.340 --> 00:45:42.540
[Guest]: And so what we saw, for example, in case of Reliance Jio and the data that had leaked

00:45:42.540 --> 00:45:49.820
[Guest]: last year, was that someone launched a site called magicapk.com, because there was a vulnerability

00:45:49.820 --> 00:45:55.940
[Guest]: at some vendors database, I mean, this is what I read in the news reports, at some vendors

00:45:55.940 --> 00:46:00.260
[Guest]: code side that Jio had given them access to.

00:46:00.260 --> 00:46:03.980
[Guest]: They started a site where you had to put in a mobile number and they would give you demographic

00:46:03.980 --> 00:46:04.980
[Guest]: details.

00:46:04.980 --> 00:46:08.920
[Guest]: Now, the Aadhaar number area in that was kept blank.

00:46:08.920 --> 00:46:13.180
[Guest]: So I'm not sure whether they had access to it or not, but who's to say that there won't

00:46:13.180 --> 00:46:18.140
[Guest]: be other players that might actually store that and add more information?

00:46:18.140 --> 00:46:23.580
[Guest]: And how does a UIDAI keep this data secure after it has left the UIDAI?

00:46:23.580 --> 00:46:27.040
[Guest]: See, when you do a credit card transaction, you know that, you know, Amazon sometimes

00:46:27.040 --> 00:46:32.060
[Guest]: stores your card, you can allow, sorry, you can allow Amazon to store your card details.

00:46:32.060 --> 00:46:38.300
[Guest]: But Amazon goes through this compliance mechanism called PCI DSS, which is a data security standard

00:46:38.300 --> 00:46:43.220
[Guest]: that it has to follow in order to be allowed to store the data.

00:46:43.220 --> 00:46:47.940
[Guest]: In case of Aadhaar, I don't know if there is a mechanism to actually check whether people

00:46:47.940 --> 00:46:50.820
[Guest]: are maintaining certain data security standards or not.

00:46:50.820 --> 00:46:58.260
[Guest]: And given the way NIC has given access to the database on HTTP, and NIC is both an AUA,

00:46:58.260 --> 00:47:05.020
[Guest]: which is an Aadhaar user agency and a KUA, which is a KYC user agency, which again can

00:47:05.020 --> 00:47:07.860
[Guest]: share demographic information.

00:47:07.860 --> 00:47:10.740
[Guest]: I don't think it's following the protocols, but it's a government body, so I don't know

00:47:10.740 --> 00:47:12.700
[Guest]: what the government is going to do about it.

00:47:12.700 --> 00:47:15.580
[Guest]: Is it going to cancel the license of another government body?

00:47:15.580 --> 00:47:16.580
[Amit Varma]: Highly unlikely.

00:47:16.580 --> 00:47:21.980
[Amit Varma]: So this is damn confusing, because I see like two contradictory dystopian situations.

00:47:21.980 --> 00:47:26.140
[Amit Varma]: One situation is that we have a government which is so inept that it is messing everything

00:47:26.140 --> 00:47:28.300
[Amit Varma]: up and is making a mess of the whole thing.

00:47:28.300 --> 00:47:33.660
[Amit Varma]: But the other dystopian situation is that if you really look at it, this is if you wanted

00:47:33.660 --> 00:47:38.860
[Amit Varma]: to be a totalitarian state with everyone's data under your control and everyone's, you

00:47:38.860 --> 00:47:44.420
[Amit Varma]: know, life one fingertip away from destruction, this is a masterful way of doing it.

00:47:44.420 --> 00:47:48.300
[Amit Varma]: Which do you think is more true?

00:47:48.300 --> 00:47:51.540
[Guest]: I'm not going to second guess in terms of intent of the government.

00:47:51.540 --> 00:47:52.540
[Amit Varma]: Fair enough.

00:47:52.540 --> 00:47:53.540
[Amit Varma]: So I don't know.

00:47:53.540 --> 00:47:56.460
[Amit Varma]: That is somewhat the effect that it's ending up having anyway.

00:47:56.460 --> 00:48:01.020
[Amit Varma]: They have all the data, they have complete control, and they have it in extra quick time.

00:48:01.020 --> 00:48:05.300
[Guest]: Look, and it is not to say that the intent was bad when it began from that perspective,

00:48:05.300 --> 00:48:06.300
[Guest]: right?

00:48:06.300 --> 00:48:08.060
[Guest]: Because we can't, we don't know what the intent was.

00:48:08.060 --> 00:48:12.540
[Guest]: Like I'm someone who supported Aadhaar when it started, because I saw the massive benefits

00:48:12.540 --> 00:48:17.980
[Guest]: it would bring in if the KYC costs would be taken on by the government.

00:48:17.980 --> 00:48:23.100
[Guest]: Because at that point, I remember Nokia had done some presentation which talked about

00:48:23.100 --> 00:48:30.020
[Guest]: the cost of authenticating each individual was about 270 rupees.

00:48:30.020 --> 00:48:33.460
[Guest]: And therefore that is a massive cost if you want to bring everyone into the financial

00:48:33.460 --> 00:48:34.460
[Guest]: system.

00:48:34.460 --> 00:48:42.220
[Guest]: Now, the government through Aadhaar was taking on that cost, so that you would have financial

00:48:42.220 --> 00:48:43.700
[Guest]: inclusion that comes in.

00:48:43.700 --> 00:48:45.780
[Guest]: That's a great idea.

00:48:45.780 --> 00:48:51.980
[Guest]: But the beast that it has become on top of that, and the repercussions of collection

00:48:51.980 --> 00:48:56.340
[Guest]: of personal information is something which many of us had not considered.

00:48:56.340 --> 00:49:00.380
[Guest]: Which is why under the BJP, under Yashwant Sinha, there was this great Parliamentary

00:49:00.380 --> 00:49:05.220
[Guest]: Standing Committee report that came out, which pointed towards all of these issues.

00:49:05.220 --> 00:49:10.700
[Guest]: Which brings me to my last point, which again, we learned from that particular report, which

00:49:10.700 --> 00:49:14.940
[Guest]: was about biometrics being an inexact science.

00:49:14.940 --> 00:49:20.940
[Guest]: So there are always going to be people who will be excluded, because biometrics are a

00:49:20.940 --> 00:49:24.660
[Guest]: probabilistic means of authentication.

00:49:24.660 --> 00:49:28.620
[Guest]: So there will always be false negatives and false positives, which is that there will

00:49:28.620 --> 00:49:33.860
[Guest]: be people whose fingerprint is correct, but that they're going to get rejected.

00:49:33.860 --> 00:49:38.340
[Guest]: And there are people whose fingerprints do not match, but they will be accepted.

00:49:38.340 --> 00:49:46.340
[Guest]: And so, I'd like to see the government actually make Aadhaar mandatory for boarding a flight.

00:49:46.340 --> 00:49:48.940
[Guest]: Because there will always be someone who will be rejected.

00:49:48.940 --> 00:49:54.560
[Guest]: And the elitism problem that we have in terms of technologists talking about how probabilistic

00:49:54.560 --> 00:50:00.380
[Guest]: science is fine, when those guys get denied flights because the fingerprint doesn't match,

00:50:00.380 --> 00:50:03.180
[Guest]: I think they'll start thinking about things a little differently.

00:50:03.180 --> 00:50:06.940
[Guest]: I don't think for them it really matters that the people who are not able to get their daily

00:50:06.940 --> 00:50:12.180
[Guest]: rations or their monthly rations, and the people who are starving because of problems

00:50:12.180 --> 00:50:15.700
[Guest]: with Aadhaar, because it's not impacting them personally.

00:50:15.700 --> 00:50:17.620
[Amit Varma]: But let's make it mandatory for flights and see what happens.

00:50:17.620 --> 00:50:19.980
[Amit Varma]: And also in this context, you can't talk probabilities.

00:50:19.980 --> 00:50:23.540
[Amit Varma]: I mean, the duty of the state is to protect every single citizen.

00:50:23.540 --> 00:50:28.700
[Amit Varma]: You can't exclude anybody to say that a 0.0 whatever percentage is not on, it has to be

00:50:28.700 --> 00:50:29.700
[Guest]: zero.

00:50:29.700 --> 00:50:30.700
[Guest]: No, no.

00:50:30.700 --> 00:50:32.820
[Amit Varma]: So there is always going to be exclusion.

00:50:32.820 --> 00:50:36.060
[Amit Varma]: Because biometrics are fundamentally flawed.

00:50:36.060 --> 00:50:42.540
[Guest]: Because biometrics change, because your fingerprints get worn out, because as you age, they change.

00:50:42.540 --> 00:50:50.980
[Guest]: So you know, where effectively, this idea of having a probabilistic authentication,

00:50:50.980 --> 00:50:55.300
[Guest]: but also a permanent mode of authentication with biometrics, which can be compromised,

00:50:55.300 --> 00:50:57.040
[Guest]: is just bizarre.

00:50:57.040 --> 00:51:03.140
[Guest]: Because if by the way, if there is 100% match, there's probably a fake biometric being used.

00:51:03.140 --> 00:51:05.380
[Amit Varma]: So the whole edifice falls apart on this basically.

00:51:05.380 --> 00:51:08.460
[Amit Varma]: So tell me this, you've, you've outlined a number of problems.

00:51:08.460 --> 00:51:11.500
[Amit Varma]: And I think any one of them on their own is a disqualifier by itself.

00:51:11.500 --> 00:51:13.940
[Amit Varma]: And together, they're quite overwhelming.

00:51:13.940 --> 00:51:18.620
[Amit Varma]: But what are the sort of solutions that you think are possible going forward?

00:51:18.620 --> 00:51:22.920
[Guest]: So one is an easy one, which is make it voluntary.

00:51:22.920 --> 00:51:26.140
[Guest]: If you don't want one, you shouldn't have to get it.

00:51:26.140 --> 00:51:29.940
[Amit Varma]: Make it, make it mandatory, that ship is sail, right?

00:51:29.940 --> 00:51:33.460
[Amit Varma]: 900 million people already have it and a lot of the data has already leaked.

00:51:33.460 --> 00:51:35.620
[Guest]: So there's another solution.

00:51:35.620 --> 00:51:38.540
[Guest]: But the other one was make it optional.

00:51:38.540 --> 00:51:43.700
[Guest]: So Aadhaar should be one of the authentication mechanisms used one of many, so that people

00:51:43.700 --> 00:51:45.660
[Guest]: can then protect themselves.

00:51:45.660 --> 00:51:50.860
[Guest]: One is the idea of deprecating IDs, which is that, let's say if your passport changes

00:51:50.860 --> 00:51:53.300
[Guest]: and the passport number changes.

00:51:53.300 --> 00:51:57.980
[Guest]: So have Aadhaar deprecate over a period of time so that you have to go and get a new

00:51:57.980 --> 00:51:59.220
[Guest]: one that's a new number.

00:51:59.220 --> 00:52:02.260
[Guest]: So your, your, your exposure is limited from that perspective.

00:52:02.260 --> 00:52:04.260
[Amit Varma]: Or rather you can get a new one if you want to.

00:52:04.260 --> 00:52:06.260
[Guest]: If you want to, of course.

00:52:06.260 --> 00:52:13.660
[Guest]: One of many IDs in use for any kind of, any kind of authentication.

00:52:13.660 --> 00:52:19.300
[Guest]: The other is to give users control to change and revoke their IDs.

00:52:19.300 --> 00:52:22.860
[Guest]: So if I want to change my Aadhaar number, I should be able to change it.

00:52:22.860 --> 00:52:26.740
[Guest]: If I want to just cancel it and never use it again, I should have the freedom to do

00:52:26.740 --> 00:52:30.780
[Guest]: so because that also gives people agency.

00:52:30.780 --> 00:52:35.720
[Guest]: One technical solution which is also being used, I think in Denmark is the idea of using

00:52:35.720 --> 00:52:39.640
[Guest]: derived authentication or pseudonymization.

00:52:39.640 --> 00:52:44.540
[Guest]: So the UIDEA initially had this idea of having a virtual ID, which is going to be built on

00:52:44.540 --> 00:52:50.300
[Guest]: top of Aadhaar so that you give your, instead of giving Aadhaar number at places, you give

00:52:50.300 --> 00:52:51.980
[Guest]: another ID.

00:52:51.980 --> 00:52:56.220
[Guest]: Now the problem with the way they're implementing it is that they're only allowing one virtual

00:52:56.220 --> 00:52:58.500
[Guest]: ID at a time.

00:52:58.500 --> 00:53:02.700
[Guest]: And the likelihood is that people will not know how to revoke it or change it.

00:53:02.700 --> 00:53:06.900
[Guest]: And so their implementation is not that great, but let's say in case of UPI, which is the

00:53:06.900 --> 00:53:11.060
[Guest]: payments mechanism, with every app you can create a new ID.

00:53:11.060 --> 00:53:19.780
[Guest]: So your bank account doesn't get exposed and one single ID doesn't get exposed.

00:53:19.780 --> 00:53:23.600
[Guest]: You also need to give citizens a right to legal recourse.

00:53:23.600 --> 00:53:29.100
[Guest]: If I can go to court, then it forces the system to fix itself because there might be monetary

00:53:29.100 --> 00:53:34.340
[Guest]: damages on the government or a court ruling might force it to change.

00:53:34.340 --> 00:53:39.260
[Guest]: You need a purpose limitation for Aadhaar, which is that it should not be linked to or

00:53:39.260 --> 00:53:44.060
[Guest]: usable for sensitive personal information and you should have a limited use case for

00:53:44.060 --> 00:53:46.300
[Guest]: which it is allowed.

00:53:46.300 --> 00:53:51.940
[Guest]: So as not to create a situation where people overexpose themselves or give their Aadhaar

00:53:51.940 --> 00:53:57.900
[Guest]: number or help create databases at a lot of places.

00:53:57.900 --> 00:54:01.380
[Guest]: You know, no uses of biometrics whatsoever.

00:54:01.380 --> 00:54:02.700
[Guest]: That needs to go.

00:54:02.700 --> 00:54:07.900
[Guest]: And in fact, the biometric data that's been collected needs to be destroyed.

00:54:07.900 --> 00:54:11.780
[Guest]: Of course, one thing which for this, that ship has sailed, but what other countries

00:54:11.780 --> 00:54:15.940
[Guest]: that are looking at similar mechanisms can do is that they need to have a data protection

00:54:15.940 --> 00:54:19.740
[Guest]: law and a privacy law before rolling something like this out.

00:54:19.740 --> 00:54:24.140
[Guest]: We've obviously done things the wrong way here.

00:54:24.140 --> 00:54:30.340
[Guest]: We need money to be spent on an awareness campaign and a disproportionate amount of

00:54:30.340 --> 00:54:34.820
[Guest]: the budget needs to be on that awareness campaign so that people understand what to do, what

00:54:34.820 --> 00:54:35.820
[Guest]: not to do.

00:54:35.820 --> 00:54:41.660
[Guest]: They have a ready reckoner for how not to compromise themselves because there is clearly

00:54:41.660 --> 00:54:44.260
[Guest]: there's information asymmetry.

00:54:44.260 --> 00:54:46.060
[Guest]: Most people don't realize the impact that this has.

00:54:46.060 --> 00:54:49.660
[Guest]: These are some of the ideas that I have.

00:54:49.660 --> 00:54:55.780
[Guest]: The push for 100% is actually what is hurting us a lot right now, because in that push we

00:54:55.780 --> 00:55:00.820
[Guest]: are more focused on getting to 100% rather than building a system that works.

00:55:00.820 --> 00:55:05.100
[Amit Varma]: So tell me something, in your interactions with policy makers, with politicians, with

00:55:05.100 --> 00:55:08.700
[Amit Varma]: bureaucrats, how receptive have they all been to these ideas of yours?

00:55:08.700 --> 00:55:11.260
[Amit Varma]: Where is the opposition coming from?

00:55:11.260 --> 00:55:19.260
[Guest]: I think one is the sunk cost fallacy, that we spend so much money and therefore we can't

00:55:19.260 --> 00:55:24.420
[Guest]: destroy it now, which is why these are recommendations for fixing it rather than shelving it altogether

00:55:24.420 --> 00:55:31.060
[Guest]: because I think shelving it would be a better idea, but in the absence of that there needs

00:55:31.060 --> 00:55:36.980
[Guest]: to be a mechanism to fix it or at least limit the damage that gets caused.

00:55:36.980 --> 00:55:43.980
[Guest]: Most opposition members don't like this system because they are also worried about surveillance

00:55:43.980 --> 00:55:51.360
[Guest]: and exclusion is a very, very big problem that they are seeing in their own constituencies.

00:55:51.360 --> 00:55:55.300
[Guest]: One of the things again that I forgot to mention earlier about the problem with Aadhaar that

00:55:55.300 --> 00:55:58.380
[Guest]: it's become a national security risk.

00:55:58.380 --> 00:56:03.740
[Guest]: So they are also conscious of that because all this data available, accessible with such

00:56:03.740 --> 00:56:08.580
[Guest]: poor security in place compromises most citizens in this country.

00:56:08.580 --> 00:56:13.100
[Guest]: Like Aadhaar is the biggest honeypot that exists for any hacker to get into because

00:56:13.100 --> 00:56:17.620
[Guest]: effectively you can dismantle a country's financial system if you get access to all

00:56:17.620 --> 00:56:19.900
[Amit Varma]: of this data, one way or another.

00:56:19.900 --> 00:56:22.980
[Amit Varma]: Which seems fairly easy to do, I mean, given the protections in place.

00:56:22.980 --> 00:56:23.980
[Guest]: Exactly.

00:56:23.980 --> 00:56:30.340
[Guest]: So we have a, but at least from the government side, I don't think they're really engaging

00:56:30.340 --> 00:56:34.620
[Guest]: or they're talking much right now because for them they don't want to admit that there's

00:56:34.620 --> 00:56:38.340
[Guest]: a problem because that's the way politics currently works.

00:56:38.340 --> 00:56:41.820
[Guest]: No one wants to admit to having made a mistake.

00:56:41.820 --> 00:56:45.660
[Guest]: I'm not sure where the Congress stands on all of this because at one level you have

00:56:45.660 --> 00:56:51.140
[Guest]: Kapil Sibal arguing very well in court, I mean, pushing back against some provisions

00:56:51.140 --> 00:56:52.140
[Guest]: in Aadhaar.

00:56:52.140 --> 00:56:58.220
[Guest]: But at the same time you have the Karnataka Congress which is pushing an Aadhaar bill.

00:56:58.220 --> 00:57:04.540
[Guest]: So you know, I think there is, it's almost two-faced the way they're behaving.

00:57:04.540 --> 00:57:09.920
[Guest]: We don't have, no one has a solution right now or no one wants to even try for the solution

00:57:09.920 --> 00:57:11.340
[Guest]: by the looks of it.

00:57:11.340 --> 00:57:16.500
[Amit Varma]: So Nikhil, I'm going to, I'm going to ask you to sum it up by referring to a quote of

00:57:16.500 --> 00:57:21.460
[Amit Varma]: yours from a TV interview I saw recently, where you said that the Supreme Court decision

00:57:21.460 --> 00:57:27.020
[Amit Varma]: about Aadhaar is, quote, the most important decision in our history, unquote.

00:57:27.020 --> 00:57:32.220
[Amit Varma]: And then you went on to say, quote, what we do, and by we you meant the citizens of India,

00:57:32.220 --> 00:57:35.740
[Amit Varma]: what we do will impact generations, unquote.

00:57:35.740 --> 00:57:37.060
[Amit Varma]: These are very big words.

00:57:37.060 --> 00:57:39.060
[Amit Varma]: This is a very, very big issue.

00:57:39.060 --> 00:57:41.660
[Amit Varma]: The consequences are very momentous.

00:57:41.660 --> 00:57:42.660
[Guest]: Sum it up for me.

00:57:42.660 --> 00:57:47.780
[Guest]: No, I think that the amount of data that we're releasing right now through this, and remember

00:57:47.780 --> 00:57:51.940
[Guest]: this is, Aadhaar is going to get linked to the DNA database when it gets created, once

00:57:51.940 --> 00:57:55.500
[Guest]: the DNA bill gets passed, right?

00:57:55.500 --> 00:57:58.060
[Amit Varma]: So like you said, our lives are data, we are data.

00:57:58.060 --> 00:57:59.060
[Guest]: Yeah, we are data.

00:57:59.060 --> 00:58:04.260
[Guest]: And so therefore, from an individual liberty perspective, this is, this is the biggest

00:58:04.260 --> 00:58:10.420
[Guest]: decision that's going to be taken about our future, about our data, about our interactions,

00:58:10.420 --> 00:58:15.940
[Guest]: because effectively, this is going to be used by algorithms to, on the good side, give us

00:58:15.940 --> 00:58:22.700
[Guest]: loans, but on the bad side, change the way we vote maybe in the future, or whether there

00:58:22.700 --> 00:58:25.860
[Guest]: is any totality in action by some government in the future.

00:58:25.860 --> 00:58:31.140
[Guest]: So really, these are our rights that are going to get impacted in ways that we can't really

00:58:31.140 --> 00:58:32.680
[Guest]: imagine right now.

00:58:32.680 --> 00:58:40.480
[Guest]: This is also the creation of a mass surveillance state with very limited checks and balances,

00:58:40.480 --> 00:58:46.180
[Guest]: because frankly, on under the guise of national security, very few checks and balances exist,

00:58:46.180 --> 00:58:47.460
[Guest]: if at all.

00:58:47.460 --> 00:58:52.340
[Guest]: So what we need to do as citizens is really push back now.

00:58:52.340 --> 00:58:56.620
[Guest]: I mean, it has to, I said this to some of the lawyers in the Supreme Court case a couple

00:58:56.620 --> 00:59:02.140
[Guest]: of years ago, that this only gets fixed when it becomes an election issue.

00:59:02.140 --> 00:59:07.780
[Guest]: I hope that the Supreme Court does the right thing, because they are effectively going

00:59:07.780 --> 00:59:10.900
[Guest]: to get judged for what they judge or for what they do.

00:59:10.900 --> 00:59:14.060
[Guest]: But we can't depend on courts entirely on this.

00:59:14.060 --> 00:59:16.060
[Guest]: This is a political problem.

00:59:16.060 --> 00:59:18.640
[Guest]: And I think there has to be a political solution.

00:59:18.640 --> 00:59:23.180
[Amit Varma]: And it is on citizens to force a political solution for this.

00:59:23.180 --> 00:59:26.300
[Amit Varma]: So I think anyone who's been listening to this episode will, I think, agree with me

00:59:26.300 --> 00:59:30.700
[Amit Varma]: that if we don't act now, it might be too late from a citizen's perspective.

00:59:30.700 --> 00:59:34.860
[Amit Varma]: But if my listeners want to know, want to ask you that, okay, I'm really concerned,

00:59:34.860 --> 00:59:38.460
[Amit Varma]: but what concrete thing can I do now as a citizen?

00:59:38.460 --> 00:59:40.420
[Guest]: A whole bunch of things, right?

00:59:40.420 --> 00:59:46.300
[Guest]: Number one, we have a site called speakforme.in, which allows you to mail your MP.

00:59:46.300 --> 00:59:50.740
[Guest]: There's some pre-prepared text in that, go and change it, right, whatever you want, and

00:59:50.740 --> 00:59:52.620
[Guest]: just send it to your MP.

00:59:52.620 --> 00:59:57.500
[Guest]: Because once MPs know that their constituents are worried, there is a likelihood that they

00:59:57.500 --> 01:00:03.700
[Guest]: will again internally push their parties to improve the way they're thinking about it.

01:00:03.700 --> 01:00:07.860
[Guest]: Call them up, call them out.

01:00:07.860 --> 01:00:12.220
[Guest]: Whatever you can, inform more people about the issues, because right now what's happening

01:00:12.220 --> 01:00:16.660
[Guest]: is that most people don't understand the problems that we're dealing with.

01:00:16.660 --> 01:00:22.660
[Guest]: Share this podcast with as many people as possible, so that people realize that the

01:00:22.660 --> 01:00:27.300
[Guest]: scale of the problem that we're facing right now, and you know, this has been pretty exhausting

01:00:27.300 --> 01:00:33.540
[Guest]: because for a lot of us who've been talking about this issue over the past few years,

01:00:33.540 --> 01:00:38.580
[Guest]: and especially for Usha Ramanathan, who's been talking about this for almost six, seven

01:00:38.580 --> 01:00:45.780
[Guest]: years now, if not more, it's a very lonely battle because most people don't either understand

01:00:45.780 --> 01:00:52.540
[Guest]: the scope of the problem, understand the issues, and things are changing so quickly that every

01:00:52.540 --> 01:00:56.780
[Guest]: time a new solution comes up, you're wondering, or something that the UIDAI does, for example,

01:00:56.780 --> 01:01:01.860
[Guest]: with FaceID or with Virtual ID that they were doing, you'd think that that solves the problem

01:01:01.860 --> 01:01:03.460
[Guest]: even though it doesn't.

01:01:03.460 --> 01:01:09.460
[Guest]: So I would say do not trust the government on this, do not trust the UIDAI on this, because

01:01:09.460 --> 01:01:12.820
[Guest]: they're trying to retain a system which is flawed.

01:01:12.820 --> 01:01:18.380
[Guest]: Go out and tell them that you want them to either remove the system or fix the system,

01:01:18.380 --> 01:01:22.620
[Guest]: because the only thing that you have going for you is your vote right now.

01:01:22.620 --> 01:01:26.060
[Guest]: I don't think there is any other option to solve this problem.

01:01:26.060 --> 01:01:28.980
[Amit Varma]: That's an inspiring call to action.

01:01:28.980 --> 01:01:30.580
[Amit Varma]: May you never walk alone.

01:01:30.580 --> 01:01:32.340
[Amit Varma]: Thank you so much for coming on the show, Nikhil.

01:01:32.340 --> 01:01:36.060
[Guest]: Thank you for having me here.

01:01:36.060 --> 01:01:43.220
[Amit Varma]: If you enjoyed listening to the show, do follow Nikhil on Twitter at nixxin, at Nixon.

01:01:43.220 --> 01:01:48.600
[Amit Varma]: You can also read his writings and follow the work of his colleagues at medianama.com.

01:01:48.600 --> 01:01:53.140
[Amit Varma]: You can follow me on Twitter at amitvarma, A-M-I-T-V-A-R-M-A.

01:01:53.140 --> 01:01:58.620
[Amit Varma]: And for past episodes of The Seen and the Unseen, do hop over to seenunseen.in.

01:01:58.620 --> 01:02:23.700
[Amit Varma]: Thank you for listening.

01:02:23.700 --> 01:02:27.760
[Unknown]: He bends down to test the warm water for his bath.

01:02:27.760 --> 01:02:32.700
[Unknown]: He comes here to quench his thirst for a hot shower and some podcasts.

01:02:32.700 --> 01:02:38.820
[Unknown]: You can witness how he enjoys having other people talk about cool stuff in his bathroom.

01:02:38.820 --> 01:02:41.900
[Unknown]: Indeed, it helps him with his loneliness.

01:02:41.900 --> 01:02:48.140
[Unknown]: You can find more of his species on ivmpodcast.com, your one-stop destination where you can check

01:02:48.140 --> 01:02:50.620
[Unknown]: out the coolest Indian podcasts.

01:02:50.620 --> 01:03:03.360
[Unknown]: Thank you for listening.

