WEBVTT

00:00:00.000 --> 00:00:08.680
[Amit Varma]: The first time I heard about the internet was in the 1990s, when a friend told me about

00:00:08.680 --> 00:00:10.480
[Amit Varma]: it with great excitement.

00:00:10.480 --> 00:00:15.120
[Amit Varma]: He said the internet is so amazing, you can just go to this site called Yahoo and search

00:00:15.120 --> 00:00:20.160
[Amit Varma]: for say Van Morrison, and it will display every single page about Van Morrison.

00:00:20.160 --> 00:00:21.520
[Amit Varma]: I said, Wow, that's so cool.

00:00:21.520 --> 00:00:23.400
[Amit Varma]: I love Van Morrison.

00:00:23.400 --> 00:00:27.080
[Amit Varma]: At that time, if you told me all the ways in which the internet was going to change

00:00:27.080 --> 00:00:32.720
[Amit Varma]: our lives in the next 25 years, I would have said, No way, that's science fiction.

00:00:32.720 --> 00:00:37.000
[Amit Varma]: But much of the science fiction of that time is everyday banal reality today.

00:00:37.000 --> 00:00:41.160
[Amit Varma]: I often think that I'm so lucky to live in these amazing times, all the information in

00:00:41.160 --> 00:00:42.760
[Amit Varma]: the world at my fingertips.

00:00:42.760 --> 00:00:47.120
[Amit Varma]: And within a few seconds, I can listen to any song ever recorded, download most of the

00:00:47.120 --> 00:00:50.080
[Amit Varma]: books that exist and watch any film that I want to.

00:00:50.080 --> 00:00:53.680
[Amit Varma]: I can connect to my friends around the world and make new ones.

00:00:53.680 --> 00:00:57.720
[Amit Varma]: This is the most empowering tool in human history.

00:00:57.720 --> 00:00:59.640
[Amit Varma]: But here's one question.

00:00:59.640 --> 00:01:04.280
[Unknown]: Is there a flip side?

00:01:04.280 --> 00:01:09.480
[Unknown]: Welcome to the scene and the unseen, our weekly podcast on economics, politics and behavioral

00:01:09.480 --> 00:01:10.480
[Unknown]: science.

00:01:10.480 --> 00:01:15.600
[Amit Varma]: Please welcome your host, Amit Badma.

00:01:15.600 --> 00:01:17.100
[Amit Varma]: Welcome to the scene and the unseen.

00:01:17.100 --> 00:01:20.960
[Amit Varma]: The topic for today is the future of the internet.

00:01:20.960 --> 00:01:26.640
[Amit Varma]: And my guests are Nikhil Pawar of Media Nama and Amit Doshi of IVM podcast.

00:01:26.640 --> 00:01:30.800
[Amit Varma]: IVM podcast, by the way, are my partners in running the scene and the unseen.

00:01:30.800 --> 00:01:33.720
[Amit Varma]: Nikhil has been worried about the future of the internet for a while.

00:01:33.720 --> 00:01:36.760
[Amit Varma]: And he suggested the theme of this episode.

00:01:36.760 --> 00:01:42.120
[Amit Varma]: Amit co-hosts a tech podcast on IVM networks called Shunya One and is one of the most clued

00:01:42.120 --> 00:01:43.120
[Amit Varma]: in guys I know.

00:01:43.120 --> 00:01:47.280
[Amit Varma]: We had this conversation a few weeks ago, and it's quite a lively discussion.

00:01:47.280 --> 00:01:48.280
[Amit Varma]: So listen in.

00:01:48.280 --> 00:01:52.400
[Amit Varma]: Nikhil and Amit, welcome to the scene and the unseen.

00:01:52.400 --> 00:01:53.400
[Unknown]: Hello.

00:01:53.400 --> 00:01:54.400
[Unknown]: Good to be here.

00:01:54.400 --> 00:01:56.320
[Amit Varma]: Yeah, this is my first time on.

00:01:56.320 --> 00:01:59.760
[Amit Varma]: So Nikhil, the internet like air, like water, it's something we just take for granted.

00:01:59.760 --> 00:02:04.040
[Amit Varma]: We assume that it was always thus and always will be a wonderful free place where anyone

00:02:04.040 --> 00:02:08.100
[Amit Varma]: can say what they want and free exchange of ideas and blah, blah, blah, blah, blah.

00:02:08.100 --> 00:02:12.920
[Amit Varma]: But you have recently been extremely worried about the direction that the internet is going

00:02:12.920 --> 00:02:13.920
[Guest]: in.

00:02:13.920 --> 00:02:14.920
[Guest]: Tell us a little bit more about that.

00:02:14.920 --> 00:02:20.040
[Guest]: Yeah, so you know, the the internet is this massive global space which unites the world.

00:02:20.040 --> 00:02:25.020
[Guest]: There are potentially no geographical boundaries on the internet.

00:02:25.020 --> 00:02:27.960
[Guest]: Something that I create or I write can be read by anyone else in the world and vice

00:02:27.960 --> 00:02:28.960
[Guest]: versa.

00:02:28.960 --> 00:02:31.040
[Guest]: And we've many of us have grown up with this space, right?

00:02:31.040 --> 00:02:36.240
[Guest]: So there is, there's a sense that we belong to the internet.

00:02:36.240 --> 00:02:40.720
[Guest]: And we feel quite often we feel more at home on the internet and people we meet of the

00:02:40.720 --> 00:02:41.720
[Guest]: internet.

00:02:41.720 --> 00:02:47.120
[Guest]: You know, growing up when I first started meeting friends off the internet, my, I had

00:02:47.120 --> 00:02:52.360
[Guest]: my uncle tell me to be careful, etc. and, and text message SMS at that point in time

00:02:52.360 --> 00:02:56.280
[Guest]: about where I am and who I'm meeting and all of that stuff.

00:02:56.280 --> 00:03:00.280
[Guest]: We've sort of outgrown that phase now and, you know, today if you land in any country

00:03:00.280 --> 00:03:03.640
[Guest]: in the world, you probably have people you want to meet or you already know because you've

00:03:03.640 --> 00:03:06.200
[Guest]: interacted with them on the internet around things that are common.

00:03:06.200 --> 00:03:12.440
[Guest]: So in that sense, the internet is this global public commons that unites the world.

00:03:12.440 --> 00:03:18.440
[Guest]: And what's been happening over the last five or six years is that there is this massive,

00:03:18.440 --> 00:03:22.520
[Guest]: and this is a political thing, there's a massive shift in the concentration of power on the

00:03:22.520 --> 00:03:27.200
[Guest]: internet and the web seems to be shrinking.

00:03:27.200 --> 00:03:33.560
[Guest]: And so, you know, our access points to the broader internet are getting more limited

00:03:33.560 --> 00:03:35.920
[Guest]: and more controlled.

00:03:35.920 --> 00:03:40.080
[Guest]: And what's also happening is that for the new people who are coming online, for most

00:03:40.080 --> 00:03:42.720
[Guest]: of them, the browser is just an app on the device.

00:03:42.720 --> 00:03:49.040
[Guest]: And so therefore, they don't really necessarily get to, you know, experience that, that, you

00:03:49.040 --> 00:03:54.080
[Guest]: know, some silly blog somewhere that someone's written, because how will they find out that

00:03:54.080 --> 00:03:55.080
[Guest]: this exists?

00:03:55.080 --> 00:04:00.160
[Guest]: They don't know what a URL is, they may not know how to type a URL, the URLs are maybe

00:04:00.160 --> 00:04:01.920
[Guest]: not in their language.

00:04:01.920 --> 00:04:05.960
[Guest]: And so there is a shift in the way how we access the internet.

00:04:05.960 --> 00:04:08.480
[Unknown]: This is something that's irritated me for so many years, right?

00:04:08.480 --> 00:04:12.560
[Unknown]: I mean, we got to a point where we could get rid of desktop software by getting our browsers

00:04:12.560 --> 00:04:17.160
[Unknown]: on the PCs, being able to do all of our stuff over there, right, our email and all that.

00:04:17.160 --> 00:04:20.160
[Unknown]: And now we went back to the same thing as soon as mobile phones came, where now everything

00:04:20.160 --> 00:04:24.440
[Unknown]: has to be through an app instead of being able to use like an open browser.

00:04:24.440 --> 00:04:26.920
[Guest]: And that's actually the challenge, right?

00:04:26.920 --> 00:04:32.480
[Guest]: So the French regulator ASEP has recently come out with a consultation paper on device

00:04:32.480 --> 00:04:37.640
[Guest]: neutrality, saying, and you know, I was initially against that idea, because I say that, you

00:04:37.640 --> 00:04:42.680
[Guest]: know, devices are unregulated, anyone can launch a device.

00:04:42.680 --> 00:04:47.080
[Guest]: But there is a concentration of power that's taken place there in terms of the app stores.

00:04:47.080 --> 00:04:50.920
[Guest]: And you know, one of the things that came up recently in India was that the TRAI, which

00:04:50.920 --> 00:04:58.080
[Guest]: is the Indian telecom regulator, could not launch an SMS spam app on the iPhone, because

00:04:58.080 --> 00:05:00.640
[Guest]: Apple wouldn't allow certain permissions.

00:05:00.640 --> 00:05:07.240
[Guest]: So if you think about it, Apple is a regulator that's regulating the Indian telecom regulator.

00:05:07.240 --> 00:05:09.000
[Guest]: And that's a bizarre situation to be in.

00:05:09.000 --> 00:05:12.880
[Guest]: So there's, and therefore, the TRAI started pushing back.

00:05:12.880 --> 00:05:18.000
[Guest]: But really, where we are going with this here is that Apple controls what gets on to the

00:05:18.000 --> 00:05:22.360
[Guest]: app store in the same way that Google controls what gets on to the Play Store.

00:05:22.360 --> 00:05:26.840
[Guest]: And between the Play Store and the app store, I think they probably have 99% of the world's

00:05:26.840 --> 00:05:27.840
[Unknown]: phones.

00:05:27.840 --> 00:05:30.080
[Unknown]: And they're actually not really good actors in this space a lot of times as well.

00:05:30.080 --> 00:05:35.240
[Unknown]: I mean, like, the way that the what happened to Windows Phone, right?

00:05:35.240 --> 00:05:39.240
[Unknown]: In some ways, is entirely because the app store and the Play Store would not play well

00:05:39.240 --> 00:05:41.000
[Guest]: with others.

00:05:41.000 --> 00:05:42.920
[Unknown]: But they don't play well with each other, right?

00:05:42.920 --> 00:05:44.400
[Unknown]: Yeah, with anybody.

00:05:44.400 --> 00:05:48.120
[Guest]: So then this is this is a fight between elephants, and the grass is getting crushed.

00:05:48.120 --> 00:05:52.200
[Guest]: So and that grass, which is getting crushed is the internet, the broader open internet.

00:05:52.200 --> 00:05:56.360
[Amit Varma]: So I want to go back to how you started the episode and forgive me if I ask some newbie

00:05:56.360 --> 00:06:01.880
[Amit Varma]: questions and, you know, seemingly basic things, I just want to kind of see if I'm understanding

00:06:01.880 --> 00:06:06.240
[Amit Varma]: you correctly, where you pointed out about how the internet is shrinking as a space.

00:06:06.240 --> 00:06:11.320
[Amit Varma]: Now I get that all the big players are getting much, much bigger, that more people's first

00:06:11.320 --> 00:06:17.680
[Amit Varma]: exposure to the internet is say through a Facebook, or, you know, through a Google then,

00:06:17.680 --> 00:06:23.040
[Amit Varma]: instead of just a wild world wide web of sites that we had out there, but at the same time,

00:06:23.040 --> 00:06:27.280
[Amit Varma]: it's still open, anyone can go out there and start anything, start their own site, start

00:06:27.280 --> 00:06:31.760
[Amit Varma]: their own app, start their own platform, they might not get much traction, because the way

00:06:31.760 --> 00:06:34.720
[Amit Varma]: people filter content has changed.

00:06:34.720 --> 00:06:40.480
[Amit Varma]: And that's kind of been, you know, these large companies are dominating that filtering process

00:06:40.480 --> 00:06:42.880
[Amit Varma]: where people discover content and so on and so forth.

00:06:42.880 --> 00:06:47.640
[Guest]: So I guess the way you need to look at it is that what part of this is harmful for free

00:06:47.640 --> 00:06:52.840
[Guest]: speech, what part of this is anti competitive in nature, right?

00:06:52.840 --> 00:06:57.440
[Guest]: And how, for example, filter bubbles impacting our discovery of things.

00:06:57.440 --> 00:07:03.880
[Guest]: If you look at, let's say, Google search versus discovering something on Facebook, Google

00:07:03.880 --> 00:07:08.680
[Guest]: search is largely intent based, but I'll take you back to almost 10 years ago, when news

00:07:08.680 --> 00:07:12.720
[Guest]: cops started complaining about Google search, because Google's algorithm, which is a black

00:07:12.720 --> 00:07:17.800
[Guest]: box, was defining how news cops content was being consumed.

00:07:17.800 --> 00:07:19.840
[Guest]: And so we're back to that same battle here.

00:07:19.840 --> 00:07:25.000
[Guest]: But now it's not just a battle on Google search, but it's also around Facebook and the filter

00:07:25.000 --> 00:07:27.400
[Guest]: bubbles and the access to content there.

00:07:27.400 --> 00:07:31.600
[Guest]: So I think another discussion that's probably going to be had, and we're not having it yet,

00:07:31.600 --> 00:07:38.520
[Guest]: is the neutrality of algorithms, and who controls what the algorithms show us from that perspective,

00:07:38.520 --> 00:07:42.640
[Guest]: because, you know, there was one experiment, which Facebook did in, I think, 2012, where

00:07:42.640 --> 00:07:47.880
[Guest]: they started changing the newsfeed to make you happy, to make you happy and sad.

00:07:47.880 --> 00:07:50.840
[Guest]: And so, you know, is it really neutral is the question?

00:07:50.840 --> 00:07:54.920
[Guest]: And do we have multiple options in terms of algorithms as well?

00:07:54.920 --> 00:07:59.920
[Guest]: These are discussions that are going to happen because they change the shape, not just the

00:07:59.920 --> 00:08:06.760
[Guest]: way we consume content, but they shape how we view the world, they can shape democracies.

00:08:06.760 --> 00:08:12.080
[Guest]: And I'd like to, you know, go back to where this battle actually started.

00:08:12.080 --> 00:08:18.360
[Guest]: And so I kind of like to imagine Facebook as a country, and the same way Google as a

00:08:18.360 --> 00:08:20.680
[Guest]: country and Amazon as a country.

00:08:20.680 --> 00:08:26.620
[Guest]: And there is this turf war and this land grab that's taking place across the board.

00:08:26.620 --> 00:08:33.000
[Guest]: So whether you look at, let's say, Amazon doing AWS, which is their hosting service,

00:08:33.000 --> 00:08:35.680
[Guest]: Google doing Google Cloud.

00:08:35.680 --> 00:08:40.620
[Guest]: So, you know, different companies are now looking at various industries, subsegments

00:08:40.620 --> 00:08:46.160
[Guest]: to get into, to get more information and more control in that space.

00:08:46.160 --> 00:08:48.360
[Guest]: Everyone wants to do commerce as well.

00:08:48.360 --> 00:08:50.360
[Guest]: And everyone wants to do devices as well.

00:08:50.360 --> 00:08:56.360
[Guest]: A voice is where the real battle is happening right now in terms of Google Home versus,

00:08:56.360 --> 00:08:58.080
[Guest]: you know, the Amazon Echo.

00:08:58.080 --> 00:09:05.800
[Guest]: You might have noticed recently, there was this battle around YouTube being removed,

00:09:05.800 --> 00:09:06.880
[Unknown]: Chromecast, I think.

00:09:06.880 --> 00:09:09.400
[Unknown]: So Amazon Prime is no longer available on Chromecast.

00:09:09.400 --> 00:09:12.480
[Guest]: Amazon Prime is no longer available on Chromecast.

00:09:12.480 --> 00:09:15.520
[Guest]: And there was a reciprocal reaction there.

00:09:15.520 --> 00:09:20.240
[Guest]: Now, in all of this, because of these battles between these guys, consumers effectively

00:09:20.240 --> 00:09:22.720
[Guest]: are deprived of that choice.

00:09:22.720 --> 00:09:26.280
[Amit Varma]: But you know, I don't understand that it would be a problem, what you're describing, if it

00:09:26.280 --> 00:09:31.880
[Amit Varma]: was just one big monolithic company taking over clouds and taking over content platforms

00:09:31.880 --> 00:09:32.880
[Amit Varma]: and so on.

00:09:32.880 --> 00:09:35.200
[Unknown]: But what you seem to have here is a really healthy competition.

00:09:35.200 --> 00:09:36.560
[Unknown]: And I think that's good for the consumer.

00:09:36.560 --> 00:09:38.040
[Unknown]: Well, generally, I would agree with you.

00:09:38.040 --> 00:09:39.880
[Unknown]: And I am pro competition in most places.

00:09:39.880 --> 00:09:43.040
[Unknown]: What I think happens over here is these ecosystems develop lock-in.

00:09:43.040 --> 00:09:47.560
[Unknown]: And when you have lock-in of that nature, it's difficult to move from one to another,

00:09:47.560 --> 00:09:48.560
[Unknown]: right?

00:09:48.560 --> 00:09:52.280
[Unknown]: I set up my entire home to function on a Chromecast and through using all Google services.

00:09:52.280 --> 00:09:54.960
[Unknown]: All of a sudden, I can no longer use Amazon Prime, right?

00:09:54.960 --> 00:09:57.440
[Amit Varma]: Well, I still use it on Chromecast casting my screen.

00:09:57.440 --> 00:09:58.440
[Unknown]: But that is a...

00:09:58.440 --> 00:10:04.680
[Guest]: But that's because casting is a protocol, it's not necessarily a, you know, it's...

00:10:04.680 --> 00:10:09.240
[Guest]: And by the way, there is every possibility that casting in the future may not allow it.

00:10:09.240 --> 00:10:11.800
[Guest]: You don't know how this is going to function in the future.

00:10:11.800 --> 00:10:12.800
[Unknown]: So there was...

00:10:12.800 --> 00:10:13.800
[Unknown]: And we've seen this happen before.

00:10:13.800 --> 00:10:14.800
[Unknown]: So there was a very...

00:10:14.800 --> 00:10:16.760
[Unknown]: So again, I mean, I brought up Windows Phone earlier, right?

00:10:16.760 --> 00:10:19.880
[Unknown]: But there was a big problem with YouTube on Windows Phone.

00:10:19.880 --> 00:10:23.240
[Unknown]: When Windows Phone wanted a YouTube app, Google wouldn't make it.

00:10:23.240 --> 00:10:25.520
[Unknown]: They made their own, but they use private APIs.

00:10:25.520 --> 00:10:26.940
[Unknown]: And then Google blocked that app.

00:10:26.940 --> 00:10:27.940
[Unknown]: And they blocked the API.

00:10:27.940 --> 00:10:30.160
[Amit Varma]: So there's always this kind of fight going on in these platforms.

00:10:30.160 --> 00:10:31.160
[Amit Varma]: My...

00:10:31.160 --> 00:10:34.320
[Amit Varma]: See, one prism through which I look at the world, as you know, Nikhil, is the whole issue

00:10:34.320 --> 00:10:38.940
[Amit Varma]: of what is voluntary and consensual and what is not.

00:10:38.940 --> 00:10:43.400
[Amit Varma]: And what I see happening here is, and not just in terms of devices and not just in terms

00:10:43.400 --> 00:10:47.400
[Amit Varma]: of Google versus Facebook, is a question I always ask myself is, where is the coercion?

00:10:47.400 --> 00:10:52.420
[Amit Varma]: Now, if all these different companies are offering different kinds of products and the

00:10:52.420 --> 00:10:56.720
[Amit Varma]: consumer can, you know, choose between one and the other, or just take a combination

00:10:56.720 --> 00:11:00.480
[Amit Varma]: of all of them, why get in the way of that voluntary exchange?

00:11:00.480 --> 00:11:04.040
[Amit Varma]: Like, when you talk about the algorithm that Facebook would have to make people happy and

00:11:04.040 --> 00:11:08.400
[Amit Varma]: sad, that yes, when I read about it, it makes me angry that damn, I'm being manipulated

00:11:08.400 --> 00:11:10.240
[Amit Varma]: and that makes me pissed off.

00:11:10.240 --> 00:11:14.080
[Amit Varma]: But then my appropriate reaction to that should be to go off Facebook.

00:11:14.080 --> 00:11:17.600
[Amit Varma]: My point is that if people have signed on voluntarily to Facebook, and if everything

00:11:17.600 --> 00:11:21.680
[Amit Varma]: is voluntary, and there's no coercion anywhere, then who are we to condescend and get in the

00:11:21.680 --> 00:11:22.680
[Guest]: way?

00:11:22.680 --> 00:11:24.800
[Guest]: No, so this, this particularly impacts you if you're a creator.

00:11:24.800 --> 00:11:30.080
[Guest]: And see, this is the difference between the internet and traditional platforms like TV

00:11:30.080 --> 00:11:31.080
[Guest]: and cable, etc.

00:11:31.080 --> 00:11:33.320
[Guest]: And which is why the internet has no parallel.

00:11:33.320 --> 00:11:38.240
[Guest]: When you're a creator, your dependency on the distribution platform is very, very high.

00:11:38.240 --> 00:11:44.240
[Guest]: Now, go back to let's say another six, seven years, and there was a big battle between

00:11:44.240 --> 00:11:47.760
[Guest]: Hatchet as a book publisher, and Amazon.

00:11:47.760 --> 00:11:52.360
[Guest]: And Hatchet did not want Amazon to drop Hatchet prices, essentially.

00:11:52.360 --> 00:11:57.840
[Guest]: And Amazon, therefore, started showing, I think, fewer Hatchet results in searches and

00:11:57.840 --> 00:11:58.840
[Amit Varma]: things like that.

00:11:58.840 --> 00:12:01.880
[Amit Varma]: I was actually a Hatchet author, I mean, I launched in India with my book, and I think

00:12:01.880 --> 00:12:02.880
[Amit Varma]: it's legitimate.

00:12:02.880 --> 00:12:04.400
[Guest]: I mean, it's two private parties negotiating.

00:12:04.400 --> 00:12:06.520
[Guest]: But it's but that's where power comes in, right?

00:12:06.520 --> 00:12:10.240
[Guest]: And the power of the platform is always going to be greater than the power of the creator.

00:12:10.240 --> 00:12:15.280
[Guest]: One of the things you have to remember about all all platforms is that they're in the business

00:12:15.280 --> 00:12:21.940
[Guest]: of maximizing fragmentation, and monetizing the aggregation, right?

00:12:21.940 --> 00:12:25.800
[Guest]: So when they maximize fragmentation, and we've seen so I did some research on the YouTube

00:12:25.800 --> 00:12:26.800
[Guest]: ecosystem.

00:12:26.800 --> 00:12:31.440
[Guest]: And you know, when YouTube initially started, every creator was really, really happy because

00:12:31.440 --> 00:12:35.440
[Guest]: they got special attention from YouTube and YouTube guys would come and teach them about

00:12:35.440 --> 00:12:38.000
[Guest]: how to do better and better.

00:12:38.000 --> 00:12:41.800
[Guest]: And you know, initially, they made a lot of money.

00:12:41.800 --> 00:12:47.680
[Guest]: As more and more creators started coming on, they started getting less help.

00:12:47.680 --> 00:12:49.600
[Guest]: And they started making less money.

00:12:49.600 --> 00:12:55.440
[Guest]: And so therefore, as fragmentation increases, it's the aggregator that holds all the power.

00:12:55.440 --> 00:13:02.640
[Guest]: And unfortunately, the way markets work is that there is only space for a few large aggregators.

00:13:02.640 --> 00:13:07.240
[Guest]: And and the network effects that come in really inhibit competition.

00:13:07.240 --> 00:13:11.000
[Guest]: And therefore, you've seen that with Facebook, for example, there's literally no competition,

00:13:11.000 --> 00:13:17.120
[Guest]: the social networking space in case of I mean, in case of Amazon, India still has competition

00:13:17.120 --> 00:13:18.760
[Guest]: in case of Flipkart.

00:13:18.760 --> 00:13:21.040
[Guest]: But even the and I don't quite agree with them.

00:13:21.040 --> 00:13:25.080
[Guest]: But they've also been complaining about capital dumping, because they realize now this is

00:13:25.080 --> 00:13:27.400
[Guest]: a battle about deeper pockets.

00:13:27.400 --> 00:13:29.400
[Guest]: And then it's going to be a last man standing game.

00:13:29.400 --> 00:13:30.680
[Amit Varma]: So let me paraphrase your point.

00:13:30.680 --> 00:13:34.640
[Guest]: You've convinced me in the sense that it's what I'm trying to say is that this is a power

00:13:34.640 --> 00:13:35.720
[Guest]: game.

00:13:35.720 --> 00:13:38.680
[Guest]: And the content creator is always going to lose in this battle.

00:13:38.680 --> 00:13:39.760
[Amit Varma]: Okay, so here's the deal.

00:13:39.760 --> 00:13:43.520
[Amit Varma]: So what I was originally arguing, and I see the nuance that you added to that what I was

00:13:43.520 --> 00:13:47.200
[Amit Varma]: originally arguing was that as long as there is competition, you can sell your content

00:13:47.200 --> 00:13:49.280
[Amit Varma]: to Netflix or Amazon or blah, blah, blah.

00:13:49.280 --> 00:13:53.280
[Amit Varma]: What you're saying, though, is that say you look at Amazon, they are basically the only

00:13:53.280 --> 00:13:56.680
[Amit Varma]: bookseller in town, there's no other business network effects kick in.

00:13:56.680 --> 00:14:00.600
[Amit Varma]: So if a publisher fights with them or doesn't agree to their terms, they don't have a choice.

00:14:00.600 --> 00:14:03.960
[Amit Varma]: You have a similar kind of monopoly in terms of uploading videos.

00:14:03.960 --> 00:14:07.960
[Amit Varma]: If you want to make your own home videos and monetize them, and so on, you basically don't

00:14:07.960 --> 00:14:08.960
[Amit Varma]: have a choice.

00:14:08.960 --> 00:14:10.200
[Amit Varma]: You have to go to YouTube.

00:14:10.200 --> 00:14:15.160
[Amit Varma]: So Mike, but at the same time, having said this, it seems problematic to go to a private

00:14:15.160 --> 00:14:20.240
[Amit Varma]: party like an Amazon or YouTube in these instances, and try to regulate them.

00:14:20.240 --> 00:14:24.440
[Amit Varma]: And especially when that regulation is done by government, it will always the process

00:14:24.440 --> 00:14:29.440
[Amit Varma]: will always be corrupted, and there will always be unintended consequences that are also harmful

00:14:29.440 --> 00:14:31.040
[Amit Varma]: plus it's coercion.

00:14:31.040 --> 00:14:36.400
[Unknown]: So so how do we how do we reconcile at some point doesn't a platform become a public good?

00:14:36.400 --> 00:14:41.360
[Unknown]: I mean, like at some point, you know, I mean, like the fact that YouTube exists as it exists,

00:14:41.360 --> 00:14:42.360
[Unknown]: right?

00:14:42.360 --> 00:14:43.360
[Unknown]: It is a public good.

00:14:43.360 --> 00:14:46.400
[Unknown]: Now, at this point in time, yeah, Google owns it, Google monetize it, all of that.

00:14:46.400 --> 00:14:48.800
[Unknown]: But it is ubiquitous in its usage.

00:14:48.800 --> 00:14:54.680
[Unknown]: It's just so far out there that a certain amount of I hate saying governmental regulation,

00:14:54.680 --> 00:14:56.680
[Amit Varma]: but a certain amount of oversight of some nature is necessary.

00:14:56.680 --> 00:15:00.680
[Amit Varma]: I'll tell you where I agree with you and where I disagree with you, where I agree with you

00:15:00.680 --> 00:15:04.800
[Amit Varma]: is that when we used to speak of net neutrality earlier, and I might have had this discussion

00:15:04.800 --> 00:15:09.160
[Amit Varma]: with Nikhil and I committed from a property rights perspective, and the question I would

00:15:09.160 --> 00:15:12.880
[Amit Varma]: ask is who owns the spectrum, the government of India owns the spectrum.

00:15:12.880 --> 00:15:16.280
[Amit Varma]: And therefore, whether they should own the spectrum or not is a separate argument.

00:15:16.280 --> 00:15:20.120
[Amit Varma]: But given that they own the spectrum, they have a right to license it out under whatever

00:15:20.120 --> 00:15:21.880
[Amit Varma]: terms they want.

00:15:21.880 --> 00:15:26.320
[Amit Varma]: And when the net neutrality issue broke up, I actually went and looked at their existing

00:15:26.320 --> 00:15:32.800
[Amit Varma]: contract with telecom providers, which allows them to change the terms in between, as Nikhil

00:15:32.800 --> 00:15:36.600
[Amit Varma]: and gang were arguing for, right, and to impose these conditions.

00:15:36.600 --> 00:15:39.440
[Amit Varma]: So coming at it from property rights, I get that, right.

00:15:39.440 --> 00:15:44.640
[Amit Varma]: But let's say YouTube is someone who is, you know, they're on the internet, they're providing

00:15:44.640 --> 00:15:49.520
[Amit Varma]: a service, they're not compelling anyone, they're not stopping competitors, who are

00:15:49.520 --> 00:15:50.520
[Amit Varma]: we to interfere?

00:15:50.520 --> 00:15:51.520
[Unknown]: I don't get that.

00:15:51.520 --> 00:15:52.520
[Unknown]: All right.

00:15:52.520 --> 00:15:53.520
[Unknown]: I know.

00:15:53.520 --> 00:15:56.680
[Unknown]: I find what is tough is it really is tough to kind of figure out, you know, what is the

00:15:56.680 --> 00:15:57.680
[Unknown]: differentiation?

00:15:57.680 --> 00:15:58.680
[Unknown]: How do you make a distinction over here?

00:15:58.680 --> 00:15:59.680
[Guest]: That's it's tough.

00:15:59.680 --> 00:16:04.440
[Guest]: Not really, actually, I mean, look, the conversation is now changing around the fact that every

00:16:04.440 --> 00:16:10.160
[Guest]: single entity that has over a billion users is being treated as something called a behemoth.

00:16:10.160 --> 00:16:17.200
[Guest]: And those entities now have the power, not just to, you know, impact creators, but also

00:16:17.200 --> 00:16:18.760
[Guest]: to shape democracy.

00:16:18.760 --> 00:16:22.680
[Guest]: And this is exactly why governments are now becoming a lot more conscious of the power

00:16:22.680 --> 00:16:23.680
[Guest]: of these platforms.

00:16:23.680 --> 00:16:27.240
[Guest]: Like, I go back to the idea of Facebook as a country.

00:16:27.240 --> 00:16:32.080
[Guest]: You know, when Zuck visits, he has these are all diplomatic visits, effectively, there's

00:16:32.080 --> 00:16:37.880
[Guest]: a certain minutes, some talking points that are already defined with the Prime Minister

00:16:37.880 --> 00:16:40.400
[Guest]: with different ministers.

00:16:40.400 --> 00:16:44.200
[Guest]: So if you just zoom out and think of Facebook as a country in a virtual world, what you

00:16:44.200 --> 00:16:50.640
[Guest]: will see is that they have a team that looks at the government policy with the government

00:16:50.640 --> 00:16:52.100
[Guest]: as a stakeholder.

00:16:52.100 --> 00:16:56.280
[Guest]: If you're running a page on Facebook, you're effectively, that's essentially the Ministry

00:16:56.280 --> 00:16:57.280
[Guest]: of Commerce.

00:16:57.280 --> 00:16:59.920
[Guest]: If you think about it, that looks at those relationships.

00:16:59.920 --> 00:17:08.840
[Guest]: Their task is to encourage usage of the platform, but also because Facebook's, it's a business,

00:17:08.840 --> 00:17:12.160
[Guest]: is also to ensure that there is enough monetization that comes in.

00:17:12.160 --> 00:17:17.920
[Guest]: So there are significant controls that it is able to exert by virtue of its scale and

00:17:17.920 --> 00:17:19.680
[Guest]: and its network effects.

00:17:19.680 --> 00:17:26.760
[Guest]: And under those circumstances, I think regulation is bound to happen, because there are negative

00:17:26.760 --> 00:17:30.760
[Guest]: consequences that are also coming out of it, which are impacting physical countries.

00:17:30.760 --> 00:17:33.360
[Guest]: So let's look at a couple of them that are that are happening, right.

00:17:33.360 --> 00:17:39.120
[Guest]: So let's look at the impact of fake news, for example.

00:17:39.120 --> 00:17:44.120
[Guest]: The US election is very clear that, you know, they had very few advertising controls that

00:17:44.120 --> 00:17:50.520
[Guest]: allowed the marketing and very tiny, like granular segmentation in terms of targeting

00:17:50.520 --> 00:17:55.240
[Guest]: individuals with content that they felt would impact the way they vote.

00:17:55.240 --> 00:18:01.280
[Guest]: I mean, there were also, there are also instances where fake sites have been created, and they're

00:18:01.280 --> 00:18:03.240
[Guest]: saying you don't need to go and vote.

00:18:03.240 --> 00:18:05.840
[Guest]: You can just go click here and vote on the website, right.

00:18:05.840 --> 00:18:09.680
[Guest]: Now, these are real consequences for democracies.

00:18:09.680 --> 00:18:11.700
[Guest]: And you need controls in place.

00:18:11.700 --> 00:18:17.960
[Guest]: In the same way, when you look at it, let's take Uber as an example, and the rape case

00:18:17.960 --> 00:18:18.960
[Guest]: in Delhi.

00:18:18.960 --> 00:18:19.960
[Guest]: Right.

00:18:19.960 --> 00:18:26.640
[Guest]: Now, Uber treats itself purely as a platform saying that we are helping discovery of cabs.

00:18:26.640 --> 00:18:31.160
[Guest]: And they claim to not be accountable for the behavior of the drivers because they're a

00:18:31.160 --> 00:18:33.080
[Guest]: pure marketplace.

00:18:33.080 --> 00:18:37.160
[Guest]: But the fact is that they are responsible because they're selecting who gets on the

00:18:37.160 --> 00:18:41.000
[Guest]: platform, and they need to do their own due diligence.

00:18:41.000 --> 00:18:45.640
[Guest]: There's another debate when it's coming to around rights of drivers as either employees

00:18:45.640 --> 00:18:51.360
[Guest]: versus, you know, or just being merchants on Uber's platform.

00:18:51.360 --> 00:18:56.560
[Guest]: And so, you know, there is what's happening right now, is that there's a gap between the

00:18:56.560 --> 00:19:01.120
[Guest]: responsibility and the accountability of these platforms.

00:19:01.120 --> 00:19:07.040
[Guest]: And that exists today because of something called intermediary liability protections.

00:19:07.040 --> 00:19:13.840
[Guest]: That means that an intermediary, like an ISP, like a Facebook, an Amazon or an Uber, is

00:19:13.840 --> 00:19:18.400
[Guest]: not liable for the actions of the entities on it.

00:19:18.400 --> 00:19:23.000
[Guest]: And we had our own case in India around that with essentially Bazi.com, where Avneesh Bajaj

00:19:23.000 --> 00:19:28.320
[Guest]: was arrested because someone put up a porn CD on sale on Bazi.com.

00:19:28.320 --> 00:19:30.720
[Guest]: It later became eBay, India.

00:19:30.720 --> 00:19:35.920
[Guest]: But we brought in those protections as well in India to protect the platforms which are

00:19:35.920 --> 00:19:40.760
[Guest]: merely mean marketplaces for exchange, right?

00:19:40.760 --> 00:19:45.920
[Guest]: Now, because of the scale of a lot of these platforms and the impact that they're having,

00:19:45.920 --> 00:19:50.800
[Guest]: and how they impact even merchants and the power that they have over them, and the fact

00:19:50.800 --> 00:19:56.880
[Guest]: that they can shape consumer behavior now, countries are looking at regulating them,

00:19:56.880 --> 00:20:02.280
[Guest]: because they are responsible for some of this behavior of not, let's say, clamping down

00:20:02.280 --> 00:20:07.240
[Guest]: on fake news, but they're not held accountable because they have these protections.

00:20:07.240 --> 00:20:10.720
[Guest]: So why I'm worried about the open internet going forward is that these intermediary liability

00:20:10.720 --> 00:20:15.880
[Guest]: protections, which I support, look like they're going to get chipped away at bit by bit by

00:20:15.880 --> 00:20:16.880
[Amit Varma]: bit.

00:20:16.880 --> 00:20:19.600
[Amit Varma]: So I want to come back to this and I'll ask you to elaborate on this because it's very

00:20:19.600 --> 00:20:22.120
[Amit Varma]: interesting and I share the same worries.

00:20:22.120 --> 00:20:24.600
[Amit Varma]: There's a tangential thought, though, I just want to throw up.

00:20:24.600 --> 00:20:25.600
[Amit Varma]: It's not an argument.

00:20:25.600 --> 00:20:27.080
[Amit Varma]: It's just a tangential thought.

00:20:27.080 --> 00:20:32.680
[Amit Varma]: I've also written op-eds and columns bemoaning, you know, what the whole fake news culture

00:20:32.680 --> 00:20:36.720
[Amit Varma]: and more than that, what has happened to our political discourse with polarization and

00:20:36.720 --> 00:20:39.880
[Amit Varma]: echo chambers and so on, all of it enabled by technology.

00:20:39.880 --> 00:20:44.720
[Amit Varma]: But my point here is that we might be shooting the messenger, because what all of this points

00:20:44.720 --> 00:20:49.600
[Amit Varma]: to is that human beings have frailties in their psychological needs and the way they

00:20:49.600 --> 00:20:56.040
[Amit Varma]: think about things, like why fake news dominates so much is that people also need to believe

00:20:56.040 --> 00:21:01.000
[Amit Varma]: in fake news that once they've given their allegiance to a tribe, they will ignore everything

00:21:01.000 --> 00:21:02.440
[Amit Varma]: from outside.

00:21:02.440 --> 00:21:08.960
[Amit Varma]: And you know, just the confirmation bias kicks in and they'll just consume content that is

00:21:08.960 --> 00:21:10.880
[Unknown]: tailored to their biases and so on.

00:21:10.880 --> 00:21:14.920
[Amit Varma]: For example, you spoke about how Facebook created these pages which said, you don't

00:21:14.920 --> 00:21:17.340
[Amit Varma]: have to go out and vote, just click here.

00:21:17.340 --> 00:21:21.360
[Amit Varma]: And the point is, to me, what that indicates is a human frailty.

00:21:21.360 --> 00:21:29.000
[Amit Varma]: And the fact that technology amplifies these frailties leads to huge problems.

00:21:29.000 --> 00:21:33.320
[Amit Varma]: But to me, the amplification isn't the problem because technology, the flip side is it also

00:21:33.320 --> 00:21:35.260
[Amit Varma]: empowers all of us.

00:21:35.260 --> 00:21:37.520
[Amit Varma]: So the issue here isn't the technology.

00:21:37.520 --> 00:21:42.200
[Amit Varma]: The issue here is that people are flawed and frail in these ways.

00:21:42.200 --> 00:21:46.560
[Amit Varma]: And that brings about the philosophical question that if human beings are like this, is it

00:21:46.560 --> 00:21:49.800
[Amit Varma]: the state's job to save them from themselves?

00:21:49.800 --> 00:21:52.520
[Amit Varma]: And I would argue that the difficult answer to that is no.

00:21:52.520 --> 00:21:59.200
[Guest]: Well, the way I look at it is that, for again, for free speech to sustain, for democracies

00:21:59.200 --> 00:22:03.600
[Guest]: to sustain, certain amount of paternalism needs to kick in at some point in time.

00:22:03.600 --> 00:22:08.240
[Guest]: Now, what the threshold for that to kick in is the one that we have to consider.

00:22:08.240 --> 00:22:17.960
[Guest]: Now, in case of, let's say, let's take the 66-day judgment, which was from 2015.

00:22:17.960 --> 00:22:23.020
[Guest]: If you're a free speech absolutist, you would say that all speech is kosher.

00:22:23.020 --> 00:22:27.240
[Guest]: But we have reasonable restrictions there in order to protect people, in order to protect

00:22:27.240 --> 00:22:28.240
[Amit Varma]: democracies.

00:22:28.240 --> 00:22:30.840
[Guest]: So I must say I'm an absolutist and I feel there should be those restrictions should

00:22:30.840 --> 00:22:31.840
[Guest]: not be there.

00:22:31.840 --> 00:22:32.840
[Guest]: Right.

00:22:32.840 --> 00:22:36.200
[Guest]: But so, for example, there is a restriction on the incitement to violence.

00:22:36.200 --> 00:22:37.200
[Guest]: Right.

00:22:37.200 --> 00:22:40.040
[Guest]: Now, what we fought against was not against incitement to violence.

00:22:40.040 --> 00:22:44.480
[Guest]: I mean, I'm someone who believes that incitement to violence should not be allowed and people

00:22:44.480 --> 00:22:48.000
[Guest]: should be put in jail for inciting violence.

00:22:48.000 --> 00:22:49.480
[Amit Varma]: But then you're like an accessory to a crime.

00:22:49.480 --> 00:22:51.480
[Guest]: It doesn't exactly fall under free speech.

00:22:51.480 --> 00:22:52.480
[Guest]: Exactly.

00:22:52.480 --> 00:22:53.480
[Guest]: No, no.

00:22:53.480 --> 00:22:55.760
[Guest]: So again, if you're an absolutist, it wouldn't be a crime.

00:22:55.760 --> 00:22:56.760
[Amit Varma]: No, no.

00:22:56.760 --> 00:22:57.760
[Amit Varma]: I disagree.

00:22:57.760 --> 00:22:58.760
[Unknown]: I think that's a narrow view of an absolutist.

00:22:58.760 --> 00:22:59.760
[Unknown]: Yeah.

00:22:59.760 --> 00:23:00.760
[Unknown]: I would have.

00:23:00.760 --> 00:23:01.760
[Unknown]: That's an accessory to a crime.

00:23:01.760 --> 00:23:02.760
[Unknown]: Exactly.

00:23:02.760 --> 00:23:04.720
[Guest]: If you are instigating a crime, you're part of that crime.

00:23:04.720 --> 00:23:09.200
[Unknown]: No, but it is a reasonable restriction that is there in terms of non-free speech.

00:23:09.200 --> 00:23:13.320
[Unknown]: Why does it need to be applied to free speech as opposed to being applied to the violence

00:23:13.320 --> 00:23:14.320
[Guest]: that's been committed?

00:23:14.320 --> 00:23:15.320
[Guest]: No, no.

00:23:15.320 --> 00:23:16.640
[Guest]: At least it applies to the violence as well.

00:23:16.640 --> 00:23:19.560
[Amit Varma]: Like the US Supreme Court had a guideline, which was, you know, the phrase clear and

00:23:19.560 --> 00:23:20.560
[Amit Varma]: present danger.

00:23:20.560 --> 00:23:21.560
[Amit Varma]: Yeah.

00:23:21.560 --> 00:23:24.440
[Amit Varma]: That if there is, if you say something and there is clear and present danger, if I remember

00:23:24.440 --> 00:23:28.680
[Amit Varma]: correctly, if there's clear and present danger and some, its imminent damage will be caused

00:23:28.680 --> 00:23:29.680
[Amit Varma]: because of that.

00:23:29.680 --> 00:23:36.520
[Amit Varma]: So, for example, if you stand out there and you say that libertarians are terrible people,

00:23:36.520 --> 00:23:37.880
[Amit Varma]: I wish they didn't exist.

00:23:37.880 --> 00:23:39.480
[Amit Varma]: I think that should absolutely be allowed.

00:23:39.480 --> 00:23:42.960
[Amit Varma]: But if you were to say, there's Amit Verma, he's a libertarian, kill him.

00:23:42.960 --> 00:23:43.960
[Amit Varma]: That's wrong.

00:23:43.960 --> 00:23:44.960
[Unknown]: That's not necessary.

00:23:44.960 --> 00:23:45.960
[Unknown]: Fire in a crowded theatre, right?

00:23:45.960 --> 00:23:48.960
[Amit Varma]: I mean, like, no, that's, that's actually a different, it's the same kind of thing.

00:23:48.960 --> 00:23:50.960
[Guest]: I've written a few pieces on that.

00:23:50.960 --> 00:23:53.960
[Guest]: The fire in a crowded theatre is a terrible example, but let's not go into that.

00:23:53.960 --> 00:23:54.960
[Guest]: No, no.

00:23:54.960 --> 00:23:58.920
[Amit Varma]: But I'm saying that, that, that's not allowed under the Sixth Sense Judgment as well.

00:23:58.920 --> 00:24:03.800
[Guest]: So paternalism will kick in at some point in time to prevent harm from taking place.

00:24:03.800 --> 00:24:07.240
[Amit Varma]: No, I think, I think, I think we're defining paternalism differently though.

00:24:07.240 --> 00:24:08.240
[Guest]: No, no.

00:24:08.240 --> 00:24:12.360
[Guest]: Now, when you go back to, let's say, how these platforms are essentially being governed,

00:24:12.360 --> 00:24:18.280
[Guest]: the lack of governance there from the platforms themselves is hampering the existence of countries

00:24:18.280 --> 00:24:19.280
[Guest]: and democracies.

00:24:19.280 --> 00:24:22.520
[Guest]: Now, if you're going to come at me and say that, that, you know, geographical boundaries

00:24:22.520 --> 00:24:27.640
[Guest]: shouldn't exist, countries shouldn't exist, that's a, that's a completely different debate.

00:24:27.640 --> 00:24:32.000
[Guest]: But it is for the protection of the state and for the people in the state, that some

00:24:32.000 --> 00:24:33.880
[Amit Varma]: of this paternalism has to kick in.

00:24:33.880 --> 00:24:34.880
[Amit Varma]: No, but I don't...

00:24:34.880 --> 00:24:35.880
[Amit Varma]: From a regulatory perspective.

00:24:35.880 --> 00:24:36.880
[Amit Varma]: See, I don't call this paternalism.

00:24:36.880 --> 00:24:37.880
[Amit Varma]: Like, I'll, I'll, I'll define it my way.

00:24:37.880 --> 00:24:38.880
[Guest]: I think the state...

00:24:38.880 --> 00:24:39.880
[Guest]: For me, all state action is paternalism.

00:24:39.880 --> 00:24:40.880
[Amit Varma]: No, I don't think so.

00:24:40.880 --> 00:24:43.680
[Amit Varma]: I think the state's legitimate duty, I mean, we can agree to disagree, but I think the

00:24:43.680 --> 00:24:46.840
[Amit Varma]: state's legitimate duty is to protect the rights of its citizens.

00:24:46.840 --> 00:24:50.720
[Amit Varma]: So if you stand up and say, there's Amit, he's a libertarian, kill him, then obviously

00:24:50.720 --> 00:24:54.320
[Amit Varma]: the state, you know, you're being an accessory to a crime or you're causing one to be committed

00:24:54.320 --> 00:24:58.920
[Amit Varma]: and the state is entirely entitled to protect the rights of Amit the libertarian.

00:24:58.920 --> 00:24:59.920
[Amit Varma]: Yeah.

00:24:59.920 --> 00:25:04.080
[Amit Varma]: And I don't consider that paternalism, but paternalism would be to say that if you are

00:25:04.080 --> 00:25:08.640
[Amit Varma]: to say that libertarians are bad people, and then I protest to the state and I'll say that,

00:25:08.640 --> 00:25:10.160
[Amit Varma]: please make Nikhil shut up.

00:25:10.160 --> 00:25:11.640
[Guest]: We should never be able to say this again.

00:25:11.640 --> 00:25:12.640
[Guest]: That is wrong.

00:25:12.640 --> 00:25:17.400
[Guest]: Even the judgment looks at, at advocacy and incitement differently.

00:25:17.400 --> 00:25:18.400
[Guest]: Right, right.

00:25:18.400 --> 00:25:22.320
[Guest]: And there's nothing wrong with advocacy, which is what this judgment clearly defines.

00:25:22.320 --> 00:25:24.120
[Guest]: So, but again, we've moved away from...

00:25:24.120 --> 00:25:25.120
[Amit Varma]: Yeah, exactly.

00:25:25.120 --> 00:25:29.240
[Unknown]: These are the minor things we can agree to disagree about, the meaning of words.

00:25:29.240 --> 00:25:30.240
[Guest]: Yeah, exactly.

00:25:30.240 --> 00:25:31.720
[Guest]: I'm just like, where did we go?

00:25:31.720 --> 00:25:35.480
[Guest]: So, so let's go back to the concentration of power and what that means, because what's

00:25:35.480 --> 00:25:43.720
[Guest]: happened since 2012-2013 is that these large platforms have become substantially large.

00:25:43.720 --> 00:25:55.960
[Guest]: So between Tencent, Baidu, Amazon, Google, Apple, Microsoft, Facebook, the world's essentially

00:25:55.960 --> 00:25:57.960
[Guest]: being carved out amongst these players.

00:25:57.960 --> 00:26:03.200
[Guest]: Now there's competition that's taking place between them, but each of them has a disproportionate

00:26:03.200 --> 00:26:09.280
[Guest]: amount of ability to influence the future of countries and indeed the future of the

00:26:09.280 --> 00:26:10.280
[Guest]: internet.

00:26:10.280 --> 00:26:16.520
[Guest]: So I think, so what I'm worried about is like, I'm someone who started a site almost 10 years

00:26:16.520 --> 00:26:22.840
[Guest]: ago with very little money, and now we've been around for 10 years, our ability to do,

00:26:22.840 --> 00:26:28.360
[Guest]: so for example, advertising as a revenue source has been shrinking substantially because all

00:26:28.360 --> 00:26:32.160
[Guest]: of it is being aggregated by Facebook and Google.

00:26:32.160 --> 00:26:37.400
[Guest]: Now this is legitimately one market power, the way I see it.

00:26:37.400 --> 00:26:39.960
[Guest]: But it's also inhibiting competition.

00:26:39.960 --> 00:26:45.760
[Guest]: And so therefore, antitrust can't quite kick in because, one, there is no indication of

00:26:45.760 --> 00:26:52.160
[Guest]: clear harm, but also there is no clear indication that these guys are doing something to inhibit

00:26:52.160 --> 00:26:56.960
[Unknown]: There's no nefarious activity.

00:26:56.960 --> 00:27:02.360
[Guest]: But at the same time, is that healthy for the space is something which is being debated

00:27:02.360 --> 00:27:03.360
[Guest]: right now.

00:27:03.360 --> 00:27:07.880
[Guest]: It's the shrinking of the web, you know, so you're more likely to start a business, an

00:27:07.880 --> 00:27:13.840
[Guest]: e-commerce site, for example, on an e-commerce service on Amazon, rather than start your

00:27:13.840 --> 00:27:20.720
[Guest]: own e-commerce portal now, because market power is retained by Amazon and Flipkart,

00:27:20.720 --> 00:27:21.720
[Amit Varma]: for that matter.

00:27:21.720 --> 00:27:27.000
[Guest]: But here's the dilemma, so that, so that, that fragmentation, which was the internet,

00:27:27.000 --> 00:27:31.600
[Guest]: and the impact that that had on allowing people to come and have the freedom to create the

00:27:31.600 --> 00:27:37.060
[Guest]: freedom to build something of their own, is kind of getting lost bit by bit.

00:27:37.060 --> 00:27:41.660
[Guest]: So I'm worried about where we're going here, because then what happens is, instead of that

00:27:41.660 --> 00:27:47.100
[Guest]: free open space, which we had, we will now all be subject to the terms and conditions

00:27:47.100 --> 00:27:51.960
[Guest]: of these platforms, because really, we don't have any other place to play on anymore.

00:27:51.960 --> 00:27:55.720
[Amit Varma]: So what are the kind of solutions that you propose, number one, and number two, what

00:27:55.720 --> 00:27:59.800
[Amit Varma]: are the kind of solutions you're worried about coming from governments or other parties?

00:27:59.800 --> 00:28:03.760
[Guest]: So I don't really have a solution right now, I have more of a problem that I'm trying to

00:28:03.760 --> 00:28:05.840
[Guest]: articulate.

00:28:05.840 --> 00:28:09.360
[Guest]: Because I'm also someone who wants limited government action and all of this, right?

00:28:09.360 --> 00:28:12.520
[Guest]: Because I don't want us to lose intermediary liability protections.

00:28:12.520 --> 00:28:17.960
[Guest]: You know, even if you think about it, net neutrality was exactly that battle, that the

00:28:17.960 --> 00:28:25.640
[Guest]: ISPs should not shape our internet experience, because they have exclusive access, or exclusive

00:28:25.640 --> 00:28:29.800
[Guest]: ability to control how we access the internet.

00:28:29.800 --> 00:28:36.000
[Guest]: And there was a great deal of cartelization in India, which now has been affected, or

00:28:36.000 --> 00:28:38.800
[Guest]: no longer exists because Jio came in.

00:28:38.800 --> 00:28:43.780
[Guest]: But I think the best analogy that I heard for ISPs, and I think we need to look at other

00:28:43.780 --> 00:28:50.000
[Guest]: platforms from that perspective as well, is to think of them as stock exchanges.

00:28:50.000 --> 00:28:56.080
[Guest]: So like, if a stock exchange starts prioritizing a particular trade, it reduces trust in that

00:28:56.080 --> 00:28:58.240
[Guest]: stock exchange.

00:28:58.240 --> 00:29:06.960
[Guest]: In the same way, if an ISP starts prioritizing one source of data versus another, makes it

00:29:06.960 --> 00:29:13.040
[Guest]: cheaper for you to access one particular source of, let's say, videos versus another, they're

00:29:13.040 --> 00:29:17.600
[Guest]: shaping your experience, and that reduces trust in the ISP itself.

00:29:17.600 --> 00:29:24.560
[Guest]: Now, in an open free market situation, you would have a million other ISPs to go to.

00:29:24.560 --> 00:29:29.040
[Guest]: But that doesn't happen because spectrum is limited, right of way access is limited.

00:29:29.040 --> 00:29:31.560
[Guest]: We don't have unbundling of the last mile in India.

00:29:31.560 --> 00:29:35.200
[Guest]: And therefore, these are the controllers of our access in a sense.

00:29:35.200 --> 00:29:39.400
[Guest]: So let's say if you think about from free speech perspective, you and I are talking

00:29:39.400 --> 00:29:40.840
[Guest]: face to face.

00:29:40.840 --> 00:29:44.360
[Guest]: But when we're talking over the internet, there are multiple layers that come in.

00:29:44.360 --> 00:29:50.480
[Guest]: So one is the it starts with the device, then it goes to the network, which is the ISP,

00:29:50.480 --> 00:29:56.400
[Guest]: then there are submarine cable providers, then there are platforms to which that data

00:29:56.400 --> 00:29:58.120
[Guest]: goes.

00:29:58.120 --> 00:30:02.700
[Guest]: Then again, the same exercise towards the person who's receiving it, right.

00:30:02.700 --> 00:30:07.960
[Guest]: So all of these players in the middle have the potential for changing how we communicate,

00:30:07.960 --> 00:30:10.520
[Guest]: whether we're able to speak to each other or not.

00:30:10.520 --> 00:30:14.440
[Amit Varma]: I'd say one important thing about free speech, and a lot of people don't get this, like often

00:30:14.440 --> 00:30:17.720
[Guest]: if I block someone on Twitter, they'll be like, you're attacking my free speech.

00:30:17.720 --> 00:30:20.680
[Unknown]: Well, the truth is that you can say whatever you want, you can choose not to receive, you

00:30:20.680 --> 00:30:24.760
[Amit Varma]: are not entitled to my attention, you're entitled to say whatever you want in your own space.

00:30:24.760 --> 00:30:28.480
[Amit Varma]: So similarly, in this case, we are not like if you and I want to communicate online, and

00:30:28.480 --> 00:30:31.240
[Amit Varma]: of course, we are going through all these different intermediaries.

00:30:31.240 --> 00:30:33.760
[Amit Varma]: But we are not entitled to any platforms.

00:30:33.760 --> 00:30:37.000
[Amit Varma]: And as long as we have a choice of platforms, it should not matter.

00:30:37.000 --> 00:30:40.080
[Guest]: But the point you're making is we don't, we don't, you see, because you will not have

00:30:40.080 --> 00:30:43.120
[Guest]: 100 million submarine cable providers in the world, right?

00:30:43.120 --> 00:30:48.480
[Guest]: You will not have, you don't even have, let's say you have about 200 or 168, I think ISPs

00:30:48.480 --> 00:30:49.480
[Guest]: in India, right?

00:30:49.480 --> 00:30:52.720
[Guest]: But really, three or four of them own most of the access, right?

00:30:52.720 --> 00:30:56.040
[Guest]: In the same way, but they compete with each other or other cartels.

00:30:56.040 --> 00:31:01.800
[Guest]: So I view them as so the smaller ones are too small to compete with the larger ones

00:31:01.800 --> 00:31:03.320
[Amit Varma]: which operate like cartels.

00:31:03.320 --> 00:31:05.760
[Amit Varma]: And the smaller ones will depend on the larger ones also to a lesser extent.

00:31:05.760 --> 00:31:09.400
[Guest]: There is a great deal of dependency between them also, also because when it comes to international

00:31:09.400 --> 00:31:12.920
[Guest]: bandwidth access, there are only very few gateways.

00:31:12.920 --> 00:31:15.840
[Guest]: And many of those ISPs also own the gateways.

00:31:15.840 --> 00:31:20.640
[Guest]: So therefore, you know, what I'm saying is that it's the number of intermediaries in

00:31:20.640 --> 00:31:26.320
[Guest]: this entire process can change the way we communicate, can prevent us from communicating.

00:31:26.320 --> 00:31:32.720
[Guest]: And therefore, you need neutrality in their behavior to ensure that free speech is communicated.

00:31:32.720 --> 00:31:36.240
[Guest]: The other thing is that I don't, and this, this is a, this is something which a lot of

00:31:36.240 --> 00:31:37.440
[Guest]: people miss, right?

00:31:37.440 --> 00:31:41.720
[Guest]: And especially libertarians, which is that the internet is not just a market.

00:31:41.720 --> 00:31:46.920
[Guest]: So one of the things that many people, especially libertarians miss is that the internet is

00:31:46.920 --> 00:31:48.760
[Guest]: not just a marketplace.

00:31:48.760 --> 00:31:51.480
[Guest]: It's also a global public commons, right?

00:31:51.480 --> 00:31:54.000
[Guest]: We don't just sell what we create.

00:31:54.000 --> 00:32:00.480
[Guest]: There is contribution that's happening to community run spaces, community owned spaces.

00:32:00.480 --> 00:32:04.880
[Guest]: So if you think about Wikipedia, if you think about GitHub and the code that's created,

00:32:04.880 --> 00:32:09.320
[Guest]: the ability for us to contribute to each and all of these are also own platforms run by

00:32:09.320 --> 00:32:11.160
[Guest]: separate organizations.

00:32:11.160 --> 00:32:14.720
[Guest]: But the ability for us to contribute to each other, you know, this is the space that's

00:32:14.720 --> 00:32:16.720
[Amit Varma]: given us the creative commons license, for example.

00:32:16.720 --> 00:32:19.760
[Amit Varma]: That's the definition of a market, by the way, a market basically is a web of voluntary

00:32:19.760 --> 00:32:20.760
[Guest]: interactions.

00:32:20.760 --> 00:32:21.760
[Guest]: That's all it is.

00:32:21.760 --> 00:32:28.520
[Guest]: But you get the gist of what I'm saying, it's not just, it's not just owned by private parties

00:32:28.520 --> 00:32:29.520
[Amit Varma]: in that sense.

00:32:29.520 --> 00:32:32.300
[Amit Varma]: So tell me something, and this is probably the gist of everything.

00:32:32.300 --> 00:32:33.300
[Amit Varma]: What do you want the government to do?

00:32:33.300 --> 00:32:36.320
[Guest]: And what do you want the government to not do?

00:32:36.320 --> 00:32:38.560
[Guest]: I don't really have an answer to that question.

00:32:38.560 --> 00:32:41.480
[Amit Varma]: Because given a part answer, what do you want, what are you worried that the government might

00:32:41.480 --> 00:32:45.520
[Amit Varma]: do, which, for example, the government could easily overreach, overregulate and become

00:32:45.520 --> 00:32:46.520
[Guest]: totalitarian.

00:32:46.520 --> 00:32:47.520
[Guest]: No, no.

00:32:47.520 --> 00:32:53.200
[Guest]: So this is where I'm sort of caught in a bind saying that, I do believe that we need regulation

00:32:53.200 --> 00:33:00.200
[Guest]: to ensure neutrality and to ensure that, for example, national interest is protected, citizens

00:33:00.200 --> 00:33:08.000
[Guest]: are protected, foreign actors can't come in and manipulate elections in our country.

00:33:08.000 --> 00:33:14.360
[Guest]: At the same time, I'm afraid of overregulation, which might create, put in liability on these

00:33:14.360 --> 00:33:15.360
[Guest]: intermediaries.

00:33:15.360 --> 00:33:19.880
[Guest]: You know, so if, if there is liability, then there is no reason to do this business in

00:33:19.880 --> 00:33:20.880
[Guest]: that sense.

00:33:20.880 --> 00:33:21.880
[Amit Varma]: It's a chilling effect.

00:33:21.880 --> 00:33:23.200
[Guest]: Then it's not just a chilling effect.

00:33:23.200 --> 00:33:27.160
[Guest]: If it's just, it's impossible for these businesses to sustain.

00:33:27.160 --> 00:33:28.160
[Unknown]: So I'll give you an example.

00:33:28.160 --> 00:33:29.160
[Unknown]: Sorry?

00:33:29.160 --> 00:33:30.160
[Unknown]: It stops everything, right?

00:33:30.160 --> 00:33:31.160
[Unknown]: It shuts you down.

00:33:31.160 --> 00:33:33.480
[Guest]: So think about it this way.

00:33:33.480 --> 00:33:38.520
[Guest]: If YouTube was held liable for every video that's put up on YouTube, the number of court

00:33:38.520 --> 00:33:41.320
[Guest]: cases would essentially kill YouTube, right?

00:33:41.320 --> 00:33:44.200
[Amit Varma]: So there are more lawyers than coders.

00:33:44.200 --> 00:33:51.320
[Amit Varma]: There are more content creators than there are lawyers.

00:33:51.320 --> 00:33:53.320
[Guest]: And so therefore each is a case in that sense.

00:33:53.320 --> 00:33:58.560
[Guest]: And so this is the safe harbor that these intermediaries have gotten, has given us the

00:33:58.560 --> 00:33:59.560
[Guest]: internet that we have.

00:33:59.560 --> 00:34:03.120
[Guest]: Like one of the things that's happening amongst the music industry, for example, and this

00:34:03.120 --> 00:34:06.960
[Guest]: is based on conversations I've had with a bunch of people in the music business over

00:34:06.960 --> 00:34:12.800
[Guest]: the years in India, is that they want the ISPs to be held liable for piracy, saying

00:34:12.800 --> 00:34:17.960
[Guest]: that the ISPs are distributors of pirated content and they make money because we download

00:34:17.960 --> 00:34:20.520
[Guest]: more, etc, etc, etc.

00:34:20.520 --> 00:34:22.880
[Guest]: If that happens, ISPs would shut down essentially.

00:34:22.880 --> 00:34:23.880
[Amit Varma]: And that's absurd.

00:34:23.880 --> 00:34:27.000
[Amit Varma]: I mean, it's like saying that if someone takes stolen goods on a road, then the person who

00:34:27.000 --> 00:34:28.280
[Guest]: owns the road should be liable.

00:34:28.280 --> 00:34:29.280
[Guest]: Exactly.

00:34:29.280 --> 00:34:34.040
[Guest]: But this is still an argument which finds favor with some people in government, with

00:34:34.040 --> 00:34:35.680
[Guest]: some regulators.

00:34:35.680 --> 00:34:41.280
[Guest]: And so therefore I worry about opening the gates to government regulation there, right?

00:34:41.280 --> 00:34:46.520
[Guest]: And what's going to happen as a consequence of that could be disastrous for internet and

00:34:46.520 --> 00:34:47.760
[Unknown]: disastrous for users.

00:34:47.760 --> 00:34:49.920
[Guest]: So does deregulation work as a solution over here?

00:34:49.920 --> 00:34:54.240
[Guest]: Again, deregulation also doesn't work because we are currently operating in a deregulated

00:34:54.240 --> 00:34:55.240
[Guest]: space.

00:34:55.240 --> 00:35:00.720
[Guest]: And without any regulation, we have, you know, several problems which have cropped up, like

00:35:00.720 --> 00:35:07.200
[Guest]: for example, fake news, a large amount of hate speech and abuse, a significant amount

00:35:07.200 --> 00:35:15.280
[Guest]: of privacy violations, the creation of filter bubbles, you know, terrorist outfits, using

00:35:15.280 --> 00:35:17.440
[Guest]: that anonymity that the internet provides.

00:35:17.440 --> 00:35:21.840
[Guest]: And I mean, I'm someone who supports anonymity because it gives vulnerable communities a

00:35:21.840 --> 00:35:22.840
[Guest]: voice.

00:35:22.840 --> 00:35:28.280
[Guest]: But the same anonymity has also been used, for example, by ISIS handles, right?

00:35:28.280 --> 00:35:30.760
[Guest]: So there's no right answer to this.

00:35:30.760 --> 00:35:32.760
[Guest]: We have to find a balance.

00:35:32.760 --> 00:35:36.920
[Guest]: Because somewhere we have to look at from a harms regulation perspective.

00:35:36.920 --> 00:35:41.880
[Guest]: So the other part of this entire platform battle that's going on is around data protection

00:35:41.880 --> 00:35:43.540
[Guest]: and privacy.

00:35:43.540 --> 00:35:51.200
[Guest]: Because the amount of data that they're collecting, that gives them the ability to, again, create

00:35:51.200 --> 00:35:56.200
[Guest]: more filter bubbles, target people better, allow advertisers to target people more sharply

00:35:56.200 --> 00:36:00.440
[Guest]: and yet not control what kind of communication advertising is going there.

00:36:00.440 --> 00:36:05.480
[Guest]: Because it's going at such a large scale, it's impossible for them to monitor as well.

00:36:05.480 --> 00:36:09.320
[Guest]: So we've got this beast that we're dealing with right now.

00:36:09.320 --> 00:36:12.560
[Guest]: And we want the beast because there's great benefit that comes from it.

00:36:12.560 --> 00:36:15.680
[Guest]: But there's also great harms that come from it.

00:36:15.680 --> 00:36:20.340
[Guest]: And so somewhere from a deregulation perspective, you know, so, for example, net neutrality

00:36:20.340 --> 00:36:25.480
[Guest]: is a kind of deregulation because through the regulation of imposing net neutrality,

00:36:25.480 --> 00:36:27.560
[Guest]: you have a deregulated space on the internet.

00:36:27.560 --> 00:36:28.560
[Guest]: Right?

00:36:28.560 --> 00:36:34.480
[Guest]: So, I don't exactly agree, there are laws which govern them.

00:36:34.480 --> 00:36:38.040
[Guest]: And largely, it allows the freedom to do legal things.

00:36:38.040 --> 00:36:42.160
[Amit Varma]: I think, moving aside from like these specific issues.

00:36:42.160 --> 00:36:44.360
[Guest]: Let me just, there are two other things.

00:36:44.360 --> 00:36:49.320
[Guest]: One of the things that we still, that is going to come up for discussion is algorithmic neutrality.

00:36:49.320 --> 00:36:56.720
[Guest]: Because it's the way the algorithms are functioning without regulation, being a black box that

00:36:56.720 --> 00:37:02.800
[Guest]: is impacting the content that people consume, and has a potential to impact again, has a

00:37:02.800 --> 00:37:07.960
[Guest]: potential to impact democracies, device neutrality is another one that's going to come up around

00:37:07.960 --> 00:37:08.960
[Amit Varma]: that same issue.

00:37:08.960 --> 00:37:12.640
[Amit Varma]: So I think trying to enforce some of these neutralities, like telling a company what

00:37:12.640 --> 00:37:17.240
[Unknown]: kind of algorithms it can or cannot use is problematic in some senses.

00:37:17.240 --> 00:37:20.120
[Unknown]: By definition, they're going to have bias built in and they're made by humans, right?

00:37:20.120 --> 00:37:25.000
[Guest]: So here's where the intermediary liability comes back to this discussion, right?

00:37:25.000 --> 00:37:31.080
[Guest]: It's applicable to platforms, and effectively is based on the fact that platforms have no

00:37:31.080 --> 00:37:34.160
[Guest]: say in what people consume.

00:37:34.160 --> 00:37:40.280
[Guest]: Now, if an algorithm is controlling what you can consume, effectively, it's no longer a

00:37:40.280 --> 00:37:41.400
[Guest]: neutral platform.

00:37:41.400 --> 00:37:44.560
[Guest]: It's an intermediate liability, protections will not be available.

00:37:44.560 --> 00:37:49.680
[Amit Varma]: But see, here's the thing, every algorithm, as Amit just said, is, will have some kind

00:37:49.680 --> 00:37:50.680
[Unknown]: of bias.

00:37:50.680 --> 00:37:54.400
[Unknown]: You're right, but I buy what he's saying as well, that I mean, like the second you introduce

00:37:54.400 --> 00:37:58.640
[Amit Varma]: the bias into the system, at that point in time, it's no longer neutral.

00:37:58.640 --> 00:38:01.800
[Amit Varma]: Yeah, but the moment you try to regulate the bias, you introduce another bias into the

00:38:01.800 --> 00:38:02.800
[Amit Varma]: system.

00:38:02.800 --> 00:38:06.320
[Amit Varma]: I don't think, I think the important thing here is you let users choose between biases.

00:38:06.320 --> 00:38:07.720
[Guest]: That's exactly the solution, right?

00:38:07.720 --> 00:38:12.640
[Guest]: So if let's say, on Facebook, I had the ability to delete my entire history, right?

00:38:12.640 --> 00:38:14.400
[Guest]: And start over, right?

00:38:14.400 --> 00:38:16.280
[Guest]: I don't right now.

00:38:16.280 --> 00:38:21.680
[Guest]: But I can have a fresh newsfeed with no bias in the system at that point in time, right?

00:38:21.680 --> 00:38:22.680
[Guest]: That freedom is useful.

00:38:22.680 --> 00:38:29.160
[Guest]: If I had, let's say, four different algorithms to choose from, or maybe 100 different algorithms

00:38:29.160 --> 00:38:33.240
[Guest]: to choose from, that again, allows me choice from that perspective.

00:38:33.240 --> 00:38:39.200
[Amit Varma]: But to get to that space from here, isn't a better way of doing it, consumer activism,

00:38:39.200 --> 00:38:42.360
[Amit Varma]: users saying that, hey, no, we don't like these features, we want those, rather than

00:38:42.360 --> 00:38:43.360
[Amit Varma]: government regulation.

00:38:43.360 --> 00:38:46.600
[Unknown]: I mean, I know you're not suggesting that, but I think the classic problematic in this

00:38:46.600 --> 00:38:47.600
[Unknown]: kind of a situation, right?

00:38:47.600 --> 00:38:52.040
[Unknown]: I mean, like, how is any kind of government action going to be able to define the rules

00:38:52.040 --> 00:38:53.520
[Unknown]: that algorithms need to function under?

00:38:53.520 --> 00:38:56.200
[Guest]: I mean, like, how is that even a possibility?

00:38:56.200 --> 00:39:01.920
[Guest]: So there are discussions that are going on around that, which is around essentially regulating

00:39:01.920 --> 00:39:03.840
[Guest]: for harms.

00:39:03.840 --> 00:39:09.240
[Guest]: So if there is demonstrable harm that's coming out from an algorithm, and you can feed a

00:39:09.240 --> 00:39:14.720
[Guest]: data set to see what's happening there, there is a potential for regulation to go and correct

00:39:14.720 --> 00:39:15.720
[Unknown]: it.

00:39:15.720 --> 00:39:16.720
[Unknown]: That feels very nebulous to me.

00:39:16.720 --> 00:39:18.560
[Guest]: It's a complicated one.

00:39:18.560 --> 00:39:19.600
[Guest]: And these are early days.

00:39:19.600 --> 00:39:23.520
[Guest]: What I'm pointing towards is that these things are going to happen in the future.

00:39:23.520 --> 00:39:28.400
[Guest]: Because this problem is only growing, right, and the US elections is a clear indication,

00:39:28.400 --> 00:39:30.520
[Guest]: elections in Italy as well.

00:39:30.520 --> 00:39:35.800
[Guest]: So these are, I mean, we have, in India here, we have a major fake news problem right now.

00:39:35.800 --> 00:39:40.780
[Guest]: And again, that's again, two internet issues fighting off against each other, right?

00:39:40.780 --> 00:39:42.840
[Guest]: So one is the problem of fake news.

00:39:42.840 --> 00:39:44.220
[Guest]: The other is need for privacy.

00:39:44.220 --> 00:39:48.000
[Guest]: You have end-to-end encryption on WhatsApp, but WhatsApp is where most of the fake news

00:39:48.000 --> 00:39:49.640
[Guest]: is being distributed.

00:39:49.640 --> 00:39:51.120
[Guest]: It's the largest media platform in the country.

00:39:51.120 --> 00:39:53.720
[Amit Varma]: And again, there's a human tendency and hunger for fake news.

00:39:53.720 --> 00:39:55.160
[Amit Varma]: So in a sense, we're shooting the messenger.

00:39:55.160 --> 00:39:59.720
[Amit Varma]: But what you're saying is also cautionary in a sense, because I know you'll agree with

00:39:59.720 --> 00:40:04.040
[Amit Varma]: my principle that whenever you give government any kind of power, you have to assume that

00:40:04.040 --> 00:40:06.280
[Amit Varma]: it will necessarily be misused.

00:40:06.280 --> 00:40:10.880
[Amit Varma]: So if you give government the power to regulate Facebook, then assume that if you're a left

00:40:10.880 --> 00:40:14.400
[Amit Varma]: liberal, assume that Yogi Adityanath will be prime minister and he'll be running, he'll

00:40:14.400 --> 00:40:16.160
[Amit Varma]: be setting that regulation.

00:40:16.160 --> 00:40:22.640
[Amit Varma]: And if you are more culturally oriented and not anti-national, then assume that Sonia

00:40:22.640 --> 00:40:25.080
[Amit Varma]: Gandhi will be somehow in charge and running.

00:40:25.080 --> 00:40:29.000
[Amit Varma]: You have to assume that the worst person you can think of is in power in the government

00:40:29.000 --> 00:40:33.160
[Amit Varma]: and give power to the government accordingly and build in enough safeguards to that accordingly.

00:40:33.160 --> 00:40:35.220
[Guest]: No, so we need the safeguards there.

00:40:35.220 --> 00:40:38.700
[Guest]: So we need regulation with oversight and safeguards.

00:40:38.700 --> 00:40:40.840
[Guest]: And of course, it's not a perfect science.

00:40:40.840 --> 00:40:43.920
[Guest]: We've had issues in every single instance where this has happened.

00:40:43.920 --> 00:40:48.960
[Guest]: But I think we have, the world is fast reaching a point where doing nothing is not an option.

00:40:48.960 --> 00:40:53.960
[Amit Varma]: I think, you know, the problem with India essentially is that a lot of the problems

00:40:53.960 --> 00:40:57.920
[Amit Varma]: that are caused by government, people can't think of any other solution to them, but more

00:40:57.920 --> 00:40:59.000
[Guest]: government.

00:40:59.000 --> 00:41:00.400
[Guest]: But this is not just India, right?

00:41:00.400 --> 00:41:01.800
[Guest]: If you look at...

00:41:01.800 --> 00:41:06.400
[Guest]: And this is a social problem, but all social problems cannot be solved by government intervention.

00:41:06.400 --> 00:41:11.360
[Guest]: If you look at Trump's election, for example, and the alleged usage of misinformation, filter

00:41:11.360 --> 00:41:15.960
[Guest]: bubbles by... and the Russian involvement and all of that... by the Russians, in fact,

00:41:15.960 --> 00:41:20.240
[Guest]: and the impact that that has had, like I gave you that example of, hey, you can go on the

00:41:20.240 --> 00:41:21.240
[Guest]: site and vote.

00:41:21.240 --> 00:41:23.240
[Guest]: You don't need to go to the election booth, right?

00:41:23.240 --> 00:41:24.240
[Amit Varma]: Those things are real problems.

00:41:24.240 --> 00:41:25.240
[Amit Varma]: But here's my point.

00:41:25.240 --> 00:41:28.720
[Amit Varma]: See, I find Trump's election very distasteful and disturbing and literally depressing.

00:41:28.720 --> 00:41:32.440
[Amit Varma]: I was just very sad that day and I was also the same day demonetization happened.

00:41:32.440 --> 00:41:35.540
[Amit Varma]: So it was a double whammy for all of us believers in liberty.

00:41:35.540 --> 00:41:39.840
[Amit Varma]: But then the point is, people are entitled to vote as they want, to get whatever news

00:41:39.840 --> 00:41:42.280
[Amit Varma]: they want, to believe whatever they want.

00:41:42.280 --> 00:41:43.280
[Amit Varma]: That's the heart of individual freedom.

00:41:43.280 --> 00:41:48.440
[Amit Varma]: Now, I agree, there's a social problem there, which you've correctly identified, the filter

00:41:48.440 --> 00:41:49.720
[Guest]: bubbles and blah, blah, blah.

00:41:49.720 --> 00:41:55.400
[Guest]: What you're ignoring there is the issue of bounded rationality and information asymmetry.

00:41:55.400 --> 00:41:57.760
[Amit Varma]: Both of these issues are very real.

00:41:57.760 --> 00:42:01.680
[Amit Varma]: I'm taking those for granted, but I'm saying government intervention leads you to totalitarianism

00:42:01.680 --> 00:42:02.680
[Guest]: in this case.

00:42:02.680 --> 00:42:04.840
[Guest]: So that's what I'm saying.

00:42:04.840 --> 00:42:10.760
[Guest]: My point here is, I'm someone who was inherently opposed to the idea of government regulating

00:42:10.760 --> 00:42:14.000
[Unknown]: a space that means freedom for me.

00:42:14.000 --> 00:42:18.000
[Guest]: But I have my senses, this is bound to happen now.

00:42:18.000 --> 00:42:23.400
[Guest]: This is and because this is, unfortunately, an idea whose time has come because of all

00:42:23.400 --> 00:42:24.400
[Guest]: the dangers.

00:42:24.400 --> 00:42:26.560
[Guest]: And it started with the Arab Spring.

00:42:26.560 --> 00:42:32.560
[Guest]: We've come a long way from the Arab Spring where, you know, it was people on Facebook

00:42:32.560 --> 00:42:37.080
[Guest]: who got together and that led to a revolution.

00:42:37.080 --> 00:42:42.240
[Guest]: Here now, it's been a change in government and electing someone is being instigated through

00:42:42.240 --> 00:42:43.580
[Guest]: these means.

00:42:43.580 --> 00:42:47.480
[Guest]: So I don't think there's any going back from there, because every single government in

00:42:47.480 --> 00:42:51.160
[Amit Varma]: the world from now on is going to be conscious.

00:42:51.160 --> 00:42:54.400
[Amit Varma]: So I want to ask you another different follow up question and go deeper into this.

00:42:54.400 --> 00:42:59.080
[Amit Varma]: But before that, I'd just like to say that, look, a problem which is caused by the large

00:42:59.080 --> 00:43:04.080
[Amit Varma]: scale voluntary actions of individuals can only, in my view, be solved by the large scale

00:43:04.080 --> 00:43:06.480
[Amit Varma]: voluntary actions of individuals, whatever form it takes.

00:43:06.480 --> 00:43:07.480
[Amit Varma]: And it's an unknown, unknown.

00:43:07.480 --> 00:43:08.480
[Guest]: We don't know what that is.

00:43:08.480 --> 00:43:15.480
[Guest]: But then what you're doing is you're ignoring a period of indoctrination, using fake information

00:43:15.480 --> 00:43:17.720
[Guest]: to make people believe that something is real.

00:43:17.720 --> 00:43:23.600
[Guest]: Because I mean, if you look at it, we are in an era where there is going to be AI generated

00:43:23.600 --> 00:43:24.600
[Amit Varma]: videos.

00:43:24.600 --> 00:43:25.600
[Amit Varma]: Absolutely.

00:43:25.600 --> 00:43:27.960
[Guest]: And for most people, they will not be able to make out the difference between one and

00:43:27.960 --> 00:43:28.960
[Amit Varma]: the other.

00:43:28.960 --> 00:43:33.240
[Amit Varma]: If you are able to have a podcast where you are attacking net neutrality and saying completely

00:43:33.240 --> 00:43:35.000
[Guest]: the opposite things, AI can do that.

00:43:35.000 --> 00:43:36.000
[Guest]: But that wouldn't be me.

00:43:36.000 --> 00:43:37.000
[Guest]: It would be your voice.

00:43:37.000 --> 00:43:42.120
[Amit Varma]: Anyway, so the question I want to ask is, like, we are more or less on the same page.

00:43:42.120 --> 00:43:47.800
[Amit Varma]: These are minor sort of bickerings, which, you know, can, which are the fun things to

00:43:47.800 --> 00:43:48.800
[Unknown]: talk about.

00:43:48.800 --> 00:43:49.800
[Amit Varma]: We're pretty much on the same page.

00:43:49.800 --> 00:43:55.080
[Amit Varma]: But so my question here goes away from the problem itself, to the kind of activism you've

00:43:55.080 --> 00:43:57.760
[Amit Varma]: done where you did the Save the Internet campaign and so on.

00:43:57.760 --> 00:44:02.520
[Amit Varma]: And my question is this, can you tell me a little bit about the different interest groups

00:44:02.520 --> 00:44:08.760
[Amit Varma]: involved and what the interplay between them is, for example, a big company would, contrary

00:44:08.760 --> 00:44:12.440
[Amit Varma]: to what people think always be against free markets, they'd be looking to consolidate

00:44:12.440 --> 00:44:19.000
[Amit Varma]: their turf and to prevent newcomers from coming in and they'd be against competition.

00:44:19.000 --> 00:44:22.520
[Amit Varma]: Similarly, you would have small groups of people with absolutely no voice like you and

00:44:22.520 --> 00:44:25.520
[Amit Varma]: me who would want competition and want markets to prevail.

00:44:25.520 --> 00:44:30.520
[Amit Varma]: Similarly, you would have different government bodies operating in their own silos, who would

00:44:30.520 --> 00:44:34.240
[Amit Varma]: want to explore opportunities for rent seeking.

00:44:34.240 --> 00:44:37.680
[Amit Varma]: So how do, how does an interplay between the different interest group play out?

00:44:37.680 --> 00:44:38.680
[Amit Varma]: Like, what are they?

00:44:38.680 --> 00:44:42.400
[Amit Varma]: And you've actually been part of negotiating with all of these interest groups, right at

00:44:42.400 --> 00:44:43.400
[Guest]: different points in time.

00:44:43.400 --> 00:44:48.600
[Guest]: So, so the way I looked at that campaign and the way we started it was this idea that we

00:44:48.600 --> 00:44:53.520
[Guest]: need to first inform people and then give them a voice.

00:44:53.520 --> 00:44:59.080
[Guest]: And interest groups will align in whichever way they want, but if there are enough people

00:44:59.080 --> 00:45:05.080
[Guest]: involved and enough people who support net neutrality, people will align in support.

00:45:05.080 --> 00:45:07.080
[Guest]: So you decided to make it a mass movement?

00:45:07.080 --> 00:45:10.940
[Guest]: We decided to make it a mass movement from the very beginning because, look, I've taken

00:45:10.940 --> 00:45:16.120
[Guest]: part in TRI consultations over, I mean, over the last decade on several occasions.

00:45:16.120 --> 00:45:21.760
[Guest]: I've sat in, I know how the process works and the TRI really has the most open and transparent

00:45:21.760 --> 00:45:22.760
[Amit Varma]: process.

00:45:22.760 --> 00:45:23.760
[Amit Varma]: What are their interests?

00:45:23.760 --> 00:45:24.760
[Amit Varma]: What do they want?

00:45:24.760 --> 00:45:25.760
[Amit Varma]: What are their interests?

00:45:25.760 --> 00:45:26.760
[Guest]: What are they fighting for?

00:45:26.760 --> 00:45:27.760
[Guest]: Tell me.

00:45:27.760 --> 00:45:32.320
[Guest]: So historically what's happened with the TRI is that, you know, the industry guys, the

00:45:32.320 --> 00:45:36.600
[Guest]: lobbyists for mobile operators, etc, go and visit them twice a week.

00:45:36.600 --> 00:45:38.520
[Guest]: They visit different people.

00:45:38.520 --> 00:45:42.880
[Guest]: They are very organized in terms of they know who to talk to, what about, etc, etc.

00:45:42.880 --> 00:45:49.640
[Guest]: So if you have someone at a regulator who doesn't necessarily have much information

00:45:49.640 --> 00:45:56.640
[Guest]: but is not very tech savvy, then these people become a source of that knowledge for them.

00:45:56.640 --> 00:46:01.480
[Guest]: And of course they do want counterpoints because they want to be neutral in this entire process.

00:46:01.480 --> 00:46:04.240
[Guest]: They want to be fair in this entire process.

00:46:04.240 --> 00:46:08.800
[Guest]: But there aren't enough players on the other side that come and speak to them.

00:46:08.800 --> 00:46:10.920
[Guest]: There's also a credibility issue.

00:46:10.920 --> 00:46:15.000
[Guest]: So for example, who am I to go and speak, even though I have an opportunity?

00:46:15.000 --> 00:46:20.520
[Guest]: Every single individual in this country, every citizen can go and speak at a TRI event, at

00:46:20.520 --> 00:46:25.320
[Guest]: a TRI open house and voice their views on a particular issue.

00:46:25.320 --> 00:46:30.060
[Guest]: What we did was we ensured that there was enough of a collective voice for citizens

00:46:30.060 --> 00:46:36.400
[Guest]: in that particular situation because we were battling all the mobile operators which have

00:46:36.400 --> 00:46:41.680
[Guest]: a tremendous amount of power which the TRI had a great deal of affinity for because they

00:46:41.680 --> 00:46:45.560
[Guest]: instigated this entire consultation process.

00:46:45.560 --> 00:46:50.640
[Guest]: We had politicians who really did not have a clue about what net utility is in the beginning

00:46:50.640 --> 00:46:54.520
[Guest]: and I can't really blame them because most people in this country did not understand

00:46:54.520 --> 00:46:56.480
[Guest]: what it is about.

00:46:56.480 --> 00:47:01.040
[Guest]: We had businesses who again didn't have too much of a clue but there was a clear benefit

00:47:01.040 --> 00:47:07.920
[Guest]: for them in terms of at least the larger players for taking ownership of internet access to

00:47:07.920 --> 00:47:09.520
[Guest]: their own benefit.

00:47:09.520 --> 00:47:14.120
[Guest]: So you had the operators which would enable this, you had the businesses that would benefit

00:47:14.120 --> 00:47:21.040
[Guest]: from it and so utility had no voice in this entire debate and I got this feeling on two

00:47:21.040 --> 00:47:22.660
[Guest]: particular occasions.

00:47:22.660 --> 00:47:30.020
[Guest]: One was the TRI open discussion, they had a discussion with industry stakeholders invited

00:47:30.020 --> 00:47:37.520
[Guest]: on creating a revenue share model between online content creators and service providers

00:47:37.520 --> 00:47:39.640
[Guest]: and the ISPs.

00:47:39.640 --> 00:47:44.600
[Guest]: So they wanted a revenue share so if you have advertising running on your site the ISPs

00:47:44.600 --> 00:47:48.160
[Guest]: would get a revenue share of that advertising.

00:47:48.160 --> 00:47:55.280
[Guest]: So when I saw that TRI seemed to be open to this discussion that was a warning signal

00:47:55.280 --> 00:47:59.480
[Guest]: and it felt very lonely in that room to be honest even though there were a few other

00:47:59.480 --> 00:48:06.880
[Guest]: people who spoke up for net utility but I actually at one point in time stood up and

00:48:06.880 --> 00:48:11.240
[Guest]: pointed towards the free speech argument saying do you realize what you're trying to do over

00:48:11.240 --> 00:48:16.320
[Guest]: here and how it's going to impact people and their communication and that this is going

00:48:16.320 --> 00:48:19.880
[Guest]: to get a constitutional challenge.

00:48:19.880 --> 00:48:23.720
[Guest]: And the TRI backed off a bit, they're like you know we're just discussing stuff here

00:48:23.720 --> 00:48:27.760
[Guest]: but really there was too much power in that room going against us.

00:48:27.760 --> 00:48:34.080
[Guest]: So the idea behind the net utility campaign was that votes beat money and so we went out

00:48:34.080 --> 00:48:39.960
[Guest]: and got the votes and we so we had we had to fight off fairly significant stakeholders.

00:48:39.960 --> 00:48:43.080
[Guest]: I don't know if I've answered your question really.

00:48:43.080 --> 00:48:46.160
[Amit Varma]: No your journey is fascinating and I think both Amit and I agree.

00:48:46.160 --> 00:48:50.000
[Guest]: But I'll tell you where this philosophy is coming from right, there are two core ideas

00:48:50.000 --> 00:48:57.880
[Guest]: to this and one of them is that all of us have a certain amount of free time and if

00:48:57.880 --> 00:49:02.920
[Guest]: we love the internet we should be willing to contribute our time and our effort to making

00:49:02.920 --> 00:49:05.880
[Guest]: it a better space for the generations that are going to follow.

00:49:05.880 --> 00:49:15.320
[Unknown]: Because the internet dies and we'll all have a lot more free time.

00:49:15.320 --> 00:49:22.080
[Guest]: So the other one, the other idea is this idea of active citizenship that we have to become

00:49:22.080 --> 00:49:26.840
[Guest]: active citizens and get involved in these regulatory processes because what happens

00:49:26.840 --> 00:49:32.160
[Guest]: is quite often we delegate that responsibility to our elected representatives or others and

00:49:32.160 --> 00:49:33.680
[Guest]: that's not working for us right.

00:49:33.680 --> 00:49:38.720
[Guest]: I mean Barack Obama has this great quote that we cannot solve the problems of our times

00:49:38.720 --> 00:49:40.720
[Guest]: unless we solve them together.

00:49:40.720 --> 00:49:45.360
[Guest]: So it's important for us to come together around issues that we really care about and

00:49:45.360 --> 00:49:49.760
[Guest]: voice our concerns because there are enough elected representatives who will listen to

00:49:49.760 --> 00:49:50.760
[Guest]: us.

00:49:50.760 --> 00:49:52.800
[Guest]: Governments will listen to us if we speak up.

00:49:52.800 --> 00:49:56.720
[Guest]: But the problem quite often is that we feel that someone else will do our job for us.

00:49:56.720 --> 00:49:59.600
[Amit Varma]: So it sounds like you overcame two classic public choice problems.

00:49:59.600 --> 00:50:01.640
[Amit Varma]: Like these are two problems of public choice theory.

00:50:01.640 --> 00:50:06.080
[Amit Varma]: One is the benefits are concentrated, the costs are diffused.

00:50:06.080 --> 00:50:10.080
[Amit Varma]: So you'll have these interest groups or these big companies making a lot of money but the

00:50:10.080 --> 00:50:13.360
[Amit Varma]: costs are so diffused that the people who are bearing the cost right as the citizens

00:50:13.360 --> 00:50:15.680
[Amit Varma]: they don't even realize what's at stake.

00:50:15.680 --> 00:50:16.680
[Amit Varma]: That's number one.

00:50:16.680 --> 00:50:20.480
[Amit Varma]: And number two is that even if you get all the citizens to agree that hey this is a problem,

00:50:20.480 --> 00:50:23.720
[Amit Varma]: there's what is called the free rider effect where they're willing to let someone else

00:50:23.720 --> 00:50:27.760
[Amit Varma]: fight the battle for them and they'll post supporting tweets and supporting statuses

00:50:27.760 --> 00:50:29.160
[Unknown]: but they won't do something themselves.

00:50:29.160 --> 00:50:33.240
[Guest]: And you kind of overcame both of these.

00:50:33.240 --> 00:50:36.280
[Guest]: And the idea was around how do we get people involved.

00:50:36.280 --> 00:50:37.480
[Guest]: So that's where the tech team came in.

00:50:37.480 --> 00:50:41.640
[Guest]: Like we put together a team in a matter of 12 days where we had a tech team in Bangalore,

00:50:41.640 --> 00:50:45.840
[Guest]: we had a legal and policy team in Delhi and this is basically just me calling up friends

00:50:45.840 --> 00:50:50.080
[Guest]: and saying hey listen this is going down, we need to do something about this.

00:50:50.080 --> 00:50:55.080
[Guest]: And I'll be honest even at that point in time I did not fully understand how to tackle many

00:50:55.080 --> 00:50:57.560
[Guest]: arguments around net neutrality.

00:50:57.560 --> 00:51:00.800
[Guest]: But the thing was that together because we kept debating some of these things we learned

00:51:00.800 --> 00:51:01.920
[Guest]: along the way.

00:51:01.920 --> 00:51:04.840
[Guest]: If I didn't have an answer someone else came up with an answer.

00:51:04.840 --> 00:51:08.520
[Guest]: We crowdsourced a lot of our learning from that perspective and the idea was to give

00:51:08.520 --> 00:51:10.240
[Guest]: people ownership of this movement.

00:51:10.240 --> 00:51:17.000
[Guest]: So another core philosophy of the movement was nobody owns the movement therefore everybody

00:51:17.000 --> 00:51:18.560
[Guest]: owns the movement.

00:51:18.560 --> 00:51:23.120
[Guest]: Because a lot of these battles fall apart when it comes to taking credit.

00:51:23.120 --> 00:51:24.800
[Guest]: And I don't have the credit for this.

00:51:24.800 --> 00:51:27.480
[Guest]: This belongs to everyone who participated.

00:51:27.480 --> 00:51:28.480
[Guest]: This wasn't…

00:51:28.480 --> 00:51:32.280
[Guest]: All I did was go and start asking people for help and trying to give them a reason to get

00:51:32.280 --> 00:51:33.280
[Amit Varma]: involved.

00:51:33.280 --> 00:51:36.680
[Amit Varma]: This in fact runs up against another behavioural economics funder, diffuse responsibility.

00:51:36.680 --> 00:51:40.840
[Amit Varma]: That if too many people have the responsibility for something nobody will do it.

00:51:40.840 --> 00:51:45.040
[Guest]: So this is the opposite of that.

00:51:45.040 --> 00:51:49.680
[Guest]: And I think that what we're seeing now because even around Aadhaar I'm interacting with a

00:51:49.680 --> 00:51:56.440
[Guest]: lot of politicians is that there is a growing concern amongst politicians also that they

00:51:56.440 --> 00:52:03.840
[Guest]: don't necessarily understand tech but they realise the impact that it's having.

00:52:03.840 --> 00:52:08.440
[Guest]: And they want to help understand it from a user perspective, from a citizen perspective

00:52:08.440 --> 00:52:10.840
[Guest]: because that's their core constituency.

00:52:10.840 --> 00:52:16.320
[Guest]: Because historically they've only been visited by interest groups that seek to benefit commercially

00:52:16.320 --> 00:52:17.780
[Guest]: from all of this.

00:52:17.780 --> 00:52:19.360
[Guest]: So I think that the more…

00:52:19.360 --> 00:52:25.400
[Guest]: And we've got social media platforms now that allow us to communicate to our MPs.

00:52:25.400 --> 00:52:30.360
[Guest]: I think one of the things that I want to work on over a period of time is to create more

00:52:30.360 --> 00:52:34.740
[Guest]: platforms for engagement with the policy makers.

00:52:34.740 --> 00:52:37.280
[Guest]: And that could be offline, that could be online.

00:52:37.280 --> 00:52:43.800
[Guest]: I mean we've seen campaigns run where, especially in the US, where people call up their representatives.

00:52:43.800 --> 00:52:45.200
[Guest]: How many of us do that here?

00:52:45.200 --> 00:52:49.800
[Amit Varma]: And you've generally seen that MPs are open to these kinds of engagements?

00:52:49.800 --> 00:52:50.800
[Guest]: Look we've…

00:52:50.800 --> 00:52:56.560
[Guest]: I'm not going to name people, but because we ran the Speak For Me campaign around Aadhaar,

00:52:56.560 --> 00:53:01.440
[Guest]: one of the things that we saw was that there were about, this is what I've heard, that

00:53:01.440 --> 00:53:09.280
[Guest]: there were 11 190 notices that were filed in the winter session of Parliament.

00:53:09.280 --> 00:53:14.840
[Guest]: Because our campaign was around asking MPs to file 190 notices for discussions on Aadhaar

00:53:14.840 --> 00:53:16.600
[Guest]: in Parliament.

00:53:16.600 --> 00:53:20.880
[Guest]: And there were over 100 questions asked about Aadhaar in that session alone, which is the

00:53:20.880 --> 00:53:22.880
[Guest]: largest that I've seen so far.

00:53:22.880 --> 00:53:27.920
[Guest]: So I think that MPs, if citizens reach out to them, they do react, they do respond.

00:53:27.920 --> 00:53:30.440
[Guest]: It's just that historically no one responds to them.

00:53:30.440 --> 00:53:35.560
[Guest]: I mean during the Net Neutrality campaign, some of the MPs got 10s and 15,000 emails

00:53:35.560 --> 00:53:36.560
[Guest]: from citizens.

00:53:36.560 --> 00:53:42.320
[Guest]: These are MPs who typically would get 5 or 10 maybe in a month or something like that.

00:53:42.320 --> 00:53:46.400
[Guest]: When you get that kind of volume, they know that people want to be heard.

00:53:46.400 --> 00:53:48.640
[Guest]: So they are our representatives.

00:53:48.640 --> 00:53:53.000
[Guest]: But our democracy, the way it's built, is that there's a big gap between the citizens

00:53:53.000 --> 00:53:54.800
[Guest]: and the ones we elect.

00:53:54.800 --> 00:53:59.480
[Guest]: And that's largely possible because the scale and no single voice is loud enough.

00:53:59.480 --> 00:54:02.040
[Guest]: But it's almost like the creation of interest groups.

00:54:02.040 --> 00:54:05.320
[Amit Varma]: So you bridge that gap with the very same technology you denigrate.

00:54:05.320 --> 00:54:06.320
[Guest]: I know.

00:54:06.320 --> 00:54:07.320
[Guest]: No, no.

00:54:07.320 --> 00:54:09.440
[Guest]: But I'm saying, so that's, that's the beauty of all of this.

00:54:09.440 --> 00:54:13.640
[Guest]: For every single thing that I've talked about today, there are pros and cons.

00:54:13.640 --> 00:54:15.420
[Guest]: And so the idea is to find a balance.

00:54:15.420 --> 00:54:18.160
[Amit Varma]: And the idea is to make sure the pros are more by voluntary action.

00:54:18.160 --> 00:54:23.400
[Amit Varma]: So I'm going to end by asking both of you two questions, which is, what makes you worried

00:54:23.400 --> 00:54:24.920
[Amit Varma]: about the future of the internet?

00:54:24.920 --> 00:54:27.400
[Amit Varma]: And what makes you hopeful about the future of the internet?

00:54:27.400 --> 00:54:29.000
[Unknown]: Amit, shall we start with you?

00:54:29.000 --> 00:54:30.000
[Unknown]: Sure.

00:54:30.000 --> 00:54:33.760
[Unknown]: So I mean, like worried, I guess would be a lot of what Nikhil is talking about.

00:54:33.760 --> 00:54:37.040
[Unknown]: I think that is kind of a concern.

00:54:37.040 --> 00:54:40.340
[Unknown]: Keep your hands off the internet, basically, you know, I mean, like, that would be my preference.

00:54:40.340 --> 00:54:46.400
[Unknown]: But I also understand that there are compulsions around why that can't be 100% kind of maximalist

00:54:46.400 --> 00:54:47.400
[Unknown]: argument.

00:54:47.400 --> 00:54:49.080
[Unknown]: There has to be like some sort of nuance over there.

00:54:49.080 --> 00:54:51.800
[Unknown]: And in terms of optimistic, I'm just, I'm generally very optimistic.

00:54:51.800 --> 00:54:56.640
[Unknown]: I think that we haven't even, it's not even 20 years old, or it's just 20 years old, 25

00:54:56.640 --> 00:54:57.640
[Unknown]: years old.

00:54:57.640 --> 00:54:58.640
[Unknown]: It's, it's so new.

00:54:58.640 --> 00:55:02.040
[Unknown]: You know, I mean, like in the context of history, I mean, like, we haven't even like scratched

00:55:02.040 --> 00:55:04.040
[Unknown]: the surface of what we're going to get through this.

00:55:04.040 --> 00:55:09.520
[Unknown]: So I mean, like, from an optimistic perspective, I think that just what's going to happen with

00:55:09.520 --> 00:55:13.600
[Unknown]: this stuff is we haven't even seen anything close to what's going to happen.

00:55:13.600 --> 00:55:14.600
[Guest]: Nikhil.

00:55:14.600 --> 00:55:18.560
[Guest]: So you don't know what you've lost till it's gone.

00:55:18.560 --> 00:55:25.400
[Guest]: And so I am extremely worried now about the openness of the internet, and the acts and

00:55:25.400 --> 00:55:29.960
[Guest]: the controls that are being now used in terms of accessing the internet, the new people

00:55:29.960 --> 00:55:35.160
[Guest]: who've come on board and have no idea about all the wonderful things that are there on

00:55:35.160 --> 00:55:39.760
[Guest]: the internet for them to experience just because they have access to only a few apps, and they

00:55:39.760 --> 00:55:42.880
[Guest]: don't even know how to go to a browser and type in a URL.

00:55:42.880 --> 00:55:48.040
[Guest]: So I'm worried about how concentration of power is going to impact internet access in

00:55:48.040 --> 00:55:49.880
[Guest]: the future.

00:55:49.880 --> 00:55:55.240
[Guest]: What I am very optimistic about is that we're currently dealing with a generation that's

00:55:55.240 --> 00:55:57.200
[Guest]: grown up with the internet.

00:55:57.200 --> 00:56:00.780
[Guest]: And they care about the space, they love the space, even though some of them may be signing

00:56:00.780 --> 00:56:06.800
[Guest]: up from some platforms, but I think most of us have access, we want access, and that's

00:56:06.800 --> 00:56:08.240
[Guest]: going to continue.

00:56:08.240 --> 00:56:12.400
[Guest]: So ours is a generation that's going to fight for the internet now.

00:56:12.400 --> 00:56:17.120
[Guest]: And there are a large number of people who are as idealistic about it.

00:56:17.120 --> 00:56:22.040
[Guest]: And essentially, this is the second rung that's going to be much better than us in terms of

00:56:22.040 --> 00:56:25.720
[Guest]: fighting for the values that we want in the internet in a sense.

00:56:25.720 --> 00:56:31.040
[Guest]: So I think I'm optimistic about that, because I interact with a lot of is I hate to use

00:56:31.040 --> 00:56:33.120
[Guest]: the word youngsters, because that makes me feel old.

00:56:33.120 --> 00:56:36.960
[Guest]: But if you are old, what are we?

00:56:36.960 --> 00:56:41.400
[Guest]: But I do feel very hopeful when I interact with them, because there is genuine love for

00:56:41.400 --> 00:56:42.880
[Guest]: the internet there.

00:56:42.880 --> 00:56:45.280
[Amit Varma]: And these are the people who will fight for it in the future.

00:56:45.280 --> 00:56:49.160
[Amit Varma]: And I think that's a very gratifying and inspiring note to end this episode on.

00:56:49.160 --> 00:56:50.160
[Amit Varma]: Thank you guys for coming.

00:56:50.160 --> 00:56:51.160
[Guest]: Thanks.

00:56:51.160 --> 00:56:53.400
[Guest]: This is fun.

00:56:53.400 --> 00:56:59.880
[Amit Varma]: If you enjoyed listening to the show, you can follow Nikhil on Twitter at Nixon, N-I-X-X-I-N.

00:56:59.880 --> 00:57:03.080
[Amit Varma]: You can follow Amit Doshi at Doshi Amit.

00:57:03.080 --> 00:57:04.080
[Amit Varma]: No space.

00:57:04.080 --> 00:57:09.440
[Amit Varma]: I'd also encourage you to check out the tech podcast that Amit co-hosts, Shunya One, on

00:57:09.440 --> 00:57:12.840
[Amit Varma]: the IVM podcast app or website.

00:57:12.840 --> 00:57:17.240
[Amit Varma]: You can follow me on Twitter at Amit Verma, A-M-I-T-V-A-R-M-A.

00:57:17.240 --> 00:57:22.000
[Amit Varma]: For past episodes of The Seen and The Unseen, including an episode I did with Nikhil on

00:57:22.000 --> 00:57:27.440
[Amit Varma]: Aadhaar, please head over to seenunseen.in.

00:57:27.440 --> 00:57:35.360
[Amit Varma]: Thank you for listening.

00:57:35.360 --> 00:57:39.680
[Amit Varma]: If you enjoyed listening to The Seen and The Unseen, check out another hit show from Indus

00:57:39.680 --> 00:57:47.040
[Amit Varma]: Fox Media Networks, Cyrus Says, which is hosted by my old colleague from MTV, Cyrus Brocha.

00:57:47.040 --> 00:57:52.240
[Amit Varma]: You can download it on any podcasting network.

00:57:52.240 --> 00:57:56.320
[Unknown]: He bends down to test the warm water for his bath.

00:57:56.320 --> 00:58:01.240
[Unknown]: He comes here to quench his thirst for a hot shower and some podcasts.

00:58:01.240 --> 00:58:07.360
[Unknown]: You can witness how he enjoys having other people talk about cool stuff in his bathroom.

00:58:07.360 --> 00:58:10.480
[Unknown]: Indeed, it helps him with his loneliness.

00:58:10.480 --> 00:58:16.700
[Unknown]: You can find more of his species on ivmpodcast.com, your one-stop destination where you can check

00:58:16.700 --> 00:58:19.160
[Unknown]: out the coolest Indian podcasts.

00:58:19.160 --> 00:58:46.520
[Unknown]: Happy listening!

